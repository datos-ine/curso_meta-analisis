[
  {
    "objectID": "unidad_2/tipos_estimador.html",
    "href": "unidad_2/tipos_estimador.html",
    "title": "Estimadores de efecto",
    "section": "",
    "text": "En esta sección repasaremos los principales estimadores de efecto utilizados en estudios epidemiológicos descriptivos y analíticos y presentaremos ejemplos para el ajuste de modelos de meta-análisis para cada caso usando R.\nComenzaremos por cargar el paquete meta:\n\nlibrary(meta)\n\nLoading required package: metadat\n\n\nLoading 'meta' package (version 8.0-2).\nType 'help(meta)' for a brief overview.\n\n\n\nAttaching package: 'meta'\n\n\nThe following object is masked from 'package:parameters':\n\n    ci\n\n\nThe following object is masked from 'package:effectsize':\n\n    nnt\n\n\nThe following object is masked from 'package:bayestestR':\n\n    ci\n\n\nPara facilitar la exploración de datos, utilizaremos el paquete tidyverse(Wickham et al. 2019):\n\nlibrary(tidyverse)\n\nEn la sección anterior, exploramos cómo personalizar los colores de los forest plot con los argumentos col.diamond y col.square. Para garantizar que los gráficos sean accesibles a personas con deficiencia en la percepción del color, utilizaremos paletas colorblind-friendly disponibles en el paquete scico (Pedersen y Crameri 2023):\n\n# Cargar paquete\nlibrary(scico)\n\n# Lista de paletas categóricas\nscico_palette_show(categorical = TRUE)\n\n\n\n\n\n\n\nEn los ejemplos siguientes, emplearemos la paleta \"buda\", que genera un gradiente de colores entre magenta y amarillo:\n\n# Paleta colorblind-friendly\npal &lt;- scico(n = 3, palette = \"buda\")"
  },
  {
    "objectID": "unidad_2/tipos_estimador.html#introducción",
    "href": "unidad_2/tipos_estimador.html#introducción",
    "title": "Estimadores de efecto",
    "section": "",
    "text": "En esta sección repasaremos los principales estimadores de efecto utilizados en estudios epidemiológicos descriptivos y analíticos y presentaremos ejemplos para el ajuste de modelos de meta-análisis para cada caso usando R.\nComenzaremos por cargar el paquete meta:\n\nlibrary(meta)\n\nLoading required package: metadat\n\n\nLoading 'meta' package (version 8.0-2).\nType 'help(meta)' for a brief overview.\n\n\n\nAttaching package: 'meta'\n\n\nThe following object is masked from 'package:parameters':\n\n    ci\n\n\nThe following object is masked from 'package:effectsize':\n\n    nnt\n\n\nThe following object is masked from 'package:bayestestR':\n\n    ci\n\n\nPara facilitar la exploración de datos, utilizaremos el paquete tidyverse(Wickham et al. 2019):\n\nlibrary(tidyverse)\n\nEn la sección anterior, exploramos cómo personalizar los colores de los forest plot con los argumentos col.diamond y col.square. Para garantizar que los gráficos sean accesibles a personas con deficiencia en la percepción del color, utilizaremos paletas colorblind-friendly disponibles en el paquete scico (Pedersen y Crameri 2023):\n\n# Cargar paquete\nlibrary(scico)\n\n# Lista de paletas categóricas\nscico_palette_show(categorical = TRUE)\n\n\n\n\n\n\n\nEn los ejemplos siguientes, emplearemos la paleta \"buda\", que genera un gradiente de colores entre magenta y amarillo:\n\n# Paleta colorblind-friendly\npal &lt;- scico(n = 3, palette = \"buda\")"
  },
  {
    "objectID": "unidad_2/tipos_estimador.html#meta-análisis-en-estudios-descriptivos",
    "href": "unidad_2/tipos_estimador.html#meta-análisis-en-estudios-descriptivos",
    "title": "Estimadores de efecto",
    "section": "Meta-análisis en estudios descriptivos",
    "text": "Meta-análisis en estudios descriptivos\nEn los estudios descriptivos, los principales estimadores de efecto incluyen la correlación, la prevalencia y la tasa de incidencia. A continuación, presentaremos ejemplos prácticos de ajuste de modelos para cada uno de ellos.\nCorrelaciones\nLas correlaciones miden la fuerza y dirección de la relación entre dos variables numéricas continuas, calculándose como:\n\\[\nr_{xy} = \\frac{Cov_{xy}}{S_xS_y}\n\\]\ndonde:\n\n\\(Cov_{xy}\\) es la covarianza entre las variables X e Y.\n\\(S_x\\) y \\(S_y\\) son los desvíos estándar de cada variable.\n\nDado que los coeficientes de correlación solamente toman valores entre -1 y 1, su distribución no es simétrica, pudiendo afectar la estimación del error estándar en muestras pequeñas. Para corregir este sesgo y estabilizar la varianza, se utiliza la transformación z de Fisher.\nLa función metacor() ajusta modelos de meta-análisis para correlaciones y aplica automáticamente esta transformación mediante el argumento sm = \"ZCOR\".\nComo ejemplo, utilizaremos la base de datos dat.aloe2013, que recopila resultados de cinco estudios sobre la relación entre condiciones laborales y salud mental en trabajadores sociales que atienden infancias.\nComenzamos cargando los datos y explorando su estructura:\n\n# Cargar datos\ndatos_cor &lt;- dat.aloe2013\n\n# Explorar datos\nglimpse(datos_cor)\n\nRows: 5\nColumns: 5\n$ study &lt;chr&gt; \"Abu-Bader (2000)\", \"Cole et al. (2004)\", \"Wallach & Mueller (20…\n$ n     &lt;int&gt; 218, 232, 156, 382, 259\n$ tval  &lt;dbl&gt; 4.61, 6.19, 4.07, -0.77, 1.16\n$ preds &lt;int&gt; 4, 7, 6, 19, 15\n$ R2    &lt;dbl&gt; 0.240, 0.455, 0.500, 0.327, 0.117\n\n\nLas principales variables de interés son:\n\nR2: coeficiente de correlación.\nn: tamaño muestral en cada estudio.\nstudy: identificador del estudio.\n\nAjustamos el modelo de meta-análisis para correlaciones aplicando la transformación z de Fisher:\n\n# Ajuste del modelo\nmod_cor &lt;- metacor(\n  cor = R2,         # Coeficiente de correlación\n  n = n,            # Tamaño de la muestra\n  studlab = study,  # Identificador del estudio\n  data = datos_cor,     # Conjunto de datos\n  sm = \"ZCOR\",      # Transformación z de Fisher\n  common = TRUE,    # Modelo de efectos fijos\n  random = TRUE     # Modelo de efectos aleatorios\n)\n\n# Resumen del modelo ajustado\nmod_cor\n\nNumber of studies: k = 5\nNumber of observations: o = 1247\n\n                        COR           95%-CI     z  p-value\nCommon effect model  0.3195 [0.2685; 0.3687] 11.62 &lt; 0.0001\nRandom effects model 0.3320 [0.1903; 0.4602]  4.44 &lt; 0.0001\n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.0259 [0.0064; 0.2528]; tau = 0.1608 [0.0800; 0.5028]\n I^2 = 84.9% [66.3%; 93.2%]; H = 2.57 [1.72; 3.84]\n\nTest of heterogeneity:\n     Q d.f.  p-value\n 26.44    4 &lt; 0.0001\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n- Fisher's z transformation of correlations\n\n\nLos resultados muestran una correlación positivasignificativa entre condiciones laborales y salud mental \\((p &lt; 0,001)\\). Sin embargo, la heterogeneidad es alta \\((I^2 = 84,9\\%)\\), lo que sugiere que existen diferencias importantes entre los estudios incluidos.\nGeneramos el forest plot para visualizar los resultados:\n\nforest(\n  mod_cor, \n  common = FALSE,               # Omite modelo de efectos fijos\n  col.diamond.random = pal[1],  # Magenta\n  col.square = pal[3]           # Amarillo\n)\n\n\n\n\n\n\n\nSi queremos personalizar los nombres de las etiquetas para que aparezcan en español, podemos modificar algunos de los siguientes argumentos:\n\nsmlab: etiqueta del estimador de efecto.\nleftlabs: etiquetas del panel izquierdo.\nrightlabs: etiquetas del panel derecho.\nhetlab: etiqueta para la heterogeneidad.\ntext.common: etiqueta del modelo de efectos fijos.\ntext.random: etiqueta del modelo de efectos aleatorios.\n\nAplicamos las modificaciones al gráfico anterior:\n\nforest(\n  mod_cor, \n  common = FALSE,                # Omite modelo de efectos fijos\n  col.diamond.random = pal[1],   # Magenta\n  col.square = pal[3],           # Amarillo\n  smlab = \"Correlación de Pearson\",\n  leftlabs = c(\"Estudio\", \"N\"),\n  rightlabs = c(\"COR\", \"95% IC\", \"Peso\"),\n  hetlab = \"Heterogeneidad: \",\n  text.random = \"Modelo de \\n efectos aleatorios\"\n)\n\n\n\n\n\n\n\nPrevalencia\nLa prevalencia representa la proporción de individuos con un evento de interés dentro de una población:\n\\[\np = \\frac{k}{n}\n\\]\ndonde:\n\n\\(k\\) es el número de individuos con la condición/evento.\n\\(n\\) es el tamaño total de la población o muestra.\n\nDado que las proporciones pueden estar cercanas a los valores extremos (0 o 1), su distribución es asimétrica, lo que afecta el cálculo del error estándar. Para corregir este problema, se aplica una transformación logit a los datos.\nLa función metaprop() permite ajustar modelos para prevalencias e incorpora automáticamente esta transformación con el argumento sm = \"PLOGIT\".\nPara ejemplificar, usaremos la base de datos dat.crisafulli2020, que contiene 26 estudios sobre la prevalencia de la distrofia muscular de Duchenne en recién nacidos:\n\n# Cargar datos\ndatos_prev &lt;- dat.crisafulli2020\n\n# Explorar datos\nglimpse(datos_prev)\n\nRows: 26\nColumns: 7\n$ study   &lt;chr&gt; \"Brooks (1977)\", \"Danieli (1977)\", \"Takeshita (1977)\", \"Drummo…\n$ pubyear &lt;int&gt; 1977, 1977, 1977, 1979, 1980, 1980, 1981, 1982, 1983, 1983, 19…\n$ country &lt;fct&gt; UK, IT, JP, NZ, AU, IT, IT, CA, FR, IT, DE, IT, JP, CA, NO, IT…\n$ from    &lt;int&gt; 1953, 1952, 1956, NA, 1960, 1952, 1955, 1950, 1978, 1969, 1977…\n$ to      &lt;int&gt; 1968, 1972, 1970, NA, 1971, 1972, 1974, 1979, 1978, 1980, 1984…\n$ cases   &lt;int&gt; 47, 66, 19, 2, 99, 105, 73, 110, 12, 156, 48, 76, 50, 5, 16, 2…\n$ total   &lt;int&gt; 177413, 234396, 91157, 10000, 532302, 371698, 301283, 420374, …\n\n\nLas principales variables de interés son:\n\ncasos: individuos con el evento.\ntotal: tamaño muestral.\nstudy: identificador de estudio .\n\nAjustamos el modelo de meta-análisis para proporciones aplicando la transformación logit:\n\n# Ajuste del modelo\nmod_prev &lt;- metaprop(\n  event = cases,     # Casos observados\n  n = total,         # Tamaño de la muestra\n  studlab = study,   # Identificador del estudio\n  data = datos_prev,      # Conjunto de datos\n  sm = \"PLOGIT\",     # Transformación logit\n  common = TRUE,     # Modelo de efectos fijos\n  random = TRUE,     # Modelo de efectos aleatorios\n  backtransf = TRUE, # Convertir resultados a proporciones\n  pscale = 100       # Expresar prevalencias como porcentaje\n)\n\n# Resumen del modelo ajustado\nmod_prev\n\nNumber of studies: k = 26\nNumber of observations: o = 6831388\nNumber of events: e = 1545\n\n                     events           95%-CI\nCommon effect model  0.0226 [0.0215; 0.0238]\nRandom effects model 0.0222 [0.0206; 0.0240]\n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.0126; tau = 0.1121; I^2 = 33.2% [0.0%; 58.6%]; H = 1.22 [1.00; 1.55]\n\nTest of heterogeneity:\n          Q d.f. p-value\n Wald 37.41   25  0.0527\n LRT  39.01   25  0.0368\n\nDetails of meta-analysis methods:\n- Random intercept logistic regression model\n- Maximum-likelihood estimator for tau^2\n- Calculation of I^2 based on Q\n- Logit transformation\n- Events per 100 observations\n\n\nComo la prevalencia del evento es muy baja, vamos a expresarla en casos por 100 000 habitantes modificando el argumento pscale en el forest plot. Además, la heterogeneidad estadística es moderada \\((I^2 = 33,2\\%)\\), por lo que se puede omitir del gráfico el modelo de efectos fijos.\nGeneramos el forest plot para visualizar los resultados:\n\nforest(\n  mod_prev,\n  col.diamond = pal[1],   # Magenta\n  col.square = pal[3],    # Amarillo\n  common = FALSE,         # Omite modelo de efectos fijos\n  pscale = 100000,        # Escala a casos/100 000 habitantes\n  smlab = \"Prevalencia \\n (por 100 000 hab.)\",\n  leftlabs = c(\"Estudio\", \"Eventos\", \"N\"),\n  rightlabs = c(\"Eventos\", \"95% IC\"),\n  hetlab = \"Heterogeneidad: \",\n  text.random = \"Modelo de efectos aleatorios\"\n)\n\n\n\n\n\n\n\nTasa de incidencia\nLa tasa de incidencia o incidence rate (IR) se utiliza para eventos que ocurren a lo largo del tiempo y se define como:\n\\[\nIR = \\frac {k}{T}\n\\]​\ndonde:\n\n\\(k\\) es el número de eventos observados.\n\\(T\\) es la suma del tiempo-persona en riesgo en cada estudio.\n\nDado que las tasas de incidencia pueden ser pequeñas y asimétricas, se recomienda aplicar una transformación logarítmica a los datos para estabilizar su varianza.\nLa función metarate() ajusta modelos de meta-análisis para tasas de incidencia, aplicando esta transformación (sm = \"IRLN\").\nComo ejemplo, usamos la base dat.nielweise2008, que contiene 9 estudios sobre la incidencia de infecciones sanguíneas asociadas al uso de catéteres:\n\n# Cargar datos\ndatos_inc &lt;- dat.nielweise2008\n\n# Explorar datos\nglimpse(datos_inc)\n\nRows: 9\nColumns: 7\n$ study   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9\n$ authors &lt;chr&gt; \"Bong et al.\", \"Ciresi et al.\", \"Hanna et al.\", \"Harter et al.…\n$ year    &lt;int&gt; 2003, 1996, 2004, 2002, 2001, 2005, 1997, 2005, 1996\n$ x1i     &lt;int&gt; 7, 8, 3, 6, 1, 1, 17, 3, 2\n$ t1i     &lt;int&gt; 1344, 1600, 12012, 1536, 370, 729, 6760, 1107, 320\n$ x2i     &lt;int&gt; 11, 8, 14, 10, 1, 8, 15, 7, 3\n$ t2i     &lt;int&gt; 1988, 1461, 10962, 1503, 483, 913, 6840, 1015, 440\n\n\nLas principales variables de interés son:\n\nx2i: casos observados.\nt2i: años-persona.\nauthors: identificador de estudio.\n\nAjustamos el modelo de meta-análisis para tasas de incidencia aplicando la transformación logarítmica:\n\n# Ajuste del modelo\nmod_inc &lt;- metarate(\n  event = x2i,            # Casos observados\n  time = t2i,             # Tiempo-persona en riesgo\n  studlab = authors,      # Identificador del estudio\n  data = datos_inc,       # Conjunto de datos\n  sm = \"IRLN\",            # Transformación logarítmica\n  common = TRUE,          # Modelo de efectos fijos\n  random = TRUE,          # Modelo de efectos aleatorios\n)\n\n# Resumen del modelo ajustado\nmod_inc\n\nNumber of studies: k = 9\nNumber of events: e = 77\n\n                       rate           95%-CI\nCommon effect model  0.0039 [0.0031; 0.0048]\nRandom effects model 0.0043 [0.0027; 0.0070]\n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.3699 [0.0940; 1.5145]; tau = 0.6082 [0.3065; 1.2307]\n I^2 = 78.0% [58.4%; 88.4%]; H = 2.13 [1.55; 2.93]\n\nTest of heterogeneity:\n     Q d.f.  p-value\n 36.38    8 &lt; 0.0001\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n- Log transformation\n\n\nComo la tasa de incidencia del evento es muy baja, vamos a expresarla en casos por 1000 años-persona modificando el argumento pscale en el forest plot. Además, la heterogeneidad estadística es alta \\((I^2 = 78\\%)\\), por lo que se puede omitir del gráfico el modelo de efectos fijos.\nGeneramos el forest plot para visualizar los resultados:\n\nforest(\n  mod_inc,\n  col.diamond = pal[1],  # Magenta\n  col.square = pal[3],   # Amarillo\n  common = FALSE,        # Omite modelo de efectos fijos\n  pscale = 1000,         # Escala a casos/1000 años-persona\n  smlab = \"Tasa de incidencia \\n (1000 años-persona)\",\n  leftlabs = c(\"Estudio\", \"Eventos\", \"Tiempo\"),\n  rightlabs = c(\"Eventos\", \"95% IC\", \"Peso\"),\n  hetlab = \"Heterogeneidad: \",\n  text.random = \"Modelo de efectos aleatorios\"\n)"
  },
  {
    "objectID": "unidad_2/tipos_estimador.html#meta-análisis-en-estudios-analíticos",
    "href": "unidad_2/tipos_estimador.html#meta-análisis-en-estudios-analíticos",
    "title": "Estimadores de efecto",
    "section": "Meta-análisis en estudios analíticos",
    "text": "Meta-análisis en estudios analíticos\nDentro de los estudios analíticos (observacionales y/o experimentales), los estimadores de efecto más comunes son la diferencia de medias, el odds-ratio (OR), el riesgo relativo (RR) y la razón de tasas de incidencia (IRR). A continuación, presentamos ejemplos prácticos de ajuste de modelos para cada uno de ellos.\nDiferencia de medias\nLa diferencia de medias entre dos grupos de exposición se define como:\n\\[\nMD = \\bar{x_e} - \\bar{x_c}\n\\]\ndonde:\n\n\\(\\bar{x_e}\\) es la media muestral del grupo expuesto o tratado.\n\\(\\bar{x_c}\\) es la media muestral del grupo no expuesto o control.\n\nEl cálculo de la diferencia de medias requiere que todas las mediciones se hayan tomado en la misma escala. Para los modelos de meta-análisis, se utiliza la diferencia de medias estandarizada, que elimina la dependencia de las unidades de medición al ponderar por el desvío estándar.\nLa función metacont() ajusta modelos de meta-análisis para diferencias de medias estandarizadas con el argumento sm = \"SMD\".\nComo ejemplo, utilizaremos la base de datos dat.furukawa2003, que contiene resultados de 17 estudios sobre la efectividad de la dosis de antidepresivos tricíclicos en casos de depresión severa.\nComenzamos cargando los datos y explorando su estructura:\n\n# Cargar datos\ndatos_md &lt;- dat.furukawa2003\n\n# Explorar datos\nglimpse(datos_md)\n\nRows: 17\nColumns: 7\n$ author &lt;chr&gt; \"Blashki(75&150)\", \"Hormazabal(86)\", \"Jacobson(75-100)\", \"Jenki…\n$ Ne     &lt;int&gt; 13, 17, 10, 7, 73, 26, 17, 11, 105, 22, 13, 29, 13, 78, 23, 11,…\n$ Me     &lt;dbl&gt; 6.40, 11.00, 17.50, 12.30, 15.70, 8.50, 25.50, 6.20, -8.10, 13.…\n$ Se     &lt;dbl&gt; 5.40, 8.20, 8.80, 9.90, 10.60, 11.00, 24.00, 7.60, 3.90, 2.30, …\n$ Nc     &lt;int&gt; 18, 16, 6, 7, 73, 28, 10, 10, 46, 19, 15, 39, 13, 71, 23, 11, 18\n$ Mc     &lt;dbl&gt; 11.40, 19.00, 23.00, 20.00, 18.70, 14.50, 53.20, 10.00, -8.50, …\n$ Sc     &lt;dbl&gt; 9.60, 8.20, 8.80, 10.50, 10.60, 11.00, 11.20, 7.60, 5.20, 1.30,…\n\n\nLas principales variables de interés son:\n\nMe: media muestral en grupo expuesto/tratamiento.\nSe: desvío estándar de la media en grupo expuesto/tratamiento.\nNe: tamaño muestral en grupo expuesto/tratamiento.\nMc: media muestral en grupo no expuesto/control.\nSc: desvío estándar de la media en grupo no expuesto/control.\nNc: tamaño muestral en grupo no expuesto/control.\nauthor: identificador de estudio.\n\nAjustamos el modelo de meta-análisis para diferencia de medias estandarizada:\n\n# Ajuste del modelo\nmod_md &lt;- metacont(\n  n.e = Ne,         # Tamaño muestral grupo expuesto\n  mean.e = Me,      # Media en grupo expuesto\n  sd.e = Se,        # Desvío estándar en grupo expuesto\n  n.c = Nc,         # Tamaño muestral grupo control\n  mean.c = Mc,      # Media en grupo control\n  sd.c = Sc,        # Desvío estándar en grupo control\n  studlab = author, # Identificador del estudio\n  data = datos_md,  # Conjunto de datos\n  sm = \"SMD\",       # Diferencia de medias estandarizada\n  common = TRUE,    # Modelo de efectos fijos\n  random = TRUE,    # Modelo de efectos aleatorios\n)\n\n# Resumen del modelo ajustado \nmod_md\n\nNumber of studies: k = 17\nNumber of observations: o = 902 (o.e = 479, o.c = 423)\n\n                         SMD             95%-CI     z  p-value\nCommon effect model  -0.3918 [-0.5286; -0.2551] -5.62 &lt; 0.0001\nRandom effects model -0.6056 [-0.9326; -0.2787] -3.63   0.0003\n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.3415 [0.1422; 1.1791]; tau = 0.5844 [0.3771; 1.0859]\n I^2 = 72.6% [55.5%; 83.1%]; H = 1.91 [1.50; 2.43]\n\nTest of heterogeneity:\n     Q d.f.  p-value\n 58.38   16 &lt; 0.0001\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n- Hedges' g (bias corrected standardised mean difference; using exact formulae)\n\n\nLa diferencia de medias estandarizada entre el grupo tratado y el grupo control es estadísticamente significativa \\((p&lt;0,001)\\) y presenta alta heterogeneidad \\((I^2 = 73,8\\%)\\), por lo que puede descartarse el modelo de efectos fijos.\nGeneramos el forest plot para visualizar los resultados:\n\nforest(\n  mod_md,\n  common = FALSE,        # Omite modelo de efectos fijos\n  col.diamond = pal[1],  # Magenta\n  col.square = pal[3],   # Amarillo claro\n  smlab = \"Diferencia de medias \\n estandarizada\",\n  leftlabs = c(\"Estudio\", \n               rep(c(\"Total\", \"Media\", \"SD\"),2)),\n  rightlabs = c(\"SMD\", \"95% IC\", \"Peso\"),\n  hetlab = \"Heterogeneidad: \",\n  text.random = \"Modelo de efectos aleatorios\"\n  )\n\n\n\n\n\n\n\nPara mejorar la visualización, podríamos omitir algunas columnas del panel izquierdo usando el argumento leftcols:\n\nforest(\n  mod_md,\n  common = FALSE,        # Omite modelo de efectos fijos\n  col.diamond = pal[1],  # Magenta\n  col.square = pal[3],   # Amarillo claro\n  leftcols = \"studlab\",  # Controla columnas panel izquierdo\n  smlab = \"Diferencia de medias \\n estandarizada\",\n  leftlabs = \"Estudio\",\n  rightlabs = c(\"SMD\", \"95% IC\", \"Peso\"),\n  hetlab = \"Heterogeneidad: \",\n  text.random = \"Modelo de efectos aleatorios\"\n  )\n\n\n\n\n\n\n\nOdds-ratio\nEl odds ratio (OR) o razón de productos cruzados se define como el cociente entre los odds del evento en el grupo expuesto/tratamiento y en el grupo no expuesto/control:\n\\[\nOR =  \\frac{a/b}{c/d}\n\\]\ndonde:\n\n\\(a\\) es el número de eventos en el grupo expuesto/tratamiento.\n\\(b\\) es el número de individuos sin el evento en el grupo expuesto/tratamiento.\n\\(c\\) es el número de eventos en el grupo no expuesto/control.\n\\(d\\) es el número de individuos sin el evento en el grupo no expuesto/control.\n\nEl OR solo puede tomar valores positivos \\((0-\\infty)\\), donde:\n\n\\(OR = 1\\) indica ausencia de efecto.\n\\(OR &gt;1\\) sugiere un aumento en la probabilidad de ocurrencia del evento en el grupo expuesto.\n\\(OR &lt; 1\\) sugiere un posible efecto protector de la exposición o tratamiento.\n\nDado que el OR sigue una distribución asimétrica, su análisis estadístico puede ser complejo. Para estabilizar la varianza y aproximar una distribución normal, se aplica una transformación logarítmica.\nLa función metabin() ajusta modelos de meta-análisis para OR e incorpora automáticamente esta transformación mediante el argumento sm = \"OR\". Además, incluye una corrección de continuidad para manejar estudios con valores de eventos iguales a cero.\nEl siguiente ejemplo utiliza la base de datos dat.collins1985b, que contiene información de 9 estudios sobre el efecto de los diuréticos en la prevención de preeclampsia.\nComenzamos cargando los datos y explorando su estructura:\n\n# Carga datos\ndatos_or &lt;- dat.collins1985b\n\n# Explorar datos\nglimpse(datos_or)\n\nRows: 9\nColumns: 16\n$ id      &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9\n$ author  &lt;chr&gt; \"Weseley & Douglas\", \"Flowers et al.\", \"Menzies\", \"Fallis et a…\n$ year    &lt;int&gt; 1962, 1962, 1964, 1964, 1964, 1965, 1966, 1971, 1975\n$ pre.nti &lt;int&gt; 131, 385, 57, 38, 1011, 1370, 506, 108, 153\n$ pre.nci &lt;int&gt; 136, 134, 48, 40, 760, 1336, 524, 103, 102\n$ pre.xti &lt;int&gt; 14, 21, 14, 6, 12, 138, 15, 6, 65\n$ pre.xci &lt;int&gt; 14, 17, 24, 18, 35, 175, 20, 2, 40\n$ oedema  &lt;int&gt; 0, 0, 1, 0, 1, 0, 0, 0, 0\n$ fup.nti &lt;int&gt; 131, 335, 57, 34, 1011, 1370, 506, 108, 153\n$ fup.nci &lt;int&gt; 136, 110, 48, 40, 760, 1336, 524, 103, 102\n$ ped.xti &lt;int&gt; 1, 6, 3, 1, 14, 24, 14, 0, 0\n$ ped.xci &lt;int&gt; 4, 3, 2, 3, 13, 19, 16, 0, 0\n$ stb.xti &lt;int&gt; 1, 3, 1, 0, 6, NA, 6, 0, 0\n$ stb.xci &lt;int&gt; 2, 2, 1, 1, 5, NA, 9, 0, 0\n$ ned.xti &lt;int&gt; 0, 3, 2, 1, 8, NA, 8, 0, 0\n$ ned.xci &lt;int&gt; 2, 1, 1, 2, 8, NA, 7, 0, 0\n\n\nLas principales variables de interés son:\n\npre.xti: número de eventos en el grupo expuesto/tratamiento.\npre.nti: tamaño muestral en el grupo expuesto/tratamiento.\npre.xci: número de eventos en el grupo no expuesto/control.\npre.nti: tamaño muestral en el grupo no expuesto/control.\nauthor: identificador del estudio.\n\n\n# Ajusta modelo\nmod_or &lt;- metabin(\n  event.e = pre.xti,  # Eventos en el grupo expuesto/tratamiento\n  n.e = pre.nti,      # Tamaño muestral en el grupo expuesto/tratamiento\n  event.c = pre.xci,  # Eventos en el grupo no expuesto/control\n  n.c = pre.nci,      # Tamaño muestral en el grupo control\n  studlab = author,   # Identificador único de cada estudio\n  data = datos_or,       # Conjunto de datos\n  sm = \"OR\",          # Odds-ratio\n  common = TRUE,      # Modelo de efectos fijos\n  random = TRUE       # Modelo de efectos aleatorios\n)\n\n# Resumen del modelo ajustado\nmod_or\n\nNumber of studies: k = 9\nNumber of observations: o = 6942 (o.e = 3759, o.c = 3183)\nNumber of events: e = 636\n\n                         OR           95%-CI     z  p-value\nCommon effect model  0.6677 [0.5620; 0.7932] -4.60 &lt; 0.0001\nRandom effects model 0.5956 [0.3843; 0.9233] -2.32   0.0205\n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.3008 [0.0723; 2.2027]; tau = 0.5484 [0.2689; 1.4842]\n I^2 = 70.7% [41.8%; 85.2%]; H = 1.85 [1.31; 2.60]\n\nTest of heterogeneity:\n     Q d.f. p-value\n 27.26    8  0.0006\n\nDetails of meta-analysis methods:\n- Mantel-Haenszel method (common effect model)\n- Inverse variance method (random effects model)\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n\n\nEl OR combinado sugiere que el uso de diuréticos reduce las probabilidades de preeclampsia en comparación con el grupo control \\((p = 0,021)\\). La heterogeneidad estadística es alta \\((I^2 = 70,7\\%)\\). Debido a esta heterogeneidad, el modelo de efectos aleatorios es el más apropiado.\nGeneramos el forest plot para visualizar los resultados:\n\nforest(\n  mod_or,\n  common = FALSE,        # Omite modelo de efectos fijos\n  col.diamond = pal[1],  # Magenta\n  col.square = pal[3],   # Amarillo claro\n  leftcols = \"studlab\",  # Columnas panel izquierdo\n  smlab = \"Odds-ratio\",\n  leftlabs = \"Estudio\",\n  rightlabs = c(\"OR\", \"95% IC\", \"Peso\"),\n  hetlab = \"Heterogeneidad: \",\n  text.random = \"Modelo de efectos aleatorios\"\n  )\n\n\n\n\n\n\n\nRiesgo relativo\nEl riesgo relativo (RR) o risk ratio mide la razón entre las probabilidades de desarrollar un evento en el grupo expuesto y en el grupo control:\n\\[\nRR =  \\frac{a/(a + b)}{c/(c + d)}\n\\]\ndonde:\n\n\\(a\\) es el número de eventos en el grupo expuesto/tratamiento.\n\\(b\\) es el número de individuos sin el evento en el grupo expuesto/tratamiento.\n\\(c\\) es el número de eventos en el grupo no expuesto/control.\n\\(d\\) es el número de individuos sin el evento en el grupo no expuesto/control.\n\nAl igual que el OR, el RR es una medida asimétrica y solo toma valores positivos \\((0-\\infty)\\). Para estabilizar la varianza y mejorar la interpretación estadística, se usa una transformación logarítmica, lo que permite modelar el RR en un intervalo simétrico y facilita la comparación entre estudios.\nLa función metabin() permite calcular el RR mediante el argumento sm = \"RR\", que aplica automáticamente la transformación logarítmica. Debido a la similitud en el cálculo con el OR, omitiremos el ejemplo para esta medida de asociación.\nRazón de tasas de incidencia\nLa razón de tasas de incidencia (incidence rate ratio, IRR) compara la frecuencia de eventos en dos grupos considerando el tiempo-persona de exposición:\n\\[\nIRR = \\frac{IR_e}{IR_c}\n\\]\ndonde:\n\n\\(IR_e\\) es la tasa de incidencia en el grupo expuesto/tratamiento.\n\\(IR_c\\) es la tasa de incidencia en el grupo no expuesto/control.\n\nAl igual que para la tasa de incidencia, se recomienda realizar la transformación logarítmica de los datos para aproximarlos a una distribución normal.\nEn meta, la función metainc() ajusta modelos de IRR con sm = \"IRR\", aplicando automáticamente la transformación logarítmica.\nA modo de ejemplo, volveremos a usar la base datos_inc, esta vez comparando entre grupo de exposición y control.\nLas principales variables de interés para este caso son:\n\nx1i: casos observados en grupo expuesto/tratamiento.\nt1i: años-persona en grupo expuesto/tratamiento.\nx2i: casos observados en grupo no expuesto/control.\nt2i: años-persona en grupo no expuesto/control.\nauthors: identificador de estudio.\n\nAjustamos el modelo de meta-análisis para IRR aplicando la transformación logarítmica:\n\n# Ajusta modelo\nmod_irr &lt;- metainc(\n  event.e = x1i,          # Casos en grupo expuesto\n  time.e = t1i,           # Tiempo-persona en grupo expuesto\n  event.c = x2i,          # Casos en grupo control\n  time.c = t2i,           # Tiempo-persona en grupo control\n  studlab = authors,      # Identificador único de cada estudio\n  data = datos_inc,       # Conjunto de datos\n  sm = \"IRR\",             # Razón de tasas de incidencia\n  common = TRUE,          # Modelo de efectos fijos\n  random = TRUE,          # Modelo de efectos aleatorios\n  )\n\n# Resumen del modelo ajustado\nmod_irr\n\nNumber of studies: k = 9\nNumber of events: e = 125\n\n                        IRR           95%-CI     z p-value\nCommon effect model  0.6602 [0.4608; 0.9459] -2.26  0.0236\nRandom effects model 0.6728 [0.4314; 1.0494] -1.75  0.0806\n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.0936 [0.0000; 1.4845]; tau = 0.3060 [0.0000; 1.2184]\n I^2 = 17.5% [0.0%; 59.5%]; H = 1.10 [1.00; 1.57]\n\nTest of heterogeneity:\n    Q d.f. p-value\n 9.70    8  0.2869\n\nDetails of meta-analysis methods:\n- Mantel-Haenszel method (common effect model)\n- Inverse variance method (random effects model)\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n\n\nLos resultados del modelo muestran que existe una disminución en el riesgo del evento en el grupo tratado que es significativa en el modelo de efectos fijos \\((p = 0,24)\\), pero no en el de efectos aleatorios \\((p = 0,81)\\), con baja heterogeneidad estadística \\((I^2 = 17,5\\%)\\).\nGeneramos el forest plot para visualizar los resultados, usando los argumentos col.diamond.random y col.diamond.common para mostrar en diferentes colores los estimadores globales del modelo de efectos fijos y el modelo de efectos aleatorios:\n\nforest(\n  mod_irr,\n  col.diamond.random = pal[1],  # Magenta\n  col.diamond.common = pal[2],   # Rosa\n  col.square = pal[3],          # Amarillo claro\n  leftcols = \"studlab\",         # Columnas panel izquierdo\n  smlab = \"Razón de tasas de incidencia\",\n  leftlabs = \"Estudio\",\n  rightlabs = c(\"IRR\", \"95% IC\", \"Peso (fijo)\", \"Peso (aleatorio)\"),\n  hetlab = \"Heterogeneidad: \",\n  text.random = \"Modelo de efectos aleatorios\",\n  text.common = \"Modelo de efectos fijos\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nNota\n\n\n\n\nDebido a la extensión del curso, nos enfocaremos exclusivamente en la implementación en R de los modelos para cada medida de asociación. Quienes deseen profundizar en el desarrollo matemático de estos modelos pueden consultar los capítulos 3 y 4.2 de Harrer et al. (2021).\nActualmente, el paquete meta no incluye funciones específicas para modelar el tiempo hasta el evento (hazard ratio, HR). Sin embargo, si los estudios reportan el log-HR y su error estándar, es posible utilizar la función metagen() con el argumento sm = \"HR\" para obtener una estimación combinada del efecto. Para una explicación detallada del proceso, pueden consultar el capítulo 2.6.1 de Schwarzer, Carpenter, y Rücker (2015)."
  },
  {
    "objectID": "unidad_2/intro.html",
    "href": "unidad_2/intro.html",
    "title": "Introducción",
    "section": "",
    "text": "Un meta-análisis es una herramienta estadística que permite sintetizar cuantitativamente la evidencia de investigaciones independientes sobre un mismo problema de investigación. Se lo ha definido como un “análisis de análisis” (Glass 1976), ya que su unidad de análisis no son individuos o poblaciones, sino estudios científicos.\nEl objetivo principal de un meta-análisis es proporcionar un estimador numérico que resuma los resultados de los estudios incluidos, permitiendo evaluar la magnitud del efecto de una intervención o la relación entre variables en diferentes contextos (Harrer et al. 2021). Es importante destacar que los meta-análisis son adecuados únicamente para investigaciones cuantitativas y, en general, requieren que los estudios analizados compartan el mismo diseño y estimen medidas de asociación similares.\nA continuación, se presentan algunas de las principales ventajas y limitaciones del meta-análisis:\n\n\n\n\nVentajas\nDesventajas\n\n\n\nPermite una síntesis cuantitativa de la evidencia disponible.\nLa validez de los resultados depende de la calidad metodológica de los estudios incluidos.\n\n\nAumenta la potencia estadística al combinar los datos de múltiples estudios.\nPuede estar afectado por sesgos de publicación.\n\n\nMejora la precisión de los estimadores al reducir la variabilidad aleatoria.\nLa heterogeneidad entre estudios puede dificultar la interpretación de los resultados.\n\n\nPermite identificar patrones no evidentes en estudios individuales.\nRequiere una metodología rigurosa y criterios estrictos de selección de estudios.\n\n\nEvalúa la consistencia de los resultados en diferentes poblaciones y contextos.\nNo corrige errores metodológicos de los estudios primarios."
  },
  {
    "objectID": "unidad_2/intro.html#qué-es-un-meta-análisis",
    "href": "unidad_2/intro.html#qué-es-un-meta-análisis",
    "title": "Introducción",
    "section": "",
    "text": "Un meta-análisis es una herramienta estadística que permite sintetizar cuantitativamente la evidencia de investigaciones independientes sobre un mismo problema de investigación. Se lo ha definido como un “análisis de análisis” (Glass 1976), ya que su unidad de análisis no son individuos o poblaciones, sino estudios científicos.\nEl objetivo principal de un meta-análisis es proporcionar un estimador numérico que resuma los resultados de los estudios incluidos, permitiendo evaluar la magnitud del efecto de una intervención o la relación entre variables en diferentes contextos (Harrer et al. 2021). Es importante destacar que los meta-análisis son adecuados únicamente para investigaciones cuantitativas y, en general, requieren que los estudios analizados compartan el mismo diseño y estimen medidas de asociación similares.\nA continuación, se presentan algunas de las principales ventajas y limitaciones del meta-análisis:\n\n\n\n\nVentajas\nDesventajas\n\n\n\nPermite una síntesis cuantitativa de la evidencia disponible.\nLa validez de los resultados depende de la calidad metodológica de los estudios incluidos.\n\n\nAumenta la potencia estadística al combinar los datos de múltiples estudios.\nPuede estar afectado por sesgos de publicación.\n\n\nMejora la precisión de los estimadores al reducir la variabilidad aleatoria.\nLa heterogeneidad entre estudios puede dificultar la interpretación de los resultados.\n\n\nPermite identificar patrones no evidentes en estudios individuales.\nRequiere una metodología rigurosa y criterios estrictos de selección de estudios.\n\n\nEvalúa la consistencia de los resultados en diferentes poblaciones y contextos.\nNo corrige errores metodológicos de los estudios primarios."
  },
  {
    "objectID": "unidad_2/intro.html#estimadores-de-efecto",
    "href": "unidad_2/intro.html#estimadores-de-efecto",
    "title": "Introducción",
    "section": "Estimadores de efecto",
    "text": "Estimadores de efecto\nEn estudios individuales, se asume que las variables de interés fueron medidas de manera uniforme en todos los participantes. Esto permite aplicar técnicas de estadística descriptiva, como el análisis exploratorio de datos (EDA), para caracterizar la muestra y evaluar relaciones entre variables.\nSin embargo, en los meta-análisis esta suposición no siempre se cumple. Aunque los criterios de inclusión sean estrictos, los estudios pueden diferir en diseño, población, medición de variables o definición de resultados. Por ello, no es posible sintetizar la evidencia utilizando exclusivamente herramientas de la estadística tradicional.\nPara integrar los resultados de diferentes estudios, los meta-análisis utilizan estimadores de efecto, también llamados tamaño de efecto o effect size. En algunos casos, estos valores se extraen directamente de los artículos, pero a menudo deben calcularse a partir de los datos reportados. Un buen estimador de efecto debe cumplir con las siguientes condiciones:\n\nComparable: Debe ser consistente entre los estudios incluidos.\nComputable: Debe poder calcularse a partir de la información disponible.\nConfiable: Debe permitir estimar su error estándar.\nInterpretable: Debe responder adecuadamente a la pregunta de investigación.\n\nDesde una perspectiva estadística, los estimadores de efecto son equivalentes a los coeficientes en modelos de regresión o a las medidas de asociación en estudios epidemiológicos, ya que cuantifican la fuerza y dirección de la relación entre dos variables. Algunos estimadores de efecto comúnmente utilizados en investigación epidemiológica y aplicables a modelos de meta-análisis incluyen: proporción, incidencia, correlación, diferencia de medias, odds-ratio (OR), riesgo relativo (RR) y hazard-ratio.\nEn las próximas secciones, exploraremos los modelos de meta-análisis más adecuados para cada estimador de efecto y su implementación en software R."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bienvenidos/as",
    "section": "",
    "text": "Les damos la bienvenida al curso de “Introducción a la Revisión Sistemática con Meta-análisis”. Antes de profundizar en los temas específicos, recomendamos a quienes lo requieran repasar el material introductorio sobre inferencia estadística y primeros pasos en R y RStudio. ya que les proporcionará una base sólida para aprovechar al máximo el curso. ¡Esperamos que disfruten y enriquezcan sus conocimientos!\n\n\n\n Volver arribaReutilizaciónCC BY-NC 4.0"
  },
  {
    "objectID": "extras/intro_inferencia.html",
    "href": "extras/intro_inferencia.html",
    "title": "Introducción a la inferencia estadística",
    "section": "",
    "text": "Artwork por @allison_horst",
    "crumbs": [
      "Material suplementario",
      "Introducción a la inferencia estadística"
    ]
  },
  {
    "objectID": "extras/intro_inferencia.html#fundamentos",
    "href": "extras/intro_inferencia.html#fundamentos",
    "title": "Introducción a la inferencia estadística",
    "section": "Fundamentos",
    "text": "Fundamentos\nLa estadística inferencial es la rama de la estadística que permite extraer conclusiones sobre una población a partir de una muestra de datos. Este proceso se sustenta en dos procedimientos principales: la estimación y la prueba de hipótesis.\nLa población se define como el conjunto completo de individuos u observaciones de interés, mientras que la muestra es el subconjunto representativo de esa población, diseñado para reflejar sus características fundamentales.\nPara describir la población se utilizan parámetros, valores numéricos como la media poblacional \\((\\mu)\\), mientras que los datos muestrales se resumen con estadísticos, por ejemplo, la media muestral \\((\\bar{x})\\).",
    "crumbs": [
      "Material suplementario",
      "Introducción a la inferencia estadística"
    ]
  },
  {
    "objectID": "extras/intro_inferencia.html#estimación-de-parámetros",
    "href": "extras/intro_inferencia.html#estimación-de-parámetros",
    "title": "Introducción a la inferencia estadística",
    "section": "Estimación de parámetros",
    "text": "Estimación de parámetros\nLa estimación consiste en utilizar información muestral para inferir el valor de un parámetro poblacional. Existen dos tipos principales:\n\nEstimación puntual: proporciona un único valor estimado. Por ejemplo, la media muestral (\\(\\bar{x}\\)) como estimador de la media poblacional (\\(\\mu\\)).\nEstimación por intervalo de confianza: proporciona un rango de valores plausibles para el parámetro, con un nivel de confianza determinado.\n\nIntervalos de confianza\nAunque los intervalos de confianza son procedimientos inferenciales, están estrechamente ligados a la estadística descriptiva. Un intervalo de confianza indica un rango de valores dentro del cual se espera que se ubique el verdadero valor del parámetro poblacional, con una cierta probabilidad conocida como nivel de confianza.\nLa forma general de un IC es:\n\\[ IC = estimador~puntual \\pm (coeficiente~de~confiabilidad) * (error~ estandar) \\]\nEstimador puntual\n\nPara la media poblacional (\\(\\mu\\)): se utiliza la media muestral \\(\\bar{x}\\).\nPara una proporción poblacional (\\(p\\)): se utiliza la proporción muestral \\(\\hat{p}\\).\nCoeficiente de confiabilidad\nCorresponde al valor asociado al nivel de confianza deseado (por ejemplo, 90%, 95%, 99%). Se denota como \\(1 - \\alpha\\), siendo \\(\\alpha\\) el nivel de significación (probabilidad de error tipo I). Por ejemplo, para un 95% de confianza, \\(\\alpha = 0.05\\) y el coeficiente es \\(Z_{1 - \\alpha/2} \\approx 1.96\\).\nError estándar (SE)\nRepresenta la variabilidad de la distribución muestral y depende del parámetro.\nPor ejemplo, para la media se calcula:\n\\[\nSE = \\frac{\\sigma}{\\sqrt{n}}\n\\]\nDonde \\(\\sigma\\) es la desviación estándar poblacional y \\(n\\) el tamaño de la muestra.\nMientras que para una proporción se calcula como:\n\\[\nSE = \\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n}}\n\\]\nTeorema del límite central\nEl Teorema del Límite Central (TLC) establece que, para muestras suficientemente grandes, la distribución muestral de la media (\\(\\bar{x}\\)) es aproximadamente normal, con media \\(\\mu\\) y varianza \\(\\sigma^2/n\\). Esto permite utilizar la distribución normal estándar para calcular probabilidades e intervalos:\n\\[\nZ = \\frac{\\bar{x}-\\mu}{\\sigma}\n\\]\nDado esto, se sabe que en una distribución normal:\n\nAproximadamente el 68% de los valores se encuentran entre \\(\\mu \\pm \\sigma\\).\nAproximadamente el 95% entre \\(\\mu \\pm 2\\sigma\\).\nAproximadamente el 99% entre \\(\\mu \\pm 3\\sigma\\).\n\nEl siguiente gráfico ilustra lo explicado anteriormente:\n\n\n\n\n\n\n\n\nUn IC al 95% no significa que haya un 95% de probabilidad de que el parámetro esté dentro de un único intervalo calculado. Lo correcto es decir que, si repitiéramos muchas veces el procedimiento muestral, el 95% de los intervalos construidos de esa forma contendrían el verdadero valor del parámetro.\n¿Cómo se interpreta un IC?\nSi repitiéramos el muestreo muchas veces, tomando muestras del mismo tamaño y construyendo un IC en cada caso, aproximadamente el \\(100 * (1 − \\alpha)\\%\\) de esos intervalos contendrían el valor real del parámetro. Por ejemplo, un IC al 95% implica que, en el largo plazo, el 95% de los intervalos construidos con este método contendrán el valor verdadero.\nLa amplitud del IC está determinada por la precisión de la estimación, que se calcula como el producto entre el coeficiente de confiabilidad (vinculado al nivel de confianza) y el error estándar. La fórmula general para construir un intervalo de confianza es:\n\\[ IC = estimador~puntual \\pm (coeficiente~de~confiabilidad) * (error~ estandar) \\]\nEn el caso de la media:\n\nAumento del nivel de confianza: Si se incrementa el nivel de confianza (por ejemplo, del 95% al 99%), el coeficiente de confiabilidad aumenta (por ejemplo, de 1.96 a 2.58), lo que produce un intervalo más amplio.\n\nReducción del error estándar: Si se mantiene fijo el nivel de confianza, reducir la amplitud del IC requiere disminuir el error estándar. Para la media, este se calcula como:\n\\[ SE = \\frac{\\sigma}{\\sqrt{n}} \\]\ny considerando que \\(\\sigma\\) es constante, la única forma de disminuir el error estándar es aumentando el tamaño muestral (\\(n\\)).\n\n\nEl cálculo de los intervalos de confianza se basa en las distribuciones muestrales de los estimadores y en el error estándar correspondiente. Aunque las fórmulas pueden parecer complejas, los paquetes estadísticos (como R) permiten calcularlos de forma automática. Lo esencial es comprender de qué depende la amplitud del IC (nivel de confianza, error estándar y tamaño de la muestra) y cómo cada uno de estos factores influye en la precisión de la estimación.",
    "crumbs": [
      "Material suplementario",
      "Introducción a la inferencia estadística"
    ]
  },
  {
    "objectID": "extras/intro_inferencia.html#pruebas-de-hipótesis",
    "href": "extras/intro_inferencia.html#pruebas-de-hipótesis",
    "title": "Introducción a la inferencia estadística",
    "section": "Pruebas de Hipótesis",
    "text": "Pruebas de Hipótesis\nLas pruebas de hipótesis (también conocidas como tests o contrastes de hipótesis) permiten tomar decisiones sobre una población a partir de los datos obtenidos de una muestra.\nAntes de profundizar en los aspectos estadísticos, es importante distinguir entre dos tipos de hipótesis:\n\nHipótesis de investigación: representan la pregunta o problema que motiva el estudio.\nHipótesis estadística: es la formulación que puede ser evaluada mediante técnicas de estadística inferencial.\n\nEl contraste de hipótesis se basa en la comparación de dos hipótesis estadísticas:\n\nHipótesis nula (\\(H_0\\)): sostiene que no existen diferencias entre los grupos comparados (por ejemplo, \\(\\mu = \\mu_0\\)​); por lo tanto, cualquier diferencia observada se debe únicamente al azar.\nHipótesis alternativa (\\(H_1\\)): plantea que existen diferencias entre grupos (por ejemplo, \\(\\mu \\neq \\mu_0,~ \\mu &gt; \\mu_0~ ó~ \\mu &lt; \\mu_0\\)). Generalmente es la formulación matemática de nuestra hipótesis de investigación y es complementaria de \\(H_0\\). No se acepta ni se refuta de manera directa.\n\nEl método estadístico nos permite cuantificar la diferencia entre grupos bajo el supuesto de que, si repitiésemos el experimento infinitas veces y obtuviésemos todas las muestras posibles del mismo tamaño, las diferencias entre grupos “iguales” seguirían una distribución muestral teórica. A partir de esta distribución, se define un valor límite (por ejemplo, que abarca el 95% o el 99% de las diferencias esperadas).\n\nSi la diferencia observada excede ese límite, se considera demasiado grande para ser atribuida al azar y se rechaza la hipótesis nula (\\(H_0\\)).\nSi la diferencia cae dentro del rango esperado, no se rechaza \\(H_0\\), ya que podría deberse al azar. En estos casos, se concluye que los grupos “no son diferentes”, lo que no implica que “sean iguales”, ya que la variabilidad muestral impide demostrar una igualdad exacta.\n\nLos contrastes de hipótesis suelen realizarse suponiendo que se conoce a priori la distribución de la población y que se extrae una muestra aleatoria de la misma.\nEstadístico de prueba\nEs el valor calculado a partir de los datos muestrales que se utiliza para tomar la decisión respecto de \\(H_0\\). Cada situación tiene un estadístico adecuado cuya magnitud, al compararse con su distribución teórica permite determinar si las diferencias observadas son atribuibles al azar. Por ejemplo:\n\nPara variables categóricas se utiliza el estadístico chi-cuadrado (\\(\\chi^2\\)).\nPara variables numéricas, se emplean distribuciones como la normal (\\(Z\\)) o t de Student (\\(t\\)).\nErrores\nEn el razonamiento de los contrastes de hipótesis existen dos posibles errores:\n\nError tipo I (\\(\\alpha\\)): ocurre cuando se rechaza la hipótesis nula siendo esta verdadera. Es decir, se concluye erróneamente que existe una diferencia cuando en realidad no la hay. Para minimizar este riesgo, se elige un \\(\\alpha\\) pequeño (por ejemplo, 0,01; 0,05 o 0,10).\nError tipo II (\\(\\beta\\)): ocurre cuando no se rechaza la hipótesis nula siendo esta falsa, es decir, se falla en detectar una diferencia real. El valor de \\(\\beta\\) depende del valor real del parámetro, y suele ser mayor que \\(\\alpha\\); sin embargo, no se conoce con certeza una vez realizada la prueba.\n\nUna vez finalizado el análisis, no es posible saber si se ha cometido alguno de estos errores, ya que el verdadero estado de la población es desconocido. Sin embargo, si se ha utilizado un \\(\\alpha\\) bajo, podemos tener mayor confianza en que, si se rechazó \\(H_0\\), el error tipo I es poco probable.\nNivel de significancia\nEl nivel de significación (\\(\\alpha\\)) representa la probabilidad de cometer un error tipo I, es decir, rechazar \\(H_0\\) cuando en realidad es verdadera. Se define antes del análisis (comúnmente 0,05 o 0,01) y determina el límite entre la región de no rechazo y la región crítica.\nRegión crítica\nSe denomina región crítica (o región de rechazo) al conjunto de valores del estadístico de prueba que llevan al rechazo de \\(H_0\\). Esta región se define según el nivel de significación (\\(\\alpha\\)), e incluye los valores extremos del estadístico que serían poco probables si \\(H_0\\) fuera cierta. En una representación gráfica, la región crítica se ubica en una o ambas colas de la distribución, dependiendo del tipo de prueba\n\n\n\n\n\n\n\n\nLa regla de decisión es la siguiente:\n\nSi el valor calculado del estadístico cae dentro de la región crítica, se rechaza \\(H_0\\) y se concluye que las diferencias observadas son estadísticamente significativas.\nSi el valor no cae en la región crítica, no se rechaza \\(H_0\\). En ese caso, las diferencias observadas pueden explicarse por el azar, y no se consideran estadísticamente significativas.\nValor crítico\nEl valor crítico o p-valor es la probabilidad de obtener un resultado igual o más extremo que el observado, bajo la suposición de que \\(H_0\\) es verdadera. Representa el menor nivel de \\(\\alpha\\) para el cual puede rechazarse \\(H_0\\).\nSi el valor p es muy pequeño, indica que el resultado observado sería poco probable si \\(H_0\\) fuera cierta, por lo tanto, se rechaza la hipótesis nula.\nLa regla práctica es:\n\nSi \\(p \\leq \\alpha\\), se rechaza \\(H_0\\).\nSi \\(p &gt; \\alpha\\), no se rechaza \\(H_0\\).\nTipos de contraste\nLos contrastes de hipótesis se clasifican según la forma de la hipótesis alternativa (\\(H_1\\)). Esta clasificación determina si la prueba es unilateral (de cola izquierda o derecha) o bilateral (de dos colas).\nTest de cola izquierda\nLa hipótesis alternativa plantea que la media del primer grupo es significativamente menor que la del segundo:\n\\[\nH_1: \\mu_1 &lt; \\mu_2\n\\]\nLa región crítica se encuentra en el extremo izquierdo de la distribución. Todo el área crítica tiene un tamaño \\(\\alpha\\) con un valor crítico de \\(-1,645\\).\n\n\n\n\n\n\n\n\nTest de cola derecha\nLa hipótesis alternativa establece que la media del primer grupo es significativamente mayor que la del segundo:\n\\[ H_1: \\mu_1 &gt; \\mu_2 \\]\nLa región crítica se concentra en el extremo derecho de la distribución y toda el área crítica tiene un tamaño \\(\\alpha\\) con un valor crítico de \\(1,645\\).\n\n\n\n\n\n\n\n\nPruebas bilaterales\nLa hipótesis alternativa afirma que existen diferencias entre los grupos, sin especificar la dirección:\n\\[\nH_1: \\mu_1 \\neq \\mu_2\n\\]\nLa región crítica se divide entre ambos extremos de la distribución, con valores críticos de \\(\\pm 1,96\\). El nivel de significación total (\\(\\alpha\\)) se reparte en partes iguales entre las dos colas (\\(\\alpha/2\\) en cada una), lo que implica un 2,5% de probabilidad en cada cola si \\(H_0\\) es verdadera.\n\n\n\n\n\n\n\n\nPotencia estadística\nLa potencia estadística es la probabilidad de rechazar la hipótesis nula (\\(H_0\\)) cuando esta es falsa, es decir, de detectar un efecto real. Se calcula como \\(1 - \\beta\\), donde \\(\\beta\\) es la probabilidad de cometer un error de tipo II. Aumenta con el tamaño muestral, disminuye con la varianza, y depende de la magnitud del efecto que se desea detectar.\nMientras que \\(\\alpha\\) se fija antes del análisis, \\(\\beta\\) varía según el valor real del parámetro. La potencia se considera adecuada cuando alcanza al menos el 80%, lo que implica un 20% de riesgo de no detectar una diferencia real.\nNo es posible reducir simultáneamente \\(\\alpha\\) y \\(\\beta\\), por lo que el diseño de una prueba debe buscar un equilibrio entre ambos errores. La potencia proporciona un control adicional en la toma de decisiones, ya que no basta con obtener un valor p pequeño: también se requiere una potencia suficiente para respaldar la conclusión.\nLa siguiente tabla resume las posibles situaciones en un contraste de hipótesis:\n\n\n\n\n\nNo rechazar H0\nRechazar H0\n\n\n\nH0 es cierta\nCorrecto (1-α)\nError tipo I (α)\n\n\nH0 es falsa\nError tipo II (β)\nCorrecto (1-β)",
    "crumbs": [
      "Material suplementario",
      "Introducción a la inferencia estadística"
    ]
  },
  {
    "objectID": "extras/intro_inferencia.html#aplicaciones-e-interpretación",
    "href": "extras/intro_inferencia.html#aplicaciones-e-interpretación",
    "title": "Introducción a la inferencia estadística",
    "section": "Aplicaciones e Interpretación",
    "text": "Aplicaciones e Interpretación\nLa inferencia estadística permite responder preguntas de investigación tales como:\n\n¿Es significativa la diferencia entre dos medias?\n¿Existe una relación entre dos variables?\n¿Cómo se distribuyen los datos respecto a un parámetro de interés?\n\nAl aplicar estos métodos, es crucial tener en cuenta la calidad y representatividad de la muestra, así como la validez de las asunciones subyacentes (normalidad, homogeneidad de varianzas, etc.).\n\n\n\n\n\n\nEste apunte sintetiza los conceptos esenciales y las herramientas básicas para llevar a cabo un análisis inferencial, que sirve de base para la interpretación de modelos y resultados en análisis cuantitativos. Quienes necesiten profundizar más en los temas, les recomendamos consultar las siguientes fuentes:\n\nManual de Epidemiología: Fundamentos, Métodos y Aplicaciones (Instituto Nacional de Epidemiología 2015): Capítulo 3.\nEstadística 12A Edición (Triola 2018): Capítulos 8 y 9.\n\n\n\n\n\nRíus Díaz et al. (2012)\nDaniel (2002)\nGlantz, S (2006)\nAgresti (2015)",
    "crumbs": [
      "Material suplementario",
      "Introducción a la inferencia estadística"
    ]
  },
  {
    "objectID": "extras/intro_R.html",
    "href": "extras/intro_R.html",
    "title": "Introducción a R y RStudio",
    "section": "",
    "text": "Artwork por @allison_horst",
    "crumbs": [
      "Material suplementario",
      "Introducción a R y RStudio"
    ]
  },
  {
    "objectID": "extras/intro_R.html#qué-es-r",
    "href": "extras/intro_R.html#qué-es-r",
    "title": "Introducción a R y RStudio",
    "section": "¿Qué es R?",
    "text": "¿Qué es R?\nR (2025) es un lenguaje de programación interpretado, orientado a objetos, multiplataforma y de código abierto, diseñado específicamente para el análisis estadístico de datos. Cuenta con estructuras y sintaxis propias, y una extensa colección de funciones desarrolladas para aplicaciones estadísticas.\n\nComo lenguaje orientado a objetos, todo lo que manipulamos —variables, funciones, conjuntos de datos, resultados— se considera un objeto, lo que aporta flexibilidad y simplicidad al trabajo con información.\nAl ser un lenguaje interpretado, los scripts se ejecutan directamente sin necesidad de compilación, lo que favorece la exploración interactiva.\nR es multiplataforma: se puede instalar y ejecutar en Linux, Windows y macOS con un comportamiento consistente.\nAdemás, es software libre distribuido bajo licencia GNU-GPL, lo que permite su uso, modificación y redistribución sin restricciones.\n\nPara instalarlo en Windows, se debe descargar el instalador desde el sitio oficial del proyecto R (CRAN) y seguir los pasos guiados. Una vez finalizada la instalación, R estará listo para usarse desde cualquier entorno compatible. Sin embargo, si no se cuenta con experiencia previa en programación, no se recomienda utilizar R directamente desde su consola nativa.",
    "crumbs": [
      "Material suplementario",
      "Introducción a R y RStudio"
    ]
  },
  {
    "objectID": "extras/intro_R.html#qué-es-rstudio",
    "href": "extras/intro_R.html#qué-es-rstudio",
    "title": "Introducción a R y RStudio",
    "section": "¿Qué es RStudio?",
    "text": "¿Qué es RStudio?\nRStudio Desktop (2025, Posit Software) es un entorno de desarrollo integrado (IDE) diseñado específicamente para facilitar el trabajo con R. Proporciona una interfaz unificada que incluye editor de scripts, consola de R, entorno, explorador de archivos, panel de gráficos y ayuda, entre otros, optimizando el flujo de trabajo.\n\n\n\n\nEntre sus principales ventajas se encuentran:\n\n\nAsistente de código: al escribir en el editor o la consola, la tecla Tab activa el autocompletado de funciones, nombres de objetos y argumentos, agilizando la escritura y reduciendo errores de sintaxis. En versiones recientes, el asistente también permite la previsualización de colores en los gráficos, resaltar los paréntesis de cierre en funciones anidadas con distintos colores y gestionar automáticamente la indentación del código.\n\n\n\nAyuda en línea: al posicionar el cursor sobre el nombre de una función en el editor y presionar F1, se accede directamente a la documentación correspondiente en el panel Help (habitualmente ubicado en la esquina inferior derecha).\n\n\n\nHistorial de comandos: en la consola, al usar las teclas de flecha arriba/abajo, se puede navegar por los comandos ejecutados durante la sesión actual. Además, el panel History (parte superior derecha) almacena los comandos de todas las sesiones previas, permitiendo reutilizarlos con un clic en To Console (Enter) o To Source (Shift + Enter), según se desee insertarlos en la consola o en el script activo.\n\n\n\nRStudio es multiplataforma, de código abierto, y permite una integración fluida con herramientas del ecosistema R, como R Markdown, Quarto, control de versiones y manejo de proyectos.\n\n\n\n\n\n\nUna vez instalados R y RStudio, ya contamos con todo lo necesario para comenzar a trabajar. Aunque instalamos ambos programas, en la práctica sólo necesitamos abrir RStudio, que utiliza a R como motor de ejecución.\n\n\n\nProyectos en RStudio\nLos proyectos de RStudio permiten organizar de forma estructurada todo el material asociado a un análisis: scripts, informes, bases de datos, imágenes, etc. Cada proyecto se vincula a una carpeta específica del sistema de archivos, y RStudio la utiliza como directorio de trabajo por defecto. Esto facilita la importación de datos y evita errores relacionados con rutas relativas o absolutas.\nPara crear un nuevo proyecto, se puede utilizar el menú File &gt; New Project… o el acceso directo New Project… ubicado en la esquina superior derecha de la interfaz. En ambos casos, se abre un asistente con tres opciones:\n\n\n\n\n\nNew Directory: crea una nueva carpeta para el proyecto. Es la opción más habitual.\nExisting Directory: vincula el proyecto a una carpeta ya existente que contenga archivos previos.\nVersion Control: permite clonar un repositorio (Git o SVN). Esta opción no se utilizará en este curso.\n\nTrabajar con proyectos garantiza que, al importar archivos, RStudio los busque automáticamente dentro de la carpeta correspondiente. Además, cada proyecto mantiene su propio entorno de trabajo, lo que significa que al cerrar o cambiar de proyecto, se conserva la configuración previa sin interferencias.\nCuando un proyecto ya existe, dentro de la carpeta encontraremos un archivo con extensión .Rproj que al ejecutarlo abre una nueva sesión de RStudio con el proyecto activo. Otras opciones son abrir desde File &gt; Open Project… o desde el ícono  en la esquina superior derecha de RStudio. Esta última opción también mantiene un historial de los proyectos abiertos recientemente, lo que permite acceder rápidamente a ellos mediante accesos directos.\nScripts en RStudio\nUn script es un archivo de texto plano que contiene instrucciones escritas en R. Permite guardar, reutilizar y compartir el código, favoreciendo la reproducibilidad del análisis.\n\nCrear un nuevo script: podemos crear un script desde el menú File &gt; New File &gt; R Script (acceso rápido: Ctrl + Shift + N) o haciendo clic en el ícono de la hoja (📄) con símbolo “+” en la barra de herramientas.\nEjecutar código: la forma habitual de ejecutar un script es línea por línea, con Ctrl + Enter o el botón Run (). El cursor debe estar en cualquier punto de la línea a ejecutar. Tras la ejecución, el cursor avanza automáticamente a la siguiente línea de código.\nEditar un script: las líneas del script pueden editarse directamente. Cada vez que se realiza una modificación, es necesario volver a ejecutar esas líneas para actualizar los resultados.\nGuardar un script: Para guardar los cambios, se puede usar el ícono del diskette (💾), el menú File &gt; Save, o el atajo Ctrl + S. Para guardar con otro nombre o ubicación, utilizar File &gt; Save As…\nAbrir un script existente: Los archivos de script tienen extensión .R. Pueden abrirse desde el panel File &gt; Open File…, el panel Files o usando el atajo de teclado Ctrl + O. Al abrirse, se muestran en una nueva pestaña del editor.",
    "crumbs": [
      "Material suplementario",
      "Introducción a R y RStudio"
    ]
  },
  {
    "objectID": "extras/intro_R.html#funciones",
    "href": "extras/intro_R.html#funciones",
    "title": "Introducción a R y RStudio",
    "section": "Funciones",
    "text": "Funciones\nEn R, los comandos básicos se denominan funciones. Muchas de ellas están incluidas en el núcleo del lenguaje (conocido como R base) y se denominan integradas, mientras que otras forman parte de paquetes adicionales.\nCada función tiene un nombre y suele requerir uno o más argumentos (también llamados parámetros), que se escriben entre paréntesis y separados por comas. Incluso las funciones que no requieren argumentos deben escribirse con paréntesis vacíos.\n\n# Sintaxis general\nnombre_de_la_función(arg1, arg2, ...)\n\nLas funciones siempre ejecutan una acción o devuelven un valor, que puede ser visualizado, almacenado o utilizado en otras operaciones.\nReglas de sintaxis\nDado que R es un lenguaje interpretado, la sintaxis debe ser estrictamente correcta. Algunos puntos clave:\n\n\nLos argumentos pueden escribirse con el nombre del parámetro seguido de un signo igual:\n\nfuncion(arg1 = 32, arg2 = 5, arg3 = 65)\n\n\n\nTambién se pueden omitir los nombres y escribir directamente los valores. En ese caso, el orden importa y debe coincidir con el definido en la documentación de la función:\n\nfuncion(32, 5, 65)\n\n\nTipos de argumentos\nLos argumentos pueden ser:\n\nValores numéricos: 3, 10.5\nLógicos: TRUE, FALSE\nEspeciales: NA (faltante), NULL, Inf\nTexto: debe escribirse entre comillas, por ejemplo \"menos\"\n\nObjetos: como variables previamente creadas (x, datos, etc.)\n\nfuncion(arg1 = 3, arg2 = NA, arg3 = TRUE, arg4 = \"menos\", arg5 = x)",
    "crumbs": [
      "Material suplementario",
      "Introducción a R y RStudio"
    ]
  },
  {
    "objectID": "extras/intro_R.html#paquetes",
    "href": "extras/intro_R.html#paquetes",
    "title": "Introducción a R y RStudio",
    "section": "Paquetes",
    "text": "Paquetes\nR se compone de un sistema base y de paquetes (librerías) que amplían sus funcionalidades. Un paquete es una colección de funciones, datos y documentación que extiende las capacidades del lenguaje para tareas específicas.\nExisten distintos tipos de paquetes:\n\nBase: se instalan y activan junto con R.\nRecomendados: también se instalan por defecto, pero requieren ser cargados manualmente.\nAdicionales: más de 17.000 disponibles en el repositorio oficial CRAN, listos para ser instalados según necesidad. Además, algunos paquetes pueden descargarse desde otros repositorios como GitHub y Bioconductor.\n\nAl ser open source, cualquier persona puede desarrollar y publicar nuevos paquetes. Esto convierte a R en una herramienta en constante evolución.\nInstalación\nLos paquetes pueden instalarse desde R o RStudio o (si no hay acceso a internet o trabajamos con conexiones de uso medido) desde archivos locales .zip o .tar.gz, descargados previamente desde CRAN u otros repositorios.\nEn RStudio, los paquetes se gestionan desde la pestaña Packages (bloque inferior derecho). Para instalar uno nuevo:\n\nHacer clic en , se abrirá una ventana emergente:\n\n\n\n\n\n\nEspecificar el nombre del paquete a instalar.\nMarcar la opción Install dependencies para incluir automáticamente sus dependencias.\nAl presionar el botón Install, R internamente traduce esta acción a la función install.packages().\n\nLos paquetes deben instalarse una única vez por computadora cuando se los va a utilizar por primera vez. A partir de entonces, sólo es necesario cargarlos al inicio de cada sesión mediante la función library():\n\nlibrary(nombre_del_paquete)\n\nDependencias\nMuchos paquetes requieren funciones de otros paquetes para funcionar. Estos paquetes (dependencias) deben estar instaladas previamente, de lo contrario la ejecución de una función puede fallar por no encontrar otra interna. Por eso, es recomendable dejar seleccionada la opción Install dependencies al instalar.\nPaquetes a instalar\nPara trabajar durante el curso, deberemos instalar los siguientes paquetes y sus dependencias:\n\n# Manejo de datos\ninstall.packages(\"tidyverse\", dependencies = T)\n\ninstall.packages(\"janitor\", dependencies = T)\n\n# Modelos de meta-análisis\ninstall.packages(\"metafor\", dependencies = T)\n\ninstall.packages(\"meta\", dependencies = T)\n\n# Paletas aptas para daltonismo\ninstall.packages(\"scico\", dependencies = T)\n\n# Visualización avanzada\nremotes::install_github(\"daniel1noble/orchaRd\")",
    "crumbs": [
      "Material suplementario",
      "Introducción a R y RStudio"
    ]
  },
  {
    "objectID": "extras/intro_R.html#objetos",
    "href": "extras/intro_R.html#objetos",
    "title": "Introducción a R y RStudio",
    "section": "Objetos",
    "text": "Objetos\nEn R, los datos, resultados, funciones y estructuras se almacenan en objetos, que constituyen la unidad fundamental de trabajo en el lenguaje.\nPara crear un objeto, se utiliza el operador de asignación &lt;- (también se acepta = aunque no se recomienda) para asignar un valor a un nombre:\n\nx &lt;- 10 \n\nEn este ejemplo, el número 10 se asigna al objeto llamado x. A partir de ese momento, podemos utilizar x en otras operaciones:\n\nx + 5  # devuelve 15\n\nLos nombres de objetos:\n\nDeben comenzar con una letra y pueden incluir letras, números, puntos (.) y guiones bajos (_).\nNo deben coincidir con palabras reservadas a funciones del lenguaje.\nSon sensibles a mayúsculas/minúsculas: Edad y edad son objetos distintos.\n\nLos objetos contenedores de datos más simples pertenecen a cinco clases que se denominan atómicas y que son los siguientes tipos de datos:\n\ninteger: números enteros.\nnumeric: números reales (también llamados “doble precisión”).\ncomplex: números complejos.\ncharacter: cadenas de texto o caracteres.\n\nlogical: valores lógicos (TRUE o FALSE).\n\nnúmero &lt;- 25           # entero\ndecimal &lt;- 3.14        # numérico\ntexto &lt;- \"Hola\"        # carácter\nlogico &lt;- TRUE         # lógico (booleano)\n\n\n\nAdemás de los tipos atómicos, los datos pueden organizarse en estructuras contenedoras que permiten agrupar múltiples valores:\n\nVector: conjunto de elementos del mismo tipo, ordenados linealmente. Se construye con la función c().\nLista: colección ordenada de objetos de distinto tipo o longitud, creada con list().\n\nDataframe: estructura bidimensional donde cada columna es un vector del mismo largo (generalmente del mismo tipo). Se construye con data.frame() o, en el tidyverse, con tibble().\n\n# Vector\nvector  &lt;- c(1, 2, 3, 4)\n\n# Lista\nlista &lt;- list(vector, \"elemento_2\") # lista\n\n# Dataframe (R base)\ndataframe &lt;- data.frame(\n  var1 = vector,\n  var2 = vector + 5,\n  var3 = vector * vector^2\n)\n\n# Dataframe (tidyverse)\ntibble &lt;- tibble(\n  var1 = vector,\n  var2 = vector + 5,\n  var3 = vector * vector^2\n)",
    "crumbs": [
      "Material suplementario",
      "Introducción a R y RStudio"
    ]
  },
  {
    "objectID": "extras/intro_R.html#archivos-de-datos",
    "href": "extras/intro_R.html#archivos-de-datos",
    "title": "Introducción a R y RStudio",
    "section": "Archivos de datos",
    "text": "Archivos de datos\nR permite importar tablas de datos desde diversos formatos, tanto utilizando funciones de R base como funciones provistas por paquetes específicos.\nEl formato más común es el texto plano (ASCII), donde los valores están organizados en columnas separadas por caracteres delimitadores. Los separadores más habituales incluyen:\n\nComa (,)\nPunto y coma (;)\nTabulación (\\t)\nBarra vertical (|)\n\nEstos archivos suelen tener una cabecera (header) en la primera fila con los nombres de las variables, y cada columna debe contener datos del mismo tipo (números, texto, lógicos, etc.).\nPara importar correctamente un archivo es importante conocer su estructura:\n\nSi incluye o no cabecera.\nQué carácter se usa como separador.\nEl tipo de codificación (UTF-8, Latin1, etc.).\n\nDado que son archivos de texto, pueden visualizarse con editores simples como el Bloc de Notas o desde RStudio, lo que facilita su inspección previa.\nPara cargar los datos desde un archivo de texto plano o una hoja de cálculo de Excel usamos el código:\n\ndatos &lt;- read.xxx(\"mis_datos.txt\")\n\n(Se debe reemplazar read.xxx() por la función correspondiente: read.table(), read.csv(), read_delim(), read_excel(), etc., según el caso).\nR también permite cargar bases de datos incluidas en paquetes instalados mediante:\n\ndata(nombre_datos)\n\ndatos &lt;- nombre_datos",
    "crumbs": [
      "Material suplementario",
      "Introducción a R y RStudio"
    ]
  },
  {
    "objectID": "extras/intro_R.html#buenas-prácticas",
    "href": "extras/intro_R.html#buenas-prácticas",
    "title": "Introducción a R y RStudio",
    "section": "Buenas prácticas",
    "text": "Buenas prácticas\nAdoptar buenas prácticas desde el inicio mejora la reproducibilidad, facilita el trabajo colaborativo y reduce errores. Algunas recomendaciones clave son:\n\nTrabajar siempre dentro de un proyecto de RStudio (.Rproj). Esto permite organizar los archivos, mantener rutas relativas consistentes y acceder a funcionalidades específicas como control de versiones o panel de archivos integrados.\nIncluir al comienzo de cada script las líneas de activación de paquetes necesarios, utilizando la función library().\nCargar los datos una vez activados los paquetes, para garantizar que todas las funciones requeridas estén disponibles.\nDocumentar el código mediante comentarios iniciados con #. Esto permite entender qué hace cada bloque de código, facilitando futuras modificaciones o revisiones.\nUsar espacios e indentación adecuada para mejorar la legibilidad. Esto es especialmente importante en estructuras anidadas (como condicionales, bucles o funciones).\n\nUna guía de estilo ampliamente recomendada —aunque no oficial— es la de tidyverse. Incluye ejemplos concretos de buenas y malas prácticas para nombrar variables, manejar líneas largas, usar sangrías, entre otros aspectos. Puede consultarse en: https://style.tidyverse.org/\n\n\n\n\n\n\nImportante\n\n\n\nEste apunte ofrece un resumen general para quienes deseen repasar los aspectos básicos de R y RStudio.\nSi no cuentan con experiencia previa en R y necesitan una introducción más detallada, podés consultar los siguientes recursos:\n\nCurso de Epidemiología Nivel Avanzado - Unidad 1: Introducción a R\nEpiR Handbook – secciones Aspectos básicos y Gestión de datos.\n\nAnte cualquier duda específica, recuerden que pueden comunicarse con los/as docentes del curso.",
    "crumbs": [
      "Material suplementario",
      "Introducción a R y RStudio"
    ]
  },
  {
    "objectID": "unidad_2/fixed_random.html",
    "href": "unidad_2/fixed_random.html",
    "title": "Modelos de efectos fijos y aleatorios",
    "section": "",
    "text": "Uno de los objetivos principales del modelado estadístico es representar la realidad de la manera más “sencilla” posible, capturando su estructura esencial y descartando elementos cuya variabilidad podría generar ruido en la interpretación de los fenómenos.\nPara ajustar un modelo estadístico, partimos de los datos disponibles y buscamos construir una representación basada en ellos. En el caso de los modelos de meta-análisis, los datos de interés son los estimadores de efecto obtenidos en cada estudio, y el objetivo principal es analizar la variabilidad entre ellos, la cual puede deberse a diferencias metodológicas, características de las poblaciones estudiadas u otras fuentes.\nExisten dos enfoques principales en meta-análisis: los modelos de efectos fijos y los modelos de efectos aleatorios. Durante este curso, describiremos sus características fundamentales y su implementación en R. Para quienes deseen profundizar en los fundamentos matemáticos de estos modelos, recomendamos consultar el Capítulo 4 de Schwarzer, Carpenter, y Rücker (2015) y el Capítulo 2 de Harrer et al. (2021)."
  },
  {
    "objectID": "unidad_2/fixed_random.html#introducción",
    "href": "unidad_2/fixed_random.html#introducción",
    "title": "Modelos de efectos fijos y aleatorios",
    "section": "",
    "text": "Uno de los objetivos principales del modelado estadístico es representar la realidad de la manera más “sencilla” posible, capturando su estructura esencial y descartando elementos cuya variabilidad podría generar ruido en la interpretación de los fenómenos.\nPara ajustar un modelo estadístico, partimos de los datos disponibles y buscamos construir una representación basada en ellos. En el caso de los modelos de meta-análisis, los datos de interés son los estimadores de efecto obtenidos en cada estudio, y el objetivo principal es analizar la variabilidad entre ellos, la cual puede deberse a diferencias metodológicas, características de las poblaciones estudiadas u otras fuentes.\nExisten dos enfoques principales en meta-análisis: los modelos de efectos fijos y los modelos de efectos aleatorios. Durante este curso, describiremos sus características fundamentales y su implementación en R. Para quienes deseen profundizar en los fundamentos matemáticos de estos modelos, recomendamos consultar el Capítulo 4 de Schwarzer, Carpenter, y Rücker (2015) y el Capítulo 2 de Harrer et al. (2021)."
  },
  {
    "objectID": "unidad_2/fixed_random.html#modelos-de-efectos-fijos",
    "href": "unidad_2/fixed_random.html#modelos-de-efectos-fijos",
    "title": "Modelos de efectos fijos y aleatorios",
    "section": "Modelos de efectos fijos",
    "text": "Modelos de efectos fijos\nEl modelo de efectos fijos parte de la premisa de que todos los estimadores de efecto incluidos en el meta-análisis corresponden a un mismo efecto verdadero común y que las diferencias observadas entre ellos se deben exclusivamente al error muestral. Bajo este enfoque, se asume que existe un único valor subyacente para el efecto de interés, por lo que el objetivo principal es estimarlo a partir de los datos disponibles.\nEl estimador de efecto global, denotado como \\(\\theta\\), se calcula como un promedio ponderado de los estimadores individuales, asignando a cada estudio un peso proporcional a su precisión:\n\\[\n\\theta = \\frac{\\sum{y_i w_i}}{\\sum{w_i}}\n\\]\nDonde:\n\n\\(y_i\\) es el efecto estimado para cada estudio.\n\\(w_i\\) es el peso asignado a cada estudio, calculado como el inverso de la varianza del estimador de efecto: \\(w_i = 1/S^2_{y_i}\\).\n\nDe este modo, los estudios con menor varianza tienen mayor influencia en la estimación final. Esta estrategia de ponderación se conoce como el método de la varianza inversa.\nDado que estos modelos suponen homogeneidad entre los estudios, no contemplan la existencia de fuentes adicionales de variabilidad más allá del error aleatorio. Por esta razón, también se les conoce como modelos de efecto común (common effect model) o modelos de efectos equivalentes (equal effect model).\nSin embargo, en la práctica, es común encontrar heterogeneidad entre los estudios, lo que puede hacer que el modelo de efectos fijos sea inadecuado. Cuando existe variabilidad real entre los estudios, un modelo de efectos aleatorios suele ser una opción más apropiada, ya que permite incorporar esta variabilidad en la estimación del efecto global."
  },
  {
    "objectID": "unidad_2/fixed_random.html#modelos-de-efectos-aleatorios",
    "href": "unidad_2/fixed_random.html#modelos-de-efectos-aleatorios",
    "title": "Modelos de efectos fijos y aleatorios",
    "section": "Modelos de efectos aleatorios",
    "text": "Modelos de efectos aleatorios\nLos modelos de efectos aleatorios suponen que, además del error aleatorio, existen otras fuentes de variabilidad entre los estudios. En este caso, no se asume que todos los estudios comparten un único efecto verdadero común, sino que cada uno estima un efecto específico que varía dentro de una distribución de efectos verdaderos.\nBajo este enfoque, los efectos verdaderos no son idénticos entre estudios, sino que siguen una distribución alrededor de una media global. Esto introduce una componente adicional de variabilidad, conocida como heterogeneidad entre estudios, que refleja diferencias sistemáticas más allá del error muestral.\nEl objetivo de estos modelos es estimar la media de la distribución de efectos verdaderos, considerando tanto la variabilidad dentro de cada estudio como la variabilidad entre estudios. Para ello, el peso asignado a cada estudio en la estimación global se ajusta de la siguiente manera:\n\\[w^*_i = \\frac{1}{S^2_{y_i} + \\tau^2}\\]\ndonde:\n\n\\(S^2_{y_i}\\) es la varianza intraestudio, que indica la precisión del estimador de efecto.\n\\(\\tau^2\\) (tau-cuadrado) es la varianza entre estudios, que mide la heterogeneidad en los efectos estimados.\n\nExisten diversos métodos para estimar \\(\\tau^2\\), siendo los más comunes la máxima verosimilitud restringida (REML) y el método de DerSimonian y Laird. Aunque el desarrollo matemático de estos métodos excede los alcances del curso, su correcta aplicación es fundamental para interpretar adecuadamente los resultados de un meta-análisis con efectos aleatorios."
  },
  {
    "objectID": "unidad_2/fixed_random.html#medidas-de-heterogeneidad",
    "href": "unidad_2/fixed_random.html#medidas-de-heterogeneidad",
    "title": "Modelos de efectos fijos y aleatorios",
    "section": "Medidas de heterogeneidad",
    "text": "Medidas de heterogeneidad\nEn un meta-análisis, la variabilidad en los resultados puede deberse a múltiples fuentes:\n\nVariabilidad intraestudio, que refleja las diferencias entre los participantes dentro de cada estudio.\nHeterogeneidad entre estudios, es decir, la variabilidad en los efectos estimados más allá de lo esperable por azar.\nError de muestreo y otras fuentes de incertidumbre, que pueden influir en las diferencias observadas.\n\nLa heterogeneidad entre estudios es particularmente importante, ya que indica si los efectos varían más de lo que se esperaría solo por error aleatorio. En la siguiente tabla, adaptada de Schwarzer, Carpenter, y Rücker (2015), se resumen los indicadores más utilizados para cuantificar la heterogeneidad:\n\n\nMedida\nInterpretación\nEscala\nRango\nNúmero de estudios\nAfectada por precisión\n\n\n\nQ de Cochran\nEvalúa si la heterogeneidad observada es estadísticamente significativa.\nAbsoluta\n[0, ∞)\nDependiente\nSí\n\n\nI²\nCuantifica qué proporción de la variabilidad total se debe a heterogeneidad real.\nPorcentaje\n[0, 100]\nIndependiente\nSí\n\n\nτ²\nMide la variabilidad real entre los efectos verdaderos de los estudios.\nVarianza\n[0, ∞)\nIndependiente\nNo\n\n\nH²\nRazón entre la varianza total observada y la varianza esperada bajo el supuesto de homogeneidad.\nAbsoluta\n[1, ∞)\nIndependiente\nSí\n\n\n\nEstos indicadores permiten evaluar si las diferencias observadas entre los estudios justifican el uso de un modelo de efectos aleatorios en lugar de uno de efectos fijos."
  },
  {
    "objectID": "unidad_2/fixed_random.html#implementación-en-r",
    "href": "unidad_2/fixed_random.html#implementación-en-r",
    "title": "Modelos de efectos fijos y aleatorios",
    "section": "Implementación en R",
    "text": "Implementación en R\nPara ajustar modelos de meta-análisis en R, los dos paquetes más utilizados son metafor (Viechtbauer 2010) y meta (Balduzzi, Rücker, y Schwarzer 2019).\n\nmetafor: Es un paquete flexible y potente que permite modelar escenarios complejos con alta precisión. Sin embargo, su uso requiere una curva de aprendizaje más pronunciada y un conocimiento avanzado en modelado estadístico.\nmeta: Es más accesible y fácil de usar, lo que lo convierte en una excelente opción para quienes sólo poseen conocimientos básicos de estadística inferencial y manejo de R. Este paquete es ideal para aplicaciones prácticas y proporciona una interfaz más simple y directa para realizar análisis estándar.\n\nDado que este curso se enfoca en la aplicación práctica del meta-análisis, utilizaremos principalmente el paquete meta. Este paquete ajusta de manera predeterminada tanto modelos de efectos fijos como de efectos aleatorios e incluye distintos estimadores de heterogeneidad estadística.\nEstructura básica\nEl paquete meta ofrece una serie de funciones para ajustar modelos de meta-análisis con una estructura uniforme. La función principal sigue el formato metaxxx(), donde xxx indica el estimador de efecto a calcular. Sus argumentos clave incluyen:\n\nmetaxxx(\n  studlab,\n  data,\n  sm,\n  common,\n  random,\n  method.tau,\n  backtransf,\n  subset,        \n  exclude,\n  subgroup,\n  cluster        \n)\n\ndonde:\n\nstudlab: Identificador único de cada estudio en el conjunto de datos.\ndata: Conjunto de datos con los resultados de los estudios incluidos en el meta-análisis.\nsm: Estimador de efecto global a calcular (ej.: “OR” para odds ratio, “RR” para riesgo relativo, “MD” para diferencia de medias, etc.).\ncommon: Indica si se ajusta un modelo de efectos fijos (TRUE, por defecto) o se omite (FALSE).\nrandom: Indica si se ajusta un modelo de efectos aleatorios (TRUE, por defecto) o se omite (FALSE).\nmethod.tau: Método para estimar la varianza entre estudios (REML, por defecto).\nbacktransf: Define si los resultados se muestran en la escala original de los datos (TRUE) o transformada (FALSE, por ejemplo log-OR).\nsubset: Permite seleccionar un subconjunto de estudios para el análisis (opcional).\nexclude: Permite excluir estudios específicos (opcional).\nsubgroup: Permite realizar un análisis por subgrupos (opcional).\ncluster: Permite ajustar modelos multinivel si los datos están agrupados en clústeres (opcional).\nEjemplo práctico\nEn este ejemplo, utilizaremos la función metagen(), diseñada para trabajar con estimadores de efecto previamente calculados. Usaremos el conjunto de datos dat.konstantopoulos2011, que contiene información de un meta-análisis de 56 estudios sobre el impacto de la modificación del calendario escolar en el rendimiento académico. Este conjunto de datos forma parte de la dependencia metadat (Viechtbauer et al. 2025), que se carga automáticamente al activar el paquete meta.\n\n# Cargar el paquete meta\nlibrary(meta)\n\n# Cargar datos\ndatos &lt;- dat.konstantopoulos2011\n\n# Explorar variables disponibles\nnames(datos)\n\n[1] \"district\" \"school\"   \"study\"    \"year\"     \"yi\"       \"vi\"      \n\n\nLas variables de entrada para metagen() serán yi (diferencia de medias estandarizada) y vi (varianza de la estimación). Ajustamos los modelos de efectos fijos y aleatorios:\n\n# Ajustar el modelo de efectos fijos y aleatorios\nmod &lt;- metagen(TE = yi,\n               seTE = vi,\n               studlab = study,\n               common = TRUE,    \n               random = TRUE,    \n               backtransf = TRUE, \n               data = datos)\n\n# Mostrar salida del modelo\nmod\n\nNumber of studies: k = 56\n\n                                         95%-CI      z p-value\nCommon effect model  -0.0133 [-0.0140; -0.0126] -38.82       0\nRandom effects model  0.1219 [ 0.0365;  0.2074]   2.80  0.0052\n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.1048 [0.0739; 0.1588]; tau = 0.3238 [0.2719; 0.3985]\n I^2 = 99.9%; H = 41.32\n\nTest of heterogeneity:\n        Q d.f. p-value\n 93892.81   55       0\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n\n\nDado que la heterogeneidad estadística es alta \\((I^2 = 99,9\\%)\\), podemos omitir el modelo de efectos fijos cambiando a FALSE el argumento common:\n\n# Ajustar solo el modelo de efectos aleatorios\nmod &lt;- metagen(TE = yi,\n               seTE = vi,\n               studlab = study,\n               common = FALSE,    \n               random = TRUE,    \n               backtransf = TRUE, \n               data = datos)\n\n# Mostrar salida del modelo\nmod\n\nNumber of studies: k = 56\n\n                                      95%-CI    z p-value\nRandom effects model 0.1219 [0.0365; 0.2074] 2.80  0.0052\n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.1048 [0.0739; 0.1588]; tau = 0.3238 [0.2719; 0.3985]\n I^2 = 99.9%; H = 41.32\n\nTest of heterogeneity:\n        Q d.f. p-value\n 93892.81   55       0\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n\n\nPara explorar los resultados con más detalle, podemos utilizar summary(mod) que incluye las métricas para cada estudio individual:\n\nEstimador de efecto: Diferencia de medias estandarizada por estudio.\n95%-CI: Intervalo de confianza al 95% de la diferencia de medias estandarizada.\n%W (random): Peso de cada estudio en el modelo de efectos aleatorios, determinado por el tamaño muestral y la varianza.\n\nA continuación se muestran los resultados generales del meta-análisis:\n\nk: número total de estudios incluidos en el análisis.\nCommon effects model: Diferencia de medias observada para cada estudio en el modelo de efectos fijos.\nRandom effects model: Diferencia de medias observada para cada estudio en el modelo de efectos aleatorios.\nEl estadístico z y su p-valor (p-value) para evaluar la significancia del efecto global.\n\nLuego se presentan las métricas de heterogeneidad:\n\ntau^2 y tau: cuantifican la variabilidad entre estudios más allá del error muestral.\nI^2: porcentaje de variabilidad atribuida a diferencias reales entre estudios.\nH y Q: indicadores de heterogeneidad en el conjunto de estudios.\n\nLa salida del modelo también detalla los métodos estadísticos utilizados, incluyendo:\n\nMétodo de varianza inversa para ponderar los estudios.\nEstimador de máxima verosimilitud restringida para tau^2.\nMetodología aplicada para calcular I^2.\n\nEn base a la salida anterior, podemos concluir que el meta-análisis realizado sobre 56 estudios individuales muestra que el rendimiento académico aumenta significativamente con la modificación del calendario escolar \\((p &lt; 0.005)\\). La alta heterogeneidad estadística \\((I^2 = 99,9\\%)\\) sugiere que la variabilidad observada se debe a diferencias reales entre estudios.\nForest plots\nLos resultados del meta-análisis pueden visualizarse mediante forest plots, gráficos que representan la distribución de los estimadores de efecto de los estudios individuales y sus intervalos de confianza en relación con el estimador global. Además, proporcionan información sobre la heterogeneidad entre estudios, facilitando la interpretación de los resultados.\nEl paquete meta incluye la función forest(), que permite generar forest plots de forma rápida y con múltiples opciones de personalización. Para conocer todos los argumentos disponibles, se puede ejecutar ?forest en la consola de R.\nAlgunos de los principales argumentos de forest() incluyen:\n\nforest(\n  mod, # Nombre del modelo de meta-análisis\n  sortvar, # Ordena los estudios según una variable numérica\n  smlab, # Etiqueta del estimador de efecto\n  col.diamond, # Color del estimador global\n  col.square, # Color de los estimadores individuales\n  print.tau2 = TRUE, # Tau-cuadrado (TRUE por defecto)\n  print.I2 = TRUE, # I-cuadrado (TRUE por defecto)\n  print.Q = TRUE, # Estadístico Q de Cochran (TRUE por defecto)\n  print.pval.Q = TRUE, # p-valor del estadístico Q (TRUE por defecto)\n  digits = 2, # Número de decimales a mostrar\n  ...)\n\nA continuación, generamos un forest plot básico a partir del modelo de efectos aleatorios. Para una mejor visualización, vamos a personalizar los colores del gráfico con los argumentos col.diamond y col.square:\n\nforest(mod,\n       smlab = \"Diferencia de medias estandarizada\",\n       col.diamond = \"orange\",\n       col.square = \"turquoise\")\n\n\n\n\n\n\n\nEl gráfico generado se organiza en tres paneles principales:\n\n\nPanel izquierdo:\n\nIdentificador de estudio (\"studlab\")\nColumnas adicionales dependientes del estimador de efecto utilizado.\n\n\n\nPanel central:\n\nLínea vertical de referencia que indica el valor de no efecto (0 en datos continuos, 1 en escalas logarítmicas).\nLínea punteada que representa el estimador global del meta-análisis.\nRombo (🔶): Representa el estimador global, cuyo ancho indica el intervalo de confianza al 95%.\nCuadrados (🟦): Representan los estimadores de los estudios individuales, con un tamaño proporcional al peso del estudio en el análisis.\nBigotes horizontales: Indican los intervalos de confianza al 95% de cada estudio.\n\n\n\nPanel derecho:\n\nEstimador de efecto e intervalo de confianza al 95% de cada estudio.\nPeso estadístico asignado a cada estudio en el modelo de efectos aleatorios.\n\n\n\nSe puede controlar la información que aparece en los lados del forest plot mediante los argumentos leftcols, rightcols, leftlabs y rightlabs. También es posible aplicar formatos predefinidos con layout = \"RevMan5\" o layout = \"JAMA\", que ajustan el diseño según estilos ampliamente utilizados en la literatura científica.\nLos gráficos generados con forest() no son compatibles conggplot2 ni se autoescalan, lo que puede ser problemático si el número de estudios es grande, ya que el gráfico podría quedar ilegible en la vista predeterminada.\nPara evitar este problema, se recomienda exportar el gráfico a un archivo de imagen (por ejemplo, PDF o PNG) usando las funciones pdf() o png(), especificando un tamaño adecuado antes de ejecutarlo con forest().\n\n# Defino parámetros para guardar la imagen\npng(\n  filename = \"forest.png\", # Nombre de archivo para guardar el gráfico\n  width = 8, # Ancho del gráfico (ajustar según sea necesario)\n  height = 13, # Alto del gráfico (ajustar según sea necesario)\n  units = \"in\", # Unidad para definir el tamaño\n  res = 300, # Resolución de imagen\n  )\n\n# Genero el gráfico (no se visualiza en el panel de Plots)\nforest(\n  mod,\n  smlab = \"Diferencia de medias estandarizada\",\n  col.diamond = \"orange\",\n  col.square = \"turquoise\",\n  leftcols = \"studlab\"\n)\n\n# Guardo el gráfico\ndev.off()\n\nEn la siguiente parte de esta unidad, exploraremos las funciones de meta que permiten ajustar modelos de meta-análisis para distintos estimadores de efecto en epidemiología. Además, abordaremos métodos para controlar la heterogeneidad, tales como el análisis de moderadores y la meta-regresión y aprenderemos qué es y como se mide el sesgo de publicación."
  },
  {
    "objectID": "unidad_2/mod_bias.html",
    "href": "unidad_2/mod_bias.html",
    "title": "Exploración de la heterogeneidad",
    "section": "",
    "text": "El análisis de moderadores permite explorar fuentes de heterogeneidad entre los estudios incluidos en un meta-análisis. Se puede realizar mediante la inclusión de una variable independiente categórica (análisis de subgrupos) o numérica (metarregresión).\nEste procedimiento contribuye a evaluar hipótesis sobre variaciones en la magnitud del efecto entre estudios y a interpretar diferencias observadas en los resultados. Sin embargo, para evitar sesgos de selección, las variables utilizadas como moderadores deben definirse de antemano, durante la extracción de datos relevantes para la revisión sistemática.\nEl análisis de moderadores consta de dos etapas:\n\nEstimación del efecto dentro de cada subgrupo.\nPrueba estadística para evaluar diferencias entre subgrupos.\n\n\nPara evaluar el efecto de una variable categórica, se puede utilizar el argumento subgroup al ajustar un modelo de meta-análisis. A continuación, realizaremos un análisis de subgrupos sobre el modelo de prevalencia ajustado previamente, considerando el país (country) como moderador.\nComenzaremos cargando los paquetes necesarios:\n\n# Carga de paquetes\nlibrary(meta)       # Modelos de meta-análisis\nlibrary(scico)      # Paletas de colores accesibles\nlibrary(janitor)    # Tablas de frecuencia\nlibrary(tidyverse)  # Manejo de datos\n\n# Paleta colorblind-friendly\npal &lt;- scico(n = 4, palette = \"buda\")\n\nCargamos los datos y exploramos su estructura:\n\n# Cargar datos\ndatos_prev &lt;- dat.crisafulli2020\n\n# Inspeccionar estructura de los datos\nglimpse(datos_prev)\n\nRows: 26\nColumns: 7\n$ study   &lt;chr&gt; \"Brooks (1977)\", \"Danieli (1977)\", \"Takeshita (1977)\", \"Drummo…\n$ pubyear &lt;int&gt; 1977, 1977, 1977, 1979, 1980, 1980, 1981, 1982, 1983, 1983, 19…\n$ country &lt;fct&gt; UK, IT, JP, NZ, AU, IT, IT, CA, FR, IT, DE, IT, JP, CA, NO, IT…\n$ from    &lt;int&gt; 1953, 1952, 1956, NA, 1960, 1952, 1955, 1950, 1978, 1969, 1977…\n$ to      &lt;int&gt; 1968, 1972, 1970, NA, 1971, 1972, 1974, 1979, 1978, 1980, 1984…\n$ cases   &lt;int&gt; 47, 66, 19, 2, 99, 105, 73, 110, 12, 156, 48, 76, 50, 5, 16, 2…\n$ total   &lt;int&gt; 177413, 234396, 91157, 10000, 532302, 371698, 301283, 420374, …\n\n\nUsaremos la función tabyl() del paquete janitor (Firke 2024) para generar una tabla de frecuencias de los niveles de la variable country:\n\ntabyl(datos_prev, country) |&gt;   # Genera tabla de frecuencia\n  arrange(-n) |&gt;                # Ordena por frecuencia\n  adorn_pct_formatting()        # Proporciones a porcentajes\n\n country n percent\n      IT 6   23.1%\n      CA 3   11.5%\n      UK 3   11.5%\n      JP 2    7.7%\n      AU 1    3.8%\n      BE 1    3.8%\n      CY 1    3.8%\n      DE 1    3.8%\n      DK 1    3.8%\n      EE 1    3.8%\n      FR 1    3.8%\n      NL 1    3.8%\n      NO 1    3.8%\n      NZ 1    3.8%\n      SI 1    3.8%\n      US 1    3.8%\n\n\nDado que la mayoría de los estudios provienen de Italia y la frecuencia en otros países es baja, creamos una variable dicotómica pais_cat:\n\ndatos_prev &lt;- datos_prev |&gt; \n  mutate(pais_cat = if_else(\n    country  == \"IT\", # Condición\n    \"Italia\",         # Valor si la condición se cumple\n    \"Otro/s\" )        # Valor si la condición no se cumple\n  )\n\nAjustamos el modelo de meta-análisis para proporciones, incorporando la variable pais_cat como moderador:\n\n# Ajuste modelo\nmod_sg &lt;- metaprop(\n  event = cases,          # Casos observados\n  n = total,              # Tamaño de la muestra\n  studlab = study,        # Identificador del estudio\n  data = datos_prev,      # Conjunto de datos\n  sm = \"PLOGIT\",          # Transformación logit\n  common = FALSE,         # Omitir modelo de efectos fijos\n  random = TRUE,          # Modelo de efectos aleatorios\n  pscale = 100000,        # Escala a casos/100 000 habitantes\n  subgroup = pais_cat     # Moderador categórico\n)\n\n# Resumen del modelo ajustado\nmod_sg\n\nNumber of studies: k = 26\nNumber of observations: o = 6831388\nNumber of events: e = 1545\n\n                      events             95%-CI\nRandom effects model 22.2342 [20.6056; 23.9915]\n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.0126; tau = 0.1121; I^2 = 33.2% [0.0%; 58.6%]; H = 1.22 [1.00; 1.55]\n\nTest of heterogeneity:\n          Q d.f. p-value\n Wald 37.41   25  0.0527\n LRT  39.01   25  0.0368\n\nResults for subgroups (random effects model):\n                    k  events             95%-CI  tau^2    tau     Q   I^2\npais_cat = Otro/s  20 20.9400 [19.0685; 22.9951] 0.0122 0.1104 26.02 27.0%\npais_cat = Italia   6 25.0380 [22.5505; 27.7999] 0.0033 0.0577  5.97 16.2%\n\nTest for subgroup differences (random effects model):\n                  Q d.f. p-value\nBetween groups 6.22    1  0.0126\n\nDetails of meta-analysis methods:\n- Random intercept logistic regression model\n- Maximum-likelihood estimator for tau^2\n- Calculation of I^2 based on Q\n- Logit transformation\n- Events per 100000 observations\n\n\nLa salida del modelo incluye dos secciones adicionales:\n\n\nResults for subgroups (random effects model): muestra los resultados para cada categoría del moderador, incluyendo:\n\nIdentificador de las categorías del moderador.\nk: número de estudios en la categoría/subgrupo.\nevents: prevalencia en la categoría/subgrupo.\n95%-CI: intervalo de confianza al 95% para la prevalencia en la categoría/subgrupo.\ntau^2: varianza dentro de la categoría/subgrupo.\ntau: desvío estándar en la categoría/subgrupo.\nQ: estadístico Q de Cochran para la categoría/subgrupo.\nI^2: porcentaje de heterogeneidad observado en la categoría/subgrupo.\n\n\nTest for subgroup differences (random effects model): prueba de hipótesis para detectar diferencias significativas entre subgrupos.\n\nEn este ejemplo, observamos una prevalencia significativamente mayor en Italia en comparación con otros países \\((p = 0,013)\\).\nPodemos visualizar los resultados del análisis de moderadores incorporando los siguiente argumentos a la función forest():\n\nlayout = \"subgroup\": muestra los estimadores de efecto para cada subgrupo y el estimador global, omitiendo los resultados de los estudios individuales.\nsort.subgroup: ordena alfabeticamente las categorías de la variable moderadora.\ncalcwidth.subgroup: ajusta el ancho del forest plot para que se muestren correctamente las etiquetas de las categorías/subgrupos.\ncalcwidth.tests: ajusta el ancho del forest plot para que se muestren correctamente las etiquetas del test de hipótesis de diferencias en las categorías/subgrupos.\nprint.subgroup.name: muestra la etiqueta de la variable moderadora delante de cada categoría (TRUE, por defecto) o lo oculta (FALSE).\nlabel.test.subgroup.common: etiqueta para los resultados del test para diferencias entre subgrupos en el modelo de efectos fijos.\nlabel.test.subgroup.random: etiqueta para los resultados del test para diferencias entre subgrupos en el modelo de efectos aleatorios.\n\nEn nuestro ejemplo:\n\nforest(\n  mod_sg,\n  layout = \"subgroup\",\n  sort.subgroup = TRUE,\n  calcwidth.subgroup = TRUE,\n  calcwidth.tests = TRUE,\n  print.subgroup.name = FALSE,\n  smlab = \"Prevalencia \\n (por 100 000 hab.)\",\n  rightlabs = c(\"Eventos\", \"95% IC\"),\n  hetlab = \"Heterogeneidad: \",\n  text.random = \"Modelo de efectos aleatorios\", \n  label.test.subgroup.random = \"Diferencias entre subgrupos\"\n)\n\n\n\n\n\n\n\nA diferencia de modelos sin moderadores, col.diamond modifica el color del estimador global y de los estimadores para cada subgrupo. En cambio, col.square no tiene efecto sobre los colores del forest plot.\n\nPara evaluar el efecto de una variable continua, como el año de publicación (pubyear), primero ajustamos el modelo de meta-análisis:\n\n# Ajuste modelo\nmod_prev &lt;- metaprop(\n  event = cases,          # Casos observados\n  n = total,              # Tamaño de la muestra\n  studlab = study,        # Identificador del estudio\n  data = datos_prev,      # Conjunto de datos\n  sm = \"PLOGIT\",          # Transformación logit\n  common = FALSE,         # Omitir modelo de efectos fijos\n  random = TRUE,          # Modelo de efectos aleatorios\n  pscale = 100000,        # Escala a casos/100 000 habitantes\n )\n\nAl modelo anterior le aplicamos la función metareg(), incluyendo pubyear como moderador en el argumento formula:\n\n# Ajustar modelo de metarregresión\nmod_year &lt;- metareg(mod_prev,\n                    formula = ~ pubyear)\n\n# Resumen del modelo ajustado\nsummary(mod_year)\n\n\nMixed-Effects Model (k = 26; tau^2 estimator: ML)\n\n  logLik  deviance       AIC       BIC      AICc   \n-75.9315   14.5514  157.8629  161.6372  158.9538   \n\ntau^2 (estimated amount of residual heterogeneity):     0.0067\ntau (square root of estimated tau^2 value):             0.0816\nI^2 (residual heterogeneity / unaccounted variability): 26.61%\nH^2 (unaccounted variability / sampling variability):   1.36\n\nTests for Residual Heterogeneity:\nWld(df = 24) = 28.8391, p-val = 0.2262\nLRT(df = 24) = 30.5162, p-val = 0.1682\n\nTest of Moderators (coefficient 2):\nQM(df = 1) = 7.1208, p-val = 0.0076\n\nModel Results:\n\n         estimate      se     zval    pval    ci.lb    ci.ub     \nintrcpt    8.5560  6.3550   1.3463  0.1782  -3.8996  21.0116     \npubyear   -0.0085  0.0032  -2.6685  0.0076  -0.0148  -0.0023  ** \n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nLos resultados muestran un efecto estadísticamente significativo del año de publicación sobre la prevalencia del evento \\((p = 0,008)\\).\nLos resultados de la metarregresión se visualizan usando bubble plots. Estos gráficos representan en el eje \\(X\\) el valor del moderador continuo y en el eje \\(Y\\) el efecto estimado para cada estudio. Cada burbuja representa un estudio individual, y su tamaño es proporcional al peso del estudio (generalmente inversamente proporcional a la varianza). Además, el gráfico incluye una línea de regresión con su intervalo de confianza del 95%, permitiendo visualizar la tendencia general.\nLa función bubble() genera este gráfico de forma rápida:\n\nbubble(\n  mod_year,\n  cex = \"common\",        # Escala de los símbolos\n  col.line = pal[2]      # Color de la línea de regresión\n)\n\n\n\n\n\n\n\nPara ajustar el tamaño de las burbujas según el peso de cada estudio, se puede modificar el argumento cex utilizando la función rescale() del paquete plotrix:\n\nbubble(\n  mod_year,\n  cex = plotrix::rescale(\n    x = 1 / mod_year$vi,\n    newrange = c(0.5, 3)),  # Ajusta la escala de los símbolos\n    col.line = pal[2]\n)\n\n\n\n\n\n\n\n\nEste contenido es opcional y está dirigido a quienes tengan conocimientos más avanzados de R y deseen generar visualizaciones más atractivas y listas para la presentación en informes o artículos científicos.\nEl paquete orchaRd (Nakagawa et al. 2023) permite crear visualizaciones con mayores opciones de personalización y compatibles con ggplot2. Sin embargo, dado que orchaRd no permite utilizar modelos ajustados por el paquete meta, es necesario reajustar el modelo utilizando metafor.\nCargamos los paquetes requeridos:\n\n# Carga paquetes\nlibrary(orchaRd)\nlibrary(metafor)\n\nCalculamos los estimadores de efecto individuales utilizando la función escalc():\n\ndat_forest &lt;- escalc(\n  measure = \"PLO\",     # estimador de efecto\n  xi = cases,          # número de casos\n  ni = total,          # tamaño muestral\n  data = datos_prev    # conjunto de datos\n  )  \n\nAjustamos el modelo de meta-análisis con moderadores utilizando rma.mv():\n\nmod_forest &lt;- rma.mv(\n  yi = yi,                             # estimador de efecto\n  V = vi,                              # error estándar\n  mods = ~ factor(pais_cat) + pubyear, # moderadores\n  random = ~ 1|study,                  # modelo de efectos aleatorios\n  data = dat_forest                    # conjunto de datos\n)\n\nGeneramos el forest plot con la función orchard_plot(), definiendo los siguientes argumentos:\n\ngroup: identificador de estudio.\nmod: nombre del moderador (1 para estimador de efecto global).\nxlab: nombre del estimador de efecto.\ntransf: mostrar los datos en escala original (opcional).\n\n\n# Forest plot por subgrupos\norchard_plot(\n  mod_forest, \n  group = \"study\",\n  mod = \"pais_cat\",\n  xlab = \"prevalencia\",\n  transfm = \"invlogit\"\n  ) +\n  # Paleta personalizada\n  scale_color_manual(values = pal) +  # color de borde\n  scale_fill_manual(values = pal)     # color de relleno\n\n\n\n\n\n\n\nCon el argumento scale_fill_scico_d() podemos usar cualquiera de las paletas colorblind-friendly incluidas en scico:\n\n# Forest plot por subgrupos\norchard_plot(\n  mod_forest, \n  group = \"study\",\n  mod = \"pais_cat\",\n  xlab = \"prevalencia\",\n  transfm = \"invlogit\"\n  ) +\n  # Paleta colorblind-friendly\n  scale_color_scico_d(palette = \"hawaii\") + # color de borde\n  scale_fill_scico_d(palette = \"hawaii\")    # color de relleno\n\n\n\n\n\n\n\nGeneramos el bubble plot para el moderador continuo (pubyear):\n\nbubble_plot(\n  mod_forest,           # modelo ajustado con metafor\n  transfm = \"invlogit\", # muestra resultados como proporciones\n  mod = \"pubyear\",      # moderador continuo\n  group = \"study\",      # identificador de estudio\n  est.col = pal[2],     # color de la línea de regresión\n  ci.col = pal[1],      # color de las líneas del 95% IC\n  ) \n\n\n\n\n\n\n\nSi quisiera generar un bubble plot para cada nivel de pais_cat, puedo usar el argumento by:\n\nbubble_plot(\n  mod_forest,           # modelo ajustado con metafor\n  transfm = \"invlogit\", # muestra resultados como proporciones\n  mod = \"pubyear\",      # moderador continuo\n  group = \"study\",      # identificador de estudio\n  est.col = pal[2],     # color de la línea de regresión\n  ci.col = pal[1],      # color de las líneas del 95% IC\n  by = \"pais_cat\"\n  ) +\n  \n  # Paleta colorblind-friendly\n  scale_color_scico_d(palette = \"glasgow\") + # color de borde\n  scale_fill_scico_d(palette = \"glasgow\")    # color de relleno"
  },
  {
    "objectID": "unidad_2/mod_bias.html#análisis-de-moderadores",
    "href": "unidad_2/mod_bias.html#análisis-de-moderadores",
    "title": "Exploración de la heterogeneidad",
    "section": "",
    "text": "El análisis de moderadores permite explorar fuentes de heterogeneidad entre los estudios incluidos en un meta-análisis. Se puede realizar mediante la inclusión de una variable independiente categórica (análisis de subgrupos) o numérica (metarregresión).\nEste procedimiento contribuye a evaluar hipótesis sobre variaciones en la magnitud del efecto entre estudios y a interpretar diferencias observadas en los resultados. Sin embargo, para evitar sesgos de selección, las variables utilizadas como moderadores deben definirse de antemano, durante la extracción de datos relevantes para la revisión sistemática.\nEl análisis de moderadores consta de dos etapas:\n\nEstimación del efecto dentro de cada subgrupo.\nPrueba estadística para evaluar diferencias entre subgrupos.\n\n\nPara evaluar el efecto de una variable categórica, se puede utilizar el argumento subgroup al ajustar un modelo de meta-análisis. A continuación, realizaremos un análisis de subgrupos sobre el modelo de prevalencia ajustado previamente, considerando el país (country) como moderador.\nComenzaremos cargando los paquetes necesarios:\n\n# Carga de paquetes\nlibrary(meta)       # Modelos de meta-análisis\nlibrary(scico)      # Paletas de colores accesibles\nlibrary(janitor)    # Tablas de frecuencia\nlibrary(tidyverse)  # Manejo de datos\n\n# Paleta colorblind-friendly\npal &lt;- scico(n = 4, palette = \"buda\")\n\nCargamos los datos y exploramos su estructura:\n\n# Cargar datos\ndatos_prev &lt;- dat.crisafulli2020\n\n# Inspeccionar estructura de los datos\nglimpse(datos_prev)\n\nRows: 26\nColumns: 7\n$ study   &lt;chr&gt; \"Brooks (1977)\", \"Danieli (1977)\", \"Takeshita (1977)\", \"Drummo…\n$ pubyear &lt;int&gt; 1977, 1977, 1977, 1979, 1980, 1980, 1981, 1982, 1983, 1983, 19…\n$ country &lt;fct&gt; UK, IT, JP, NZ, AU, IT, IT, CA, FR, IT, DE, IT, JP, CA, NO, IT…\n$ from    &lt;int&gt; 1953, 1952, 1956, NA, 1960, 1952, 1955, 1950, 1978, 1969, 1977…\n$ to      &lt;int&gt; 1968, 1972, 1970, NA, 1971, 1972, 1974, 1979, 1978, 1980, 1984…\n$ cases   &lt;int&gt; 47, 66, 19, 2, 99, 105, 73, 110, 12, 156, 48, 76, 50, 5, 16, 2…\n$ total   &lt;int&gt; 177413, 234396, 91157, 10000, 532302, 371698, 301283, 420374, …\n\n\nUsaremos la función tabyl() del paquete janitor (Firke 2024) para generar una tabla de frecuencias de los niveles de la variable country:\n\ntabyl(datos_prev, country) |&gt;   # Genera tabla de frecuencia\n  arrange(-n) |&gt;                # Ordena por frecuencia\n  adorn_pct_formatting()        # Proporciones a porcentajes\n\n country n percent\n      IT 6   23.1%\n      CA 3   11.5%\n      UK 3   11.5%\n      JP 2    7.7%\n      AU 1    3.8%\n      BE 1    3.8%\n      CY 1    3.8%\n      DE 1    3.8%\n      DK 1    3.8%\n      EE 1    3.8%\n      FR 1    3.8%\n      NL 1    3.8%\n      NO 1    3.8%\n      NZ 1    3.8%\n      SI 1    3.8%\n      US 1    3.8%\n\n\nDado que la mayoría de los estudios provienen de Italia y la frecuencia en otros países es baja, creamos una variable dicotómica pais_cat:\n\ndatos_prev &lt;- datos_prev |&gt; \n  mutate(pais_cat = if_else(\n    country  == \"IT\", # Condición\n    \"Italia\",         # Valor si la condición se cumple\n    \"Otro/s\" )        # Valor si la condición no se cumple\n  )\n\nAjustamos el modelo de meta-análisis para proporciones, incorporando la variable pais_cat como moderador:\n\n# Ajuste modelo\nmod_sg &lt;- metaprop(\n  event = cases,          # Casos observados\n  n = total,              # Tamaño de la muestra\n  studlab = study,        # Identificador del estudio\n  data = datos_prev,      # Conjunto de datos\n  sm = \"PLOGIT\",          # Transformación logit\n  common = FALSE,         # Omitir modelo de efectos fijos\n  random = TRUE,          # Modelo de efectos aleatorios\n  pscale = 100000,        # Escala a casos/100 000 habitantes\n  subgroup = pais_cat     # Moderador categórico\n)\n\n# Resumen del modelo ajustado\nmod_sg\n\nNumber of studies: k = 26\nNumber of observations: o = 6831388\nNumber of events: e = 1545\n\n                      events             95%-CI\nRandom effects model 22.2342 [20.6056; 23.9915]\n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.0126; tau = 0.1121; I^2 = 33.2% [0.0%; 58.6%]; H = 1.22 [1.00; 1.55]\n\nTest of heterogeneity:\n          Q d.f. p-value\n Wald 37.41   25  0.0527\n LRT  39.01   25  0.0368\n\nResults for subgroups (random effects model):\n                    k  events             95%-CI  tau^2    tau     Q   I^2\npais_cat = Otro/s  20 20.9400 [19.0685; 22.9951] 0.0122 0.1104 26.02 27.0%\npais_cat = Italia   6 25.0380 [22.5505; 27.7999] 0.0033 0.0577  5.97 16.2%\n\nTest for subgroup differences (random effects model):\n                  Q d.f. p-value\nBetween groups 6.22    1  0.0126\n\nDetails of meta-analysis methods:\n- Random intercept logistic regression model\n- Maximum-likelihood estimator for tau^2\n- Calculation of I^2 based on Q\n- Logit transformation\n- Events per 100000 observations\n\n\nLa salida del modelo incluye dos secciones adicionales:\n\n\nResults for subgroups (random effects model): muestra los resultados para cada categoría del moderador, incluyendo:\n\nIdentificador de las categorías del moderador.\nk: número de estudios en la categoría/subgrupo.\nevents: prevalencia en la categoría/subgrupo.\n95%-CI: intervalo de confianza al 95% para la prevalencia en la categoría/subgrupo.\ntau^2: varianza dentro de la categoría/subgrupo.\ntau: desvío estándar en la categoría/subgrupo.\nQ: estadístico Q de Cochran para la categoría/subgrupo.\nI^2: porcentaje de heterogeneidad observado en la categoría/subgrupo.\n\n\nTest for subgroup differences (random effects model): prueba de hipótesis para detectar diferencias significativas entre subgrupos.\n\nEn este ejemplo, observamos una prevalencia significativamente mayor en Italia en comparación con otros países \\((p = 0,013)\\).\nPodemos visualizar los resultados del análisis de moderadores incorporando los siguiente argumentos a la función forest():\n\nlayout = \"subgroup\": muestra los estimadores de efecto para cada subgrupo y el estimador global, omitiendo los resultados de los estudios individuales.\nsort.subgroup: ordena alfabeticamente las categorías de la variable moderadora.\ncalcwidth.subgroup: ajusta el ancho del forest plot para que se muestren correctamente las etiquetas de las categorías/subgrupos.\ncalcwidth.tests: ajusta el ancho del forest plot para que se muestren correctamente las etiquetas del test de hipótesis de diferencias en las categorías/subgrupos.\nprint.subgroup.name: muestra la etiqueta de la variable moderadora delante de cada categoría (TRUE, por defecto) o lo oculta (FALSE).\nlabel.test.subgroup.common: etiqueta para los resultados del test para diferencias entre subgrupos en el modelo de efectos fijos.\nlabel.test.subgroup.random: etiqueta para los resultados del test para diferencias entre subgrupos en el modelo de efectos aleatorios.\n\nEn nuestro ejemplo:\n\nforest(\n  mod_sg,\n  layout = \"subgroup\",\n  sort.subgroup = TRUE,\n  calcwidth.subgroup = TRUE,\n  calcwidth.tests = TRUE,\n  print.subgroup.name = FALSE,\n  smlab = \"Prevalencia \\n (por 100 000 hab.)\",\n  rightlabs = c(\"Eventos\", \"95% IC\"),\n  hetlab = \"Heterogeneidad: \",\n  text.random = \"Modelo de efectos aleatorios\", \n  label.test.subgroup.random = \"Diferencias entre subgrupos\"\n)\n\n\n\n\n\n\n\nA diferencia de modelos sin moderadores, col.diamond modifica el color del estimador global y de los estimadores para cada subgrupo. En cambio, col.square no tiene efecto sobre los colores del forest plot.\n\nPara evaluar el efecto de una variable continua, como el año de publicación (pubyear), primero ajustamos el modelo de meta-análisis:\n\n# Ajuste modelo\nmod_prev &lt;- metaprop(\n  event = cases,          # Casos observados\n  n = total,              # Tamaño de la muestra\n  studlab = study,        # Identificador del estudio\n  data = datos_prev,      # Conjunto de datos\n  sm = \"PLOGIT\",          # Transformación logit\n  common = FALSE,         # Omitir modelo de efectos fijos\n  random = TRUE,          # Modelo de efectos aleatorios\n  pscale = 100000,        # Escala a casos/100 000 habitantes\n )\n\nAl modelo anterior le aplicamos la función metareg(), incluyendo pubyear como moderador en el argumento formula:\n\n# Ajustar modelo de metarregresión\nmod_year &lt;- metareg(mod_prev,\n                    formula = ~ pubyear)\n\n# Resumen del modelo ajustado\nsummary(mod_year)\n\n\nMixed-Effects Model (k = 26; tau^2 estimator: ML)\n\n  logLik  deviance       AIC       BIC      AICc   \n-75.9315   14.5514  157.8629  161.6372  158.9538   \n\ntau^2 (estimated amount of residual heterogeneity):     0.0067\ntau (square root of estimated tau^2 value):             0.0816\nI^2 (residual heterogeneity / unaccounted variability): 26.61%\nH^2 (unaccounted variability / sampling variability):   1.36\n\nTests for Residual Heterogeneity:\nWld(df = 24) = 28.8391, p-val = 0.2262\nLRT(df = 24) = 30.5162, p-val = 0.1682\n\nTest of Moderators (coefficient 2):\nQM(df = 1) = 7.1208, p-val = 0.0076\n\nModel Results:\n\n         estimate      se     zval    pval    ci.lb    ci.ub     \nintrcpt    8.5560  6.3550   1.3463  0.1782  -3.8996  21.0116     \npubyear   -0.0085  0.0032  -2.6685  0.0076  -0.0148  -0.0023  ** \n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nLos resultados muestran un efecto estadísticamente significativo del año de publicación sobre la prevalencia del evento \\((p = 0,008)\\).\nLos resultados de la metarregresión se visualizan usando bubble plots. Estos gráficos representan en el eje \\(X\\) el valor del moderador continuo y en el eje \\(Y\\) el efecto estimado para cada estudio. Cada burbuja representa un estudio individual, y su tamaño es proporcional al peso del estudio (generalmente inversamente proporcional a la varianza). Además, el gráfico incluye una línea de regresión con su intervalo de confianza del 95%, permitiendo visualizar la tendencia general.\nLa función bubble() genera este gráfico de forma rápida:\n\nbubble(\n  mod_year,\n  cex = \"common\",        # Escala de los símbolos\n  col.line = pal[2]      # Color de la línea de regresión\n)\n\n\n\n\n\n\n\nPara ajustar el tamaño de las burbujas según el peso de cada estudio, se puede modificar el argumento cex utilizando la función rescale() del paquete plotrix:\n\nbubble(\n  mod_year,\n  cex = plotrix::rescale(\n    x = 1 / mod_year$vi,\n    newrange = c(0.5, 3)),  # Ajusta la escala de los símbolos\n    col.line = pal[2]\n)\n\n\n\n\n\n\n\n\nEste contenido es opcional y está dirigido a quienes tengan conocimientos más avanzados de R y deseen generar visualizaciones más atractivas y listas para la presentación en informes o artículos científicos.\nEl paquete orchaRd (Nakagawa et al. 2023) permite crear visualizaciones con mayores opciones de personalización y compatibles con ggplot2. Sin embargo, dado que orchaRd no permite utilizar modelos ajustados por el paquete meta, es necesario reajustar el modelo utilizando metafor.\nCargamos los paquetes requeridos:\n\n# Carga paquetes\nlibrary(orchaRd)\nlibrary(metafor)\n\nCalculamos los estimadores de efecto individuales utilizando la función escalc():\n\ndat_forest &lt;- escalc(\n  measure = \"PLO\",     # estimador de efecto\n  xi = cases,          # número de casos\n  ni = total,          # tamaño muestral\n  data = datos_prev    # conjunto de datos\n  )  \n\nAjustamos el modelo de meta-análisis con moderadores utilizando rma.mv():\n\nmod_forest &lt;- rma.mv(\n  yi = yi,                             # estimador de efecto\n  V = vi,                              # error estándar\n  mods = ~ factor(pais_cat) + pubyear, # moderadores\n  random = ~ 1|study,                  # modelo de efectos aleatorios\n  data = dat_forest                    # conjunto de datos\n)\n\nGeneramos el forest plot con la función orchard_plot(), definiendo los siguientes argumentos:\n\ngroup: identificador de estudio.\nmod: nombre del moderador (1 para estimador de efecto global).\nxlab: nombre del estimador de efecto.\ntransf: mostrar los datos en escala original (opcional).\n\n\n# Forest plot por subgrupos\norchard_plot(\n  mod_forest, \n  group = \"study\",\n  mod = \"pais_cat\",\n  xlab = \"prevalencia\",\n  transfm = \"invlogit\"\n  ) +\n  # Paleta personalizada\n  scale_color_manual(values = pal) +  # color de borde\n  scale_fill_manual(values = pal)     # color de relleno\n\n\n\n\n\n\n\nCon el argumento scale_fill_scico_d() podemos usar cualquiera de las paletas colorblind-friendly incluidas en scico:\n\n# Forest plot por subgrupos\norchard_plot(\n  mod_forest, \n  group = \"study\",\n  mod = \"pais_cat\",\n  xlab = \"prevalencia\",\n  transfm = \"invlogit\"\n  ) +\n  # Paleta colorblind-friendly\n  scale_color_scico_d(palette = \"hawaii\") + # color de borde\n  scale_fill_scico_d(palette = \"hawaii\")    # color de relleno\n\n\n\n\n\n\n\nGeneramos el bubble plot para el moderador continuo (pubyear):\n\nbubble_plot(\n  mod_forest,           # modelo ajustado con metafor\n  transfm = \"invlogit\", # muestra resultados como proporciones\n  mod = \"pubyear\",      # moderador continuo\n  group = \"study\",      # identificador de estudio\n  est.col = pal[2],     # color de la línea de regresión\n  ci.col = pal[1],      # color de las líneas del 95% IC\n  ) \n\n\n\n\n\n\n\nSi quisiera generar un bubble plot para cada nivel de pais_cat, puedo usar el argumento by:\n\nbubble_plot(\n  mod_forest,           # modelo ajustado con metafor\n  transfm = \"invlogit\", # muestra resultados como proporciones\n  mod = \"pubyear\",      # moderador continuo\n  group = \"study\",      # identificador de estudio\n  est.col = pal[2],     # color de la línea de regresión\n  ci.col = pal[1],      # color de las líneas del 95% IC\n  by = \"pais_cat\"\n  ) +\n  \n  # Paleta colorblind-friendly\n  scale_color_scico_d(palette = \"glasgow\") + # color de borde\n  scale_fill_scico_d(palette = \"glasgow\")    # color de relleno"
  },
  {
    "objectID": "unidad_2/mod_bias.html#sesgo-de-publicación-y-análisis-de-sensibilidad",
    "href": "unidad_2/mod_bias.html#sesgo-de-publicación-y-análisis-de-sensibilidad",
    "title": "Exploración de la heterogeneidad",
    "section": "Sesgo de publicación y análisis de sensibilidad",
    "text": "Sesgo de publicación y análisis de sensibilidad\nEl sesgo de publicación (publication bias) se refiere a la tendencia de publicar con mayor frecuencia estudios con resultados positivos, estadísticamente significativos o con grandes tamaños del efecto. Esto puede distorsionar la síntesis de la evidencia en un meta-análisis, produciendo una sobreestimación del efecto global. Por ello, es esencial evaluar y ajustar el sesgo de publicación para garantizar que los resultados sean lo más precisos y representativos posible.\nFunnel plot\nEl funnel plot o gráfico de embudo representa en el eje \\(Y\\) el tamaño muestral o la precisión de los estudios, y en el eje \\(X\\) el estimador de efecto para cada estudio. En ausencia de sesgo de publicación, se espera una distribución simétrica que forme un patrón similar a un embudo; de lo contrario, se observa asimetría.\nPara generar un funnel plot, se utiliza la función funnel():\n\nfunnel(mod_prev)\n\n\n\n\n\n\n\nTest de Egger\nEl test de Egger evalúa la simetría del funnel plot mediante una regresión lineal entre el estimador de efecto y su error estándar. Un p-valor menor a 0,05 sugiere la presencia de sesgo de publicación.\nEste test se implementa con la función metabias():\n\nmetabias(\n  mod_prev,               # modelo de meta-análisis\n  method.bias = \"Egger\"   # aplica test de Egger (opción por defecto)\n  )\n\nLinear regression test of funnel plot asymmetry\n\nTest result: t = -1.45, df = 24, p-value = 0.1603\nBias estimate: -0.6649 (SE = 0.4589)\n\nDetails:\n- multiplicative residual heterogeneity variance (tau^2 = 1.4335)\n- predictor: standard error\n- weight:    inverse variance\n- reference: Egger et al. (1997), BMJ\n\n\nTest de Begg\nEl test de Begg utiliza la correlación de rangos para evaluar la relación entre el tamaño del efecto y el error estándar. Un p-valor menor que 0,05 indica la presencia de sesgo de publicación.\nSe implementa añadiendo el argumento method.bias = \"Begg\" a la función metabias():\n\nmetabias(\n  mod_prev,             # modelo de meta-análisis\n  method.bias = \"Begg\"  # aplica test de Begg\n  )\n\nRank correlation test of funnel plot asymmetry\n\nTest result: z = -0.90, p-value = 0.3662\nBias estimate: -41.0000 (SE = 45.3689)\n\nReference: Begg & Mazumdar (1993), Biometrics\n\n\nTrim-and-fill\nEl método trim-and-fill estima el número de estudios faltantes debido al sesgo de publicación y ajusta la media global en consecuencia, incorporando estudios hipotéticos. Esto ayuda a corregir la estimación del efecto global.\nSe utiliza la función trimfill():\n\ntrimfill(mod_prev)\n\nNumber of studies: k = 32 (with 6 added studies)\n\n                      events             95%-CI\nRandom effects model 23.4496 [21.7062; 25.3329]\n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.0181; tau = 0.1344; I^2 = 42.4% [12.2%; 62.2%]; H = 1.32 [1.07; 1.63]\n\nTest of heterogeneity:\n     Q d.f. p-value\n 53.82   31  0.0067\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Maximum-likelihood estimator for tau^2\n- Calculation of I^2 based on Q\n- Trim-and-fill method to adjust for funnel plot asymmetry (L-estimator)\n- Logit transformation\n- Events per 100000 observations\n\n\nGeneralmente, se recomienda utilizar dos o más métodos para evaluar el sesgo de publicación y obtener una visión más completa de su impacto en el meta-análisis. En el ejemplo anterior, no hubiera sido necesario realizar el trim-and-fill ya que el funnel plot tiene una forma bastante simétrica y el p-valor de los test de Egger y Begg fue menor a 0,05.\nAnálisis de sensibilidad\nEl análisis de sensibilidad se utiliza para evaluar la robustez de los resultados del meta-análisis. Una estrategia común es reajustar el modelo excluyendo estudios con menor tamaño muestral o de menor calidad, y comparar el estimador de efecto y su 95% IC con el modelo original. Otra opción es realizar un análisis leave-one-out, en el que se remueve un estudio a la vez y se observa la variación del efecto global.\nLa función metainf() permite realizar el análisis de influencia (leave-one-out):\n\nmetainf(\n  mod_prev,          # modelo de meta-análisis\n  pooled = \"random\"  # modelo de efectos aleatorios\n  )\n\nEste análisis ayuda a determinar si algún estudio en particular influye de forma excesiva en los resultados del meta-análisis. Al igual que en los modelos anteriores, los resultados pueden visualizarse usando forest plots.\n\n\n\n\n\n\nHasta aquí hemos cubierto los aspectos básicos para evaluar fuentes de heterogeneidad en modelos de meta-análisis. Quienes tengan interés en profundizar en las medidas de heterogeneidad y su aplicación, recomendamos consultar el artículo de (Bown y Sutton 2010) y los capítulos 7, 8 y 9 de Harrer et al. (2021)."
  }
]