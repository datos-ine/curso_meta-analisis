[
  {
    "objectID": "unidad_2/04_mod_bias.html",
    "href": "unidad_2/04_mod_bias.html",
    "title": "Exploración de la heterogeneidad",
    "section": "",
    "text": "En la clase anterior abordamos el ajuste de modelos de efectos fijos y aleatorios, la representación gráfica de los resultados mediante forest plots y la estimación de la heterogeneidad estadística. En esta clase, nos enfocaremos en distintas estrategias para controlar la heterogeneidad observada y evaluar la robustez de los modelos ajustados.",
    "crumbs": [
      "Introducción a la Revisión Sistemática con Meta-análisis",
      "Meta-análisis",
      "Exploración de la heterogeneidad"
    ]
  },
  {
    "objectID": "unidad_2/04_mod_bias.html#introducción",
    "href": "unidad_2/04_mod_bias.html#introducción",
    "title": "Exploración de la heterogeneidad",
    "section": "",
    "text": "En la clase anterior abordamos el ajuste de modelos de efectos fijos y aleatorios, la representación gráfica de los resultados mediante forest plots y la estimación de la heterogeneidad estadística. En esta clase, nos enfocaremos en distintas estrategias para controlar la heterogeneidad observada y evaluar la robustez de los modelos ajustados.",
    "crumbs": [
      "Introducción a la Revisión Sistemática con Meta-análisis",
      "Meta-análisis",
      "Exploración de la heterogeneidad"
    ]
  },
  {
    "objectID": "unidad_2/04_mod_bias.html#análisis-de-moderadores",
    "href": "unidad_2/04_mod_bias.html#análisis-de-moderadores",
    "title": "Exploración de la heterogeneidad",
    "section": "Análisis de moderadores",
    "text": "Análisis de moderadores\nEl análisis de moderadores permite explorar fuentes de heterogeneidad entre los estudios incluidos en un meta-análisis. Puede realizarse incorporando como moderador una variable categórica (análisis de subgrupos) o una variable numérica (metarregresión).\nEste enfoque contribuye a:\n\nEvaluar hipótesis sobre variaciones en la magnitud del efecto entre estudios.\nInterpretar diferencias observadas en los resultados.\n\nPara evitar sesgos de selección, es fundamental definir las variables moderadoras durante la extracción de datos en la revisión sistemática.\nEl análisis de moderadores consta de dos etapas:\n\nEstimación del efecto dentro de cada subgrupo.\nPrueba estadística para evaluar diferencias entre subgrupos.\n\n\nAnálisis de sugbgrupos\nPara evaluar el efecto de una variable categórica, ajustamos el modelo de meta-análisis incluyendo el argumento subgroup. En el siguiente ejemplo, realizaremos un análisis de subgrupos a partir del modelo para prevalencia previamente ajustado, utilizando el país (country) como moderador.\nCargamos los paquetes necesarios:\n\n# Cargar paquetes\nlibrary(meta)       # Modelos de meta-análisis\nlibrary(janitor)    # Tablas de frecuencia\nlibrary(tidyverse)  # Manejo de datos\n\nCargamos los datos y exploramos su estructura:\n\n# Cargar datos\ndatos_prev &lt;- dat.crisafulli2020\n\n# Inspeccionar estructura de los datos\nglimpse(datos_prev)\n\nRows: 26\nColumns: 7\n$ study   &lt;chr&gt; \"Brooks (1977)\", \"Danieli (1977)\", \"Takeshita (1977)\", \"Drummo…\n$ pubyear &lt;int&gt; 1977, 1977, 1977, 1979, 1980, 1980, 1981, 1982, 1983, 1983, 19…\n$ country &lt;fct&gt; UK, IT, JP, NZ, AU, IT, IT, CA, FR, IT, DE, IT, JP, CA, NO, IT…\n$ from    &lt;int&gt; 1953, 1952, 1956, NA, 1960, 1952, 1955, 1950, 1978, 1969, 1977…\n$ to      &lt;int&gt; 1968, 1972, 1970, NA, 1971, 1972, 1974, 1979, 1978, 1980, 1984…\n$ cases   &lt;int&gt; 47, 66, 19, 2, 99, 105, 73, 110, 12, 156, 48, 76, 50, 5, 16, 2…\n$ total   &lt;int&gt; 177413, 234396, 91157, 10000, 532302, 371698, 301283, 420374, …\n\n\nUsaremos la función tabyl() del paquete janitor (Firke 2024) para generar una tabla de frecuencias de los niveles de la variable country:\n\ntabyl(datos_prev, country) |&gt;   # Generar tabla de frecuencia\n  arrange(-n) |&gt;                # Ordenar por frecuencia\n  adorn_pct_formatting()        # Proporciones a porcentajes\n\n country n percent\n      IT 6   23.1%\n      CA 3   11.5%\n      UK 3   11.5%\n      JP 2    7.7%\n      AU 1    3.8%\n      BE 1    3.8%\n      CY 1    3.8%\n      DE 1    3.8%\n      DK 1    3.8%\n      EE 1    3.8%\n      FR 1    3.8%\n      NL 1    3.8%\n      NO 1    3.8%\n      NZ 1    3.8%\n      SI 1    3.8%\n      US 1    3.8%\n\n\nComo la mayoría de los estudios provienen de Italia y la frecuencia en otros países es baja, creamos una variable dicotómica pais_cat:\n\ndatos_prev &lt;- datos_prev |&gt; \n  mutate(pais_cat = if_else(\n    country  == \"IT\", # Condición\n    \"Italia\",         # Valor si la condición se cumple\n    \"Otro/s\" ))        # Valor si la condición no se cumple\n\nAjustamos el modelo de meta-análisis para proporciones, incorporando pais_cat como moderador:\n\n# Ajustar modelo\nmod_sg &lt;- metaprop(\n  event = cases,          # Casos observados\n  n = total,              # Tamaño de la muestra\n  studlab = study,        # Identificador del estudio\n  data = datos_prev,      # Conjunto de datos\n  sm = \"PLOGIT\",          # Transformación logit\n  common = FALSE,         # Omitir modelo de efectos fijos\n  random = TRUE,          # Modelo de efectos aleatorios\n  pscale = 100000,        # Escala a casos/100 000 habitantes\n1  subgroup = pais_cat\n)\n\n\n1\n\nModerador categórico\n\n\n\n\n\n# Salida del modelo ajustado\nmod_sg\n\nNumber of studies: k = 26\nNumber of observations: o = 6831388\nNumber of events: e = 1545\n\n                      events             95%-CI\nRandom effects model 22.2342 [20.6056; 23.9915]\n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.0126; tau = 0.1121; I^2 = 33.2% [0.0%; 58.6%]; H = 1.22 [1.00; 1.55]\n\nTest of heterogeneity:\n          Q d.f. p-value\n Wald 37.41   25  0.0527\n LRT  39.01   25  0.0368\n\nResults for subgroups (random effects model):\n                    k  events             95%-CI  tau^2    tau     Q   I^2\npais_cat = Otro/s  20 20.9400 [19.0685; 22.9951] 0.0122 0.1104 26.02 27.0%\npais_cat = Italia   6 25.0380 [22.5505; 27.7999] 0.0033 0.0577  5.97 16.2%\n\nTest for subgroup differences (random effects model):\n                  Q d.f. p-value\nBetween groups 6.22    1  0.0126\n\nDetails of meta-analysis methods:\n- Random intercept logistic regression model\n- Maximum-likelihood estimator for tau^2\n- Calculation of I^2 based on Q\n- Logit transformation\n- Events per 100000 observations\n\n\nLa salida del modelo incluye dos secciones adicionales:\n\nResults for subgroups (random effects model): muestra los resultados para cada categoría del moderador, incluyendo:\n\nIdentificador de las categorías del moderador.\nk: número de estudios en la categoría/subgrupo.\nevents: prevalencia en la categoría/subgrupo.\n95%-CI: intervalo de confianza al 95% para la prevalencia en la categoría/subgrupo.\ntau^2: varianza dentro de la categoría/subgrupo.\ntau: desvío estándar en la categoría/subgrupo.\nQ: estadístico Q de Cochran para la categoría/subgrupo.\nI^2: porcentaje de heterogeneidad observado en la categoría/subgrupo.\n\nTest for subgroup differences (random effects model): prueba de hipótesis para detectar diferencias significativas entre subgrupos.\n\nEn este ejemplo, observamos una prevalencia significativamente mayor en Italia en comparación con otros países \\((p = 0,013)\\).\nPodemos visualizar los resultados del análisis de moderadores incorporando los siguiente argumentos a la función forest():\n\nforest(\n  mod_sg,\n1  layout = \"subgroup\",\n2  sort.subgroup = TRUE,\n3  calcwidth.subgroup = TRUE,\n4  calcwidth.tests = TRUE,\n5  print.subgroup.name = FALSE,\n  smlab = \"Prevalencia \\n (por 100 000 hab.)\",\n  rightlabs = c(\"Eventos\", \"95% IC\"),\n  hetlab = \"Heterogeneidad: \",\n  text.random = \"Modelo de efectos aleatorios\", \n6  label.test.subgroup.random = \"Diferencias entre subgrupos\"\n)\n\n\n1\n\nlayout = \"subgroup\": muestra los estimadores de efecto para cada subgrupo y el estimador global, omitiendo los resultados de los estudios individuales.\n\n2\n\nsort.subgroup: ordena alfabéticamente las categorías de la variable moderadora.\n\n3\n\ncalcwidth.subgroup: ajusta el ancho del forest plot para que se muestren correctamente las etiquetas de las categorías/subgrupos.\n\n4\n\ncalcwidth.tests: ajusta el ancho del forest plot para que se muestren correctamente las etiquetas del test de hipótesis de diferencias en las categorías/subgrupos.\n\n5\n\nprint.subgroup.name: muestra la etiqueta de la variable moderadora delante de cada categoría (TRUE, por defecto) o lo oculta (FALSE).\n\n6\n\nlabel.test.subgroup.random: etiqueta para los resultados del test para diferencias entre subgrupos en el modelo de efectos aleatorios.\n\n\n\n\n\n\n\n\n\n\n\nCuando graficamos un análisis de subgrupos, el argumento col.diamond modifica el color del estimador global y de los estimadores por subgrupo. El argumento col.square no tiene efecto en este caso.\n\n\nMetarregresión\nLa metarregresión evalúa el efecto de una variable continua (por ejemplo, el año de publicación, pubyear) sobre la magnitud del efecto.\n\n# Ajustar modelo\nmod_prev &lt;- metaprop(\n  event = cases,          # Casos observados\n  n = total,              # Tamaño de la muestra\n  studlab = study,        # Identificador del estudio\n  data = datos_prev,      # Conjunto de datos\n  sm = \"PLOGIT\",          # Transformación logit\n  common = FALSE,         # Omitir modelo de efectos fijos\n  random = TRUE,          # Modelo de efectos aleatorios\n  pscale = 100000,        # Escala a casos/100 000 habitantes\n )\n\nAl modelo anterior le aplicamos la función metareg(), incluyendo pubyear como moderador en el argumento formula:\n\n# Ajustar modelo de metarregresión\nmod_year &lt;- metareg(mod_prev,\n                    formula = ~ pubyear)\n\n# Resumen del modelo ajustado\nsummary(mod_year)\n\n\nMixed-Effects Model (k = 26; tau^2 estimator: ML)\n\n  logLik  deviance       AIC       BIC      AICc   \n-75.9315   14.5514  157.8629  161.6372  158.9538   \n\ntau^2 (estimated amount of residual heterogeneity):     0.0067\ntau (square root of estimated tau^2 value):             0.0816\nI^2 (residual heterogeneity / unaccounted variability): 26.61%\nH^2 (unaccounted variability / sampling variability):   1.36\n\nTests for Residual Heterogeneity:\nWld(df = 24) = 28.8391, p-val = 0.2262\nLRT(df = 24) = 30.5162, p-val = 0.1682\n\nTest of Moderators (coefficient 2):\nQM(df = 1) = 7.1208, p-val = 0.0076\n\nModel Results:\n\n         estimate      se     zval    pval    ci.lb    ci.ub     \nintrcpt    8.5560  6.3550   1.3463  0.1782  -3.8996  21.0116     \npubyear   -0.0085  0.0032  -2.6685  0.0076  -0.0148  -0.0023  ** \n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nLos resultados muestran un efecto estadísticamente significativo del año de publicación sobre la prevalencia del evento \\((p = 0,008)\\).\n\nBubble plots\nLos resultados de la metarregresión se visualizan usando bubble plots. Estos gráficos representan en el eje \\(X\\) el valor del moderador continuo y en el eje \\(Y\\) el efecto estimado para cada estudio. Cada burbuja representa un estudio individual, y su tamaño es proporcional al peso del estudio (generalmente inversamente proporcional a la varianza). Además, el gráfico incluye una línea de regresión con su intervalo de confianza del 95%, permitiendo visualizar la tendencia general.\nLa función bubble() genera este gráfico de forma rápida:\n\nbubble(\n1  mod_year,\n2  cex = \"common\",\n3  col.line = pal[2]\n)\n\n\n1\n\nModelo de meta-análisis.\n\n2\n\nTamaño de las burbujas.\n\n3\n\nColor para la línea de regresión.\n\n\n\n\n\n\n\n\n\n\n\nPara ajustar el tamaño de las burbujas según el peso de cada estudio usaremos la función rescale() del paquete plotrix:\n\n# Peso de cada estudio\nwt &lt;- plotrix::rescale(\n    x = 1 / mod_year$vi,\n    newrange = c(0.5, 3))\n\nPara ajustar el tamaño de las burbujas según el peso de cada estudio, se puede modificar el argumento cex utilizando la función rescale() del paquete plotrix:\n\nbubble(\n  mod_year,\n  cex = wt,  # Ajusta la escala de los símbolos\n  col.line = pal[2]\n)\n\n\n\n\n\n\n\n\n\n\n\nVisualización avanzada con paquete orchaRd\nEste contenido es opcional y está dirigido a personas con conocimientos más avanzados en R que deseen crear visualizaciones personalizables y listas para presentación en informes o publicaciones científicas.\nEl paquete orchaRd (Nakagawa et al. 2023) permite crear visualizaciones estéticamente más atractivas y compatibles con ggplot2. Para instalarlo ejecutamos el siguiente código:\n\nremotes::install_github(\"daniel1noble/orchaRd\")\n\nUn aspecto a tener en cuenta es que los modelos ajustados con meta no son reconocidos por orchaRd, por lo que debemos reajustarlos en metafor.\nCargamos los paquetes requeridos:\n\nlibrary(metafor)\nlibrary(orchaRd)\nlibrary(scico)\n\nPrevio al ajuste del modelo, debemos calcular los estimadores de efecto individuales utilizando la función escalc():\n\ndat_orchard &lt;- escalc(\n  measure = \"PLO\",     # estimador de efecto\n  xi = cases,          # número de casos\n  ni = total,          # tamaño muestral\n  data = datos_prev    # conjunto de datos\n  )  \n\nAjustamos el modelo de meta-análisis con moderadores utilizando la función rma.mv() de metafor:\n\nmod_orchard &lt;- rma.mv(\n1  yi = yi,\n2  V = vi,\n3  mods = ~ factor(pais_cat) + pubyear,\n4  random = ~ 1|study,\n5  data = dat_orchard)\n\n\n1\n\nEstimador de efecto individual.\n\n2\n\nError estándar del estimador.\n\n3\n\nModeradores categóricos y/o numéricos.\n\n4\n\nDefinir efecto aleatorio.\n\n5\n\nConjunto de datos.\n\n\n\n\nPodemos generar un forest plot con los estimadores individuales y el estimador global usando la función caterpillars():\n\ncaterpillars(mod_orchard, \n             group = \"study\", \n             xlab = \"log(prevalencia)\", g = TRUE) \n\n\n\n\n\n\n\n\nSi queremos un gráfico más avanzado que muestre el análisis de subgrupos, usaremos la función orchard_plot():\n\norchard_plot(\n  mod_orchard,          \n1  group = \"study\",\n2  mod = \"pais_cat\",\n3  xlab = \"prevalencia\",\n4  transfm = \"invlogit\"\n  ) \n\n\n1\n\ngroup: identificador de estudio.\n\n2\n\nmod: nombre del moderador (1 para estimador de efecto global).\n\n3\n\nxlab: nombre del estimador de efecto.\n\n4\n\ntransf: mostrar los datos en escala original (opcional).\n\n\n\n\n\n\n\n\n\n\n\nCon el argumento scale_fill_scico_d() podemos usar cualquiera de las paletas colorblind-friendly incluidas en scico:\n\n# Forest plot por subgrupos\norchard_plot(\n  mod_orchard, \n  group = \"study\",\n  mod = \"pais_cat\",\n  xlab = \"prevalencia\",\n  transfm = \"invlogit\"\n  ) +\n  # Paleta colorblind-friendly\n  scale_color_scico_d(palette = \"hawaii\") + # color de borde\n  scale_fill_scico_d(palette = \"hawaii\")    # color de relleno\n\n\n\n\n\n\n\n\nGeneramos el bubble plot para el moderador continuo (pubyear):\n\nbubble_plot(\n  mod_orchard,           \n1  transfm = \"invlogit\",\n2  mod = \"pubyear\",\n3  group = \"study\",\n4  est.col = \"orange\",\n5  ci.col = \"magenta\")\n\n\n1\n\nMuestra resultados como proporciones\n\n2\n\nModerador continuo\n\n3\n\nIdentificador único de estudio\n\n4\n\nColor de la línea de regresión\n\n5\n\nColor de las líneas del 95% IC\n\n\n\n\n\n\n\n\n\n\n\nSi quisiera generar un bubble plot para cada nivel de pais_cat, puedo usar el argumento by:\n\nbubble_plot(\n  mod_orchard,           \n  transfm = \"invlogit\",\n  mod = \"pubyear\",     \n  group = \"study\",      \n  est.col = pal[2],     \n  ci.col = pal[1],      \n  by = \"pais_cat\"\n  ) +\n  \n  # Paleta colorblind-friendly\n  scale_color_scico_d(palette = \"glasgow\") + # color de borde\n  scale_fill_scico_d(palette = \"glasgow\")    # color de relleno",
    "crumbs": [
      "Introducción a la Revisión Sistemática con Meta-análisis",
      "Meta-análisis",
      "Exploración de la heterogeneidad"
    ]
  },
  {
    "objectID": "unidad_2/04_mod_bias.html#sesgo-de-publicación-y-análisis-de-sensibilidad",
    "href": "unidad_2/04_mod_bias.html#sesgo-de-publicación-y-análisis-de-sensibilidad",
    "title": "Exploración de la heterogeneidad",
    "section": "Sesgo de publicación y análisis de sensibilidad",
    "text": "Sesgo de publicación y análisis de sensibilidad\nEl sesgo de publicación (publication bias) se refiere a la tendencia de publicar con mayor frecuencia estudios con resultados positivos, estadísticamente significativos o con grandes tamaños del efecto. Esto puede distorsionar la síntesis de la evidencia en un meta-análisis, produciendo una sobreestimación del efecto global. Por ello, es esencial evaluar y ajustar el sesgo de publicación para garantizar que los resultados sean lo más precisos y representativos posible.\n\nFunnel plots\nEl funnel plot o gráfico de embudo representa en el eje \\(Y\\) el tamaño muestral o la precisión de los estudios, y en el eje \\(X\\) el estimador de efecto para cada estudio. En ausencia de sesgo de publicación, se espera una distribución simétrica que forme un patrón similar a un embudo; de lo contrario, se observa asimetría.\nPara generar un funnel plot, se utiliza la función funnel():\n\nfunnel(mod_prev)\n\n\n\n\n\n\n\n\n\n\nTest de Egger\nEl test de Egger evalúa la simetría del funnel plot mediante una regresión lineal entre el estimador de efecto y su error estándar. Un p-valor menor a 0,05 sugiere la presencia de sesgo de publicación.\nEste test se implementa con la función metabias():\n\nmetabias(\n  mod_prev,               # modelo de meta-análisis\n  method.bias = \"Egger\"   # aplica test de Egger (opción por defecto)\n  )\n\nLinear regression test of funnel plot asymmetry\n\nTest result: t = -1.45, df = 24, p-value = 0.1603\nBias estimate: -0.6649 (SE = 0.4589)\n\nDetails:\n- multiplicative residual heterogeneity variance (tau^2 = 1.4335)\n- predictor: standard error\n- weight:    inverse variance\n- reference: Egger et al. (1997), BMJ\n\n\n\n\nTest de Begg\nEl test de Begg utiliza la correlación de rangos para evaluar la relación entre el tamaño del efecto y el error estándar. Un p-valor menor que 0,05 indica la presencia de sesgo de publicación.\nSe implementa añadiendo el argumento method.bias = \"Begg\" a la función metabias():\n\nmetabias(\n  mod_prev,             # modelo de meta-análisis\n  method.bias = \"Begg\"  # aplica test de Begg\n  )\n\nRank correlation test of funnel plot asymmetry\n\nTest result: z = -0.90, p-value = 0.3662\nBias estimate: -41.0000 (SE = 45.3689)\n\nReference: Begg & Mazumdar (1993), Biometrics\n\n\n\n\nTrim-and-fill\nEl método trim-and-fill estima el número de estudios faltantes debido al sesgo de publicación y ajusta la media global en consecuencia, incorporando estudios hipotéticos. Esto ayuda a corregir la estimación del efecto global.\nSe utiliza la función trimfill():\n\ntrimfill(mod_prev)\n\nNumber of studies: k = 32 (with 6 added studies)\n\n                      events             95%-CI\nRandom effects model 23.4496 [21.7062; 25.3329]\n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.0181; tau = 0.1344; I^2 = 42.4% [12.2%; 62.2%]; H = 1.32 [1.07; 1.63]\n\nTest of heterogeneity:\n     Q d.f. p-value\n 53.82   31  0.0067\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Maximum-likelihood estimator for tau^2\n- Calculation of I^2 based on Q\n- Trim-and-fill method to adjust for funnel plot asymmetry (L-estimator)\n- Logit transformation\n- Events per 100000 observations\n\n\nGeneralmente, se recomienda utilizar dos o más métodos para evaluar el sesgo de publicación y obtener una visión más completa de su impacto en el meta-análisis. En el ejemplo anterior, no hubiera sido necesario realizar el trim-and-fill ya que el funnel plot tiene una forma bastante simétrica y el p-valor de los test de Egger y Begg fue menor a 0,05.\n\n\nAnálisis de sensibilidad\nEl análisis de sensibilidad permite evaluar la robustez de los resultados de un meta-análisis. Una estrategia común consiste en reajustar el modelo excluyendo estudios con menor tamaño muestral o de menor calidad, y luego comparar el estimador de efecto y su intervalo de confianza del 95% con los del modelo original. Otra alternativa es el análisis leave-one-out, que implica eliminar un estudio a la vez para observar cómo varía el estimador global.\nLa función leave_one_out() del paquete orchaRd permite realizar este tipo de análisis:\n\nleave_one &lt;- leave_one_out(mod_orchard, group = \"study\")\n\nEste procedimiento ayuda a identificar si algún estudio influye de manera desproporcionada en los resultados del meta-análisis. Al igual que en modelos anteriores, los resultados pueden representarse gráficamente:\n\norchard_leave1out(leave1out = leave_one,     # Objeto leave-one-out\n                  xlab = \"logit-prevalencia\" # Nombre del estimador\n                  )\n\n\n\n\n\n\n\n\nEn el gráfico, el eje \\(Y\\) representa cada elemento del grupo (en este caso, cada estudio), mientras que el eje \\(X\\) muestra el estimador de efecto. Para cada estudio, se presenta el resultado del modelo al excluirlo: estimador de efecto global, su intervalo de confianza, el intervalo de predicción, y los “puntos fantasma”, que marcan la ubicación del estudio excluido.",
    "crumbs": [
      "Introducción a la Revisión Sistemática con Meta-análisis",
      "Meta-análisis",
      "Exploración de la heterogeneidad"
    ]
  },
  {
    "objectID": "unidad_2/04_mod_bias.html#modelos-multinivel",
    "href": "unidad_2/04_mod_bias.html#modelos-multinivel",
    "title": "Exploración de la heterogeneidad",
    "section": "Modelos multinivel",
    "text": "Modelos multinivel\nTodos los modelos de meta-análisis pueden considerarse modelos multinivel, ya que implican múltiples fuentes de variación. Los modelos de efectos aleatorios, consideran dos niveles de variabilidad:\n\nError aleatorio: variabilidad entre participantes dentro de un mismo estudio.\nHeterogeneidad entre estudios: diferencias sistemáticas entre los efectos reportados por estudios distintos.\n\nEn este contexto, los individuos están “anidados” dentro de cada estudio, lo que configura una estructura jerárquica de los datos, similar a la de los modelos de efectos mixtos.\nSin embargo, en algunos casos esta estructurano refleja adecuadamente la falta de independencia presente en los datos. Por ejemplo, puede suceder que un mismo estudio reporte múltiples estimadores de efecto correspondientes a distintos grupos de participantes, momentos temporales, sitios de estudio, tratamientos o desenlaces. En estas situaciones, asumir independencia entre las estimaciones dentro de un estudio puede conducir a inferencias sesgadas.\nLos modelos de tres niveles incorporan una capa adicional de variabilidad que permite modelar la heterogeneidad intraestudio. De este modo, se mejora el ajuste del modelo y se pueden utilizar todas las estimaciones disponibles, sin necesidad de promediarlas o seleccionar una por estudio, evitando así pérdida de información.\n\nAjuste en R\nSi bien el paquete recomendado para ajustar modelos multinivel es metafor, su uso requiere conocimientos más avanzados de estadística y de programación en R. Por ese motivo, continuaremos utilizando el paquete meta, que permite incorporar una estructura de tres niveles mediante el argumento cluster.\nTrabajaremos con el conjunto de datos dat.bornmann2007, que contiene los resultados de 21 estudios sobre diferencias de género en la adjudicación de becas y subsidios para investigación:\n\n# Cargar datos\ndatos &lt;- dat.bornmann2007\n\n# Explorar datos\nglimpse(datos)\n\nRows: 66\nColumns: 13\n$ study      &lt;chr&gt; \"Ackers (2000)\", \"Ackers (2000)\", \"Ackers (2000)\", \"Ackers …\n$ obs        &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 1, 1, 2, 3, 4,…\n$ doctype    &lt;chr&gt; \"Grey\", \"Grey\", \"Grey\", \"Grey\", \"Grey\", \"Grey\", \"Grey\", \"Ar…\n$ gender     &lt;chr&gt; \"M&F\", \"M&F\", \"M&F\", \"M&F\", \"M&F\", \"M&F\", \"M&F\", \"M&F\", \"M&…\n$ year       &lt;dbl&gt; 1996.0, 1996.0, 1996.0, 1996.0, 1996.0, 1996.0, 1996.0, 199…\n$ org        &lt;chr&gt; \"MSCA\", \"MSCA\", \"MSCA\", \"MSCA\", \"MSCA\", \"MSCA\", \"MSCA\", \"DF…\n$ country    &lt;chr&gt; \"Europe\", \"Europe\", \"Europe\", \"Europe\", \"Europe\", \"Europe\",…\n$ type       &lt;chr&gt; \"Fellowship\", \"Fellowship\", \"Fellowship\", \"Fellowship\", \"Fe…\n$ discipline &lt;chr&gt; \"Physical Sciences\", \"Physical Sciences\", \"Physical Science…\n$ waward     &lt;int&gt; 139, 45, 44, 63, 157, 114, 381, 8, 5, 6, 8, 4, 20, 5, 11, 2…\n$ wtotal     &lt;int&gt; 711, 258, 236, 251, 910, 589, 2027, 13, 8, 8, 16, 11, 44, 1…\n$ maward     &lt;int&gt; 274, 166, 219, 96, 252, 460, 489, 53, 53, 63, 53, 43, 55, 7…\n$ mtotal     &lt;int&gt; 1029, 908, 928, 507, 1118, 2244, 2275, 72, 82, 97, 94, 92, …\n\n\nLas variables de interés son:\n\nwaward: número de mujeres que recibieron la beca/subsidio.\nwtotal: número de mujeres que se postularon a la beca/subsidio.\nmaward: número de varones que recibieron la beca/subsidio.\nmtotal: número de varones que se postularon a la beca/subsidio.\n\nEl conjunto de datos contiene 66 observaciones, lo que sugiere que varios estudios reportan más de un estimador de efecto. Para confirmarlo, generamos una tabla de frecuencias por estudio:\n\n# Tabla frecuencias por autor\ntabyl(datos, study)\n\n                 study n    percent\n         Ackers (2000) 7 0.10606061\n   Allmendinger (2002) 7 0.10606061\n        Bazeley (1998) 1 0.01515152\n       Bornmann (2005) 1 0.01515152\n         Brouns (2000) 5 0.07575758\n         Dexter (2002) 3 0.04545455\n          Emery (1992) 1 0.01515152\n        Friesen (1998) 3 0.04545455\n      Goldsmith (2002) 2 0.03030303\n          Grant (1997) 4 0.06060606\n     Jayasinghe (2001) 1 0.01515152\n            NSF (2005) 8 0.12121212\n           Over (1996) 1 0.01515152\n       Sigelman (1987) 1 0.01515152\n        Taplick (2005) 3 0.04545455\n          Viner (2004) 2 0.03030303\n           Ward (1998) 1 0.01515152\n Wellcome Trust (1997) 1 0.01515152\n       Wenneras (1997) 1 0.01515152\n        Willems (2001) 4 0.06060606\n           Wood (1997) 9 0.13636364\n\n\nComo se observa, cada estudio aporta entre 1 y 9 estimaciones. Veamos qué ocurre si ajustamos un modelo de efectos aleatorios convencional:\n\n# Ajustar modelo\nmod &lt;- metabin(event.e = waward,  # Mujeres que recibieron la beca\n               n.e = wtotal,      # Mujeres que se postularon\n               event.c = maward,  # Varones que recibieron la beca\n               n.c = mtotal,      # Varones que se postularon\n               data = datos,      # Tabla de datos\n               sm = \"OR\",         # Estimador de efecto\n               common = FALSE,    # Omitir modelo de efectos fijos\n               studlab = study)   # Identificador único del estudio\n\n# Salida del modelo\nmod\n\nNumber of studies: k = 66\nNumber of observations: o = 353725 (o.e = 74060, o.c = 279665)\nNumber of events: e = 109357\n\n                         OR           95%-CI     z p-value\nRandom effects model 0.9349 [0.8838; 0.9889] -2.35  0.0188\n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.0218 [0.0121; 0.0802]; tau = 0.1476 [0.1101; 0.2831]\n I^2 = 70.6% [62.4%; 77.1%]; H = 1.85 [1.63; 2.09]\n\nTest of heterogeneity:\n      Q d.f.  p-value\n 221.28   65 &lt; 0.0001\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n\n\nEl modelo muestra que las mujeres tienen significativamente menor probabilidad de recibir subsidios, y que existe una alta heterogeneidad estadística (\\(I^2 = 70,6\\%\\)). Sin embargo, este modelo asume independencia entre las 66 observaciones, lo que podría distorsionar la estimación de los coeficientes.\nAntes de ajustar un modelo de tres niveles, generamos una nueva variable con un identificador único por observación:\n\ndatos &lt;- datos |&gt; \n  mutate(id = seq(1, 66))\n\nPara incorporar la estructura multinivel, utilizamos el argumento cluster. Como existen múltiples observaciones por estudio, definimos study como clúster e id como identificador de cada observación:\n\n# Ajustar modelo de tres niveles\nmod_m &lt;- metabin(event.e = waward,  # Mujeres que recibieron la beca\n               n.e = wtotal,      # Mujeres que se postularon\n               event.c = maward,  # Varones que recibieron la beca\n               n.c = mtotal,      # Varones que se postularon\n               data = datos,      # Tabla de datos\n               sm = \"OR\",         # Estimador de efecto\n               common = FALSE,    # Omitir modelo de efectos fijos\n               studlab = id,  # Identificador único del estudio\n               cluster = study\n) \n\nAhora veamos la salida del modelo:\n\nmod_m\n\nNumber of studies: n = 21\nNumber of estimates: k = 66\nNumber of observations: o = 353725 (o.e = 74060, o.c = 279665)\nNumber of events: e = 109357\n\n                         OR           95%-CI     z p-value\nRandom effects model 0.9039 [0.8329; 0.9810] -2.42  0.0155\n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2.1 = 0.0161 [0.0040; 0.0555]; tau.1 = 0.1268 [0.0630; 0.2357] (between cluster)\n tau^2.2 = 0.0038 [0.0008; 0.0146]; tau.2 = 0.0613 [0.0285; 0.1208] (within cluster)\n I^2 = 70.6% [62.4%; 77.1%]; H = 1.85 [1.63; 2.09]\n\nTest of heterogeneity:\n      Q d.f.  p-value\n 221.28   65 &lt; 0.0001\n\nDetails of meta-analysis methods:\n- Inverse variance method (three-level model)\n- Restricted maximum-likelihood estimator for tau^2\n- Profile-Likelihood method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n\n\nPodemos observar que el estimador global, su intervalo de confianza y la significación estadística difieren del modelo anterior. Además, la heterogeneidad se descompone en dos componentes:\n\n\\(\\tau^2_1\\) (entre estudios, o clústeres)\n\\(\\tau^2_2\\) (heterogeneidad dentro del estudio)\n\nEsta descomposición permite una estimación más precisa de la variabilidad real y evita subestimar o sobreestimar la incertidumbre asociada al efecto global.\nAl igual que en los modelos de efectos fijos y aleatorios, podemos representar gráficamente los resultados mediante forest plots y realizar análisis de moderadores. Sin embargo, para evaluar sesgo de publicación debemos usar el modelo de efectos aleatorios.\n\n\n\n\n\n\nHasta aquí hemos cubierto los aspectos básicos para evaluar fuentes de heterogeneidad en modelos de meta-análisis. Quienes tengan interés en profundizar en las medidas de heterogeneidad y su aplicación, recomendamos consultar el artículo de (Bown y Sutton 2010) y los capítulos 7, 8 y 9 de Harrer et al. (2021).",
    "crumbs": [
      "Introducción a la Revisión Sistemática con Meta-análisis",
      "Meta-análisis",
      "Exploración de la heterogeneidad"
    ]
  },
  {
    "objectID": "unidad_2/02_fixed_random.html",
    "href": "unidad_2/02_fixed_random.html",
    "title": "Modelos de meta-análisis",
    "section": "",
    "text": "Uno de los objetivos principales del modelado estadístico es representar la realidad de la manera más “sencilla” posible, capturando su estructura esencial y descartando elementos cuya variabilidad podría generar ruido en la interpretación de los fenómenos.\nPara ajustar un modelo estadístico, partimos de los datos disponibles y buscamos construir una representación basada en ellos. En el caso de los modelos de meta-análisis, los datos de interés son los estimadores de efecto obtenidos en cada estudio, y el objetivo principal es analizar la variabilidad entre ellos, la cual puede deberse a diferencias metodológicas, características de las poblaciones estudiadas u otras fuentes.\nExisten dos enfoques principales en meta-análisis: los modelos de efectos fijos y los modelos de efectos aleatorios. Durante este curso, describiremos sus características fundamentales y su implementación en R. Para quienes deseen profundizar en los fundamentos matemáticos de estos modelos, recomendamos consultar el Capítulo 4 de Schwarzer, Carpenter, y Rücker (2015) y el Capítulo 2 de Harrer et al. (2021).",
    "crumbs": [
      "Introducción a la Revisión Sistemática con Meta-análisis",
      "Meta-análisis",
      "Modelos de meta-análisis"
    ]
  },
  {
    "objectID": "unidad_2/02_fixed_random.html#introducción",
    "href": "unidad_2/02_fixed_random.html#introducción",
    "title": "Modelos de meta-análisis",
    "section": "",
    "text": "Uno de los objetivos principales del modelado estadístico es representar la realidad de la manera más “sencilla” posible, capturando su estructura esencial y descartando elementos cuya variabilidad podría generar ruido en la interpretación de los fenómenos.\nPara ajustar un modelo estadístico, partimos de los datos disponibles y buscamos construir una representación basada en ellos. En el caso de los modelos de meta-análisis, los datos de interés son los estimadores de efecto obtenidos en cada estudio, y el objetivo principal es analizar la variabilidad entre ellos, la cual puede deberse a diferencias metodológicas, características de las poblaciones estudiadas u otras fuentes.\nExisten dos enfoques principales en meta-análisis: los modelos de efectos fijos y los modelos de efectos aleatorios. Durante este curso, describiremos sus características fundamentales y su implementación en R. Para quienes deseen profundizar en los fundamentos matemáticos de estos modelos, recomendamos consultar el Capítulo 4 de Schwarzer, Carpenter, y Rücker (2015) y el Capítulo 2 de Harrer et al. (2021).",
    "crumbs": [
      "Introducción a la Revisión Sistemática con Meta-análisis",
      "Meta-análisis",
      "Modelos de meta-análisis"
    ]
  },
  {
    "objectID": "unidad_2/02_fixed_random.html#modelos-de-efectos-fijos",
    "href": "unidad_2/02_fixed_random.html#modelos-de-efectos-fijos",
    "title": "Modelos de meta-análisis",
    "section": "Modelos de efectos fijos",
    "text": "Modelos de efectos fijos\nEl modelo de efectos fijos parte de la premisa de que todos los estimadores de efecto incluidos en el meta-análisis (\\(y_k\\)) provienen de una población homogénea. Es decir, se asume un único efecto verdadero subyacente, denotado como \\(\\theta\\), y que las diferencias observadas entre estudios se explican únicamente por el error muestral (\\(\\epsilon_k\\)).\n\\[\ny_k = \\theta + \\epsilon_k\n\\tag{1}\\]\nEste error muestral es dependiente del tamaño de la muestra y equivalente al error estándar del estimador. El objetivo es entonces calcular \\(\\theta\\) usando el promedio ponderado de los estimadores de efecto individuales.\n\\[\n\\theta = \\frac{\\sum{y_k w_k}}{\\sum{w_k}} \\qquad donde~w_k = \\frac{1}{S^2_{y_k}}\n\\tag{2}\\]\nEn el modelo de efectos fijos, los estudios con menor varianza poseen mayor influencia sobre la estimación global. Esta estrategia de ponderación se conoce como el método de la varianza inversa.\nComo se supone que los estudios son homogéneos entre sí, no se considera la existencia de fuentes de variabilidad adicionales. Por esta razón, también se les conoce como modelo de efecto común (common effect model) o modelo de efectos equivalentes (equal effect model).\nNo obstante, en la práctica, es frecuente encontrar heterogeneidad real entre los estudios, lo que hace inadecuado el enfoque de efectos fijos. En estos casos, conviene optar por un modelo de efectos aleatorios, que incorpora explícitamente esa heterogeneidad en la estimación del efecto global.",
    "crumbs": [
      "Introducción a la Revisión Sistemática con Meta-análisis",
      "Meta-análisis",
      "Modelos de meta-análisis"
    ]
  },
  {
    "objectID": "unidad_2/02_fixed_random.html#modelos-de-efectos-aleatorios",
    "href": "unidad_2/02_fixed_random.html#modelos-de-efectos-aleatorios",
    "title": "Modelos de meta-análisis",
    "section": "Modelos de efectos aleatorios",
    "text": "Modelos de efectos aleatorios\nLos modelos de efectos aleatorios asumen que, además del error muestral, existen fuentes adicionales de variabilidad entre los estudios. A diferencia del modelo de efectos fijos, no se postula un único efecto verdadero común, sino que se considera que cada estudio estima un efecto específico, que varía alrededor de una media global.\nLa relación entre el estimador de efecto para cada estudio (\\(y_k\\)) y su efecto verdadero se expresa como:\n\\[\ny_k = \\theta_k + \\epsilon_k\n\\tag{3}\\]\nEn este enfoque, los verdaderos efectos de los estudios (\\(\\theta_k\\)) no son idénticos, sino que se distribuyen según una distribución de probabilidad con media \\(\\mu\\) y desvío estándar \\(\\tau\\),\nReemplazando \\(\\theta_k\\) en la ecuación anterior:\n\\[\ny_k = \\mu + \\tau_k + \\epsilon_k\n\\tag{4}\\]\ndonde:\n\n\\(\\tau_k\\) representa el desvío del efecto verdadero del estudio \\(k\\) con respecto a la media global.\n\\(\\epsilon_k\\) es el error muestral.\n\nEl objetivo del modelo es estimar la media de la distribución de efectos verdaderos (\\(\\mu\\)), teniendo en cuenta tanto la variabilidad dentro de los estudios (error muestral) como la variabilidad entre estudios (heterogeneidad). Para ello, cada estudio se pondera mediante una versión ajustada del método de la varianza inversa:\n\\[w^*_i = \\frac{1}{S^2_{y_k} + \\tau^2} \\qquad donde~\\tau^2 es~ la~ varianza~entre~estudios \\tag{5}\\]\nEl valor de tau-cuadrado no se conoce de antemano y debe estimarse a partir de los datos. Entre los métodos más utilizados se encuentran el estimador de DerSimonian y Laird y la máxima verosimilitud restringida (REML). Aunque su desarrollo técnico excede los objetivos de este curso, es importante destacar que la elección del método puede influir tanto en la estimación del efecto global como en la amplitud de los intervalos de confianza.\n\nIndicadores de heterogeneidad\nEn un meta-análisis, la variabilidad en los resultados puede deberse a múltiples fuentes:\n\nVariabilidad intraestudio: refleja las diferencias entre los participantes dentro de cada estudio.\nHeterogeneidad entre estudios: variabilidad en los efectos estimados más allá de lo esperable por azar.\nError de muestreo y otras fuentes de incertidumbre, que pueden influir en las diferencias observadas.\n\nLa heterogeneidad entre estudios es particularmente importante, ya que indica si los efectos varían más de lo que se esperaría solo por error aleatorio. En la siguiente tabla, adaptada de Schwarzer, Carpenter, y Rücker (2015), se resumen los indicadores más utilizados para cuantificar la heterogeneidad:\n\n\n\n\n\nMedida\nInterpretación\nEscala\nRango\nNúmero de estudios\nAfectada por precisión\n\n\n\n\nQ de Cochran\nEvalúa si la heterogeneidad observada es estadísticamente significativa.\nAbsoluta\n[0, ∞)\nDependiente\nSí\n\n\nI²\nCuantifica qué proporción de la variabilidad total se debe a heterogeneidad real.\nPorcentaje\n[0, 100]\nIndependiente\nSí\n\n\nτ²\nMide la variabilidad real entre los efectos verdaderos de los estudios.\nVarianza\n[0, ∞)\nIndependiente\nNo\n\n\nH²\nRazón entre la varianza total observada y la varianza esperada bajo el supuesto de homogeneidad.\nAbsoluta\n[1, ∞)\nIndependiente\nSí\n\n\n\n\n\n\n\nEstos indicadores permiten evaluar si las diferencias observadas entre los estudios justifican el uso de un modelo de efectos aleatorios en lugar de uno de efectos fijos.",
    "crumbs": [
      "Introducción a la Revisión Sistemática con Meta-análisis",
      "Meta-análisis",
      "Modelos de meta-análisis"
    ]
  },
  {
    "objectID": "unidad_2/02_fixed_random.html#implementación-en-r",
    "href": "unidad_2/02_fixed_random.html#implementación-en-r",
    "title": "Modelos de meta-análisis",
    "section": "Implementación en R",
    "text": "Implementación en R\nExisten diversos paquetes para ajustar modelos de meta-análisis en R, siendo los más utilizados metafor (Viechtbauer 2010) y meta (Balduzzi, Rücker, y Schwarzer 2019). Ambos ajustan modelos robustos, pero difieren en su enfoque, facilidad de uso y otras características.\n\n\n\n\n\n\nmetafor\nmeta\n\n\n\n\nCaracterística principal\nFlexibilidad y potencia\nFacilidad de uso\n\n\nCurva de aprendizaje\nModerada a alta\nApto para principiantes en R\n\n\nTipo de datos\nPuede manejar diversos tipos de datos y transformaciones\nFunciones específicas para cada tipo de datos\n\n\nMeta-regresiones\nPermite múltiples covariables e interacciones\nPermiten una o pocas covariables\n\n\nAnálisis de subgrupos\nMeta-regresión con predictores categóricos\nArgumentos específicos para análisis de subgrupos\n\n\nSalida\nDetallada, muestra estadísticos avanzados\nConcisa, orientada a interpretar los resultados\n\n\n\n\n\n\n\nDado que este curso se enfoca en la aplicación práctica del meta-análisis, utilizaremos principalmente el paquete meta, que ajusta por defecto modelos de efectos fijos y aleatorios, e incluye distintos estimadores de heterogeneidad estadística.\n\nEstructura básica\nEl paquete meta ofrece una serie de funciones para ajustar modelos de meta-análisis con una estructura uniforme. La función principal es metagen(), que permite trabajar con datos precalculados. Sus argumentos principales son:\n\nmetagen(\n1  TE,\n2  seTE,\n3  studlab,\n4  data,\n5  subset,\n6  common,\n7  random,\n8  subgroup,\n9  cluster\n)\n\n\n1\n\nEstimador de efecto individual.\n\n2\n\nError estándar el estimador de efecto individual.\n\n3\n\nIdentificador único del estudio (opcional).\n\n4\n\nConjunto de datos a utilizar (opcional).\n\n5\n\nFiltrar estudios por una condición (opcional).\n\n6\n\nAjustar modelo de efectos fijos (TRUE/FALSE).\n\n7\n\nAjustar modelo de efectos aleatorios (TRUE/FALSE).\n\n8\n\nDefinir variable para análisis de subgrupos (opcional).\n\n9\n\nDefinir variable para ajuste de modelo multinivel (opcional).\n\n\n\n\n\n\nEjemplo práctico\nUsaremos el conjunto de datos dat.konstantopoulos2011, incluido en la dependencia metadat (Viechtbauer et al. 2025). El mismo presenta los resultados de 56 estudios que comparan el rendimiento escolar de estudiantes que asisten a escuelas con un calendario escolar modificado —caracterizado por varios períodos cortos de vacaciones distribuidos a lo largo del año— con aquellos que asisten a escuelas con un calendario tradicional, que incluye un receso de verano largo y vacaciones más breves en invierno y primavera. Los resultados se expresan como diferencias de medias estandarizadas.\nComenzaremos por cargar el paquete necesario:\n\n# Cargar el paquete meta\nlibrary(meta)\n\nCargamos los datos y exploramos su estructura:\n\n# Cargar datos\ndatos &lt;- dat.konstantopoulos2011\n\n# Explorar estructura del dataset\nnames(datos)\n\n[1] \"district\" \"school\"   \"study\"    \"year\"     \"yi\"       \"vi\"      \n\n\nLas variables de entrada para metagen() serán yi (diferencia de medias estandarizada), vi (variabilidad de la estimación) y study (identificador único del estudio):\n\n# Ajustar el modelo\nmod &lt;- metagen(TE = yi,\n               seTE = vi,\n               studlab = study,\n               common = TRUE,    \n               random = TRUE,    \n               backtransf = TRUE, \n               data = datos)\n\nPodemos acceder a la salida completa del modelo, con los estimadores de efecto y su \\(95\\%~CI\\) para cada estudio usando summary(), o a una versión más resumida imprimiendo el objeto donde almacenamos el modelo:\n\n# Resumen del modelo\nmod\n\nNumber of studies: k = 56\n\n                                         95%-CI      z p-value\nCommon effect model  -0.0133 [-0.0140; -0.0126] -38.82       0\nRandom effects model  0.1219 [ 0.0365;  0.2074]   2.80  0.0052\n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.1048 [0.0739; 0.1588]; tau = 0.3238 [0.2719; 0.3985]\n I^2 = 99.9%; H = 41.32\n\nTest of heterogeneity:\n        Q d.f. p-value\n 93892.81   55       0\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n\n\nAntes de analizar en detalle cada elemento de la salida debemos fijarnos en el valor de \\(I^2\\), ya que si el porcentaje de heterogeneidad estadística es alto, debemos omitir los resultados del modelo de efectos fijos. En nuestro ejemplo \\(I^2 = 99,9\\%\\) nos indica que el modelo de efectos aleatorios es el más apropiado (podemos reajustar el modelo cambiando el argumento common a FALSE o simplemente ignorar estos coeficientes).\nUna vez que decidimos con cual modelo quedarnos, procedemos a interpretar la salida:\n\nk: número de estudios incluidos en el análisis.\nCommon effect model: estimador de efecto, \\(95\\%~IC\\), estadístico z y significancia estadística para el modelo de efectos fijos.\nRandom effects model: estimador de efecto, \\(95\\%~IC\\), estadístico z y significancia estadística para el modelo de efectos aleatorios.\nQuantifying heterogeneity (with 95%-CIs): muestra las distintas medidas de heterogeneidad y los test de significancia asociados:\n\ntau^2: variabilidad entre estudios (tau-cuadrado) y su \\(95\\%~IC\\).\ntau: raíz cuadrada de la variabilidad entre estudios y su \\(95\\%~IC\\).\nI^2: porcentaje de variabilidad atribuida a diferencias reales entre estudios (\\(I^2\\)).\nH: raíz cuadrada del estadístico \\(H^2\\), que mide la razón entre la varianza observada y la esperada.\nQ: estadístico Q de Cochran con sus grados de libertad y significancia.\n\nDetails of meta-analysis methods: indica los métodos estadísticos utilizados en el ajuste del modelo, incluyendo:\n\nInverse variance method: método de varianza inversa para ponderar los estudios.\nRestricted maximum-likelihood estimator for tau^2: estimador de máxima verosimilitud restringida para tau-cuadrado.\nQ-Profile method for confidence interval of tau^2 and tau: método para estimar el intervalo de confianza de tau y tau-cuadrado.\nCalculation of I^2 based on Q: metodología aplicada para calcular \\(I^2\\).\n\n\n\n\nInterpretación de resultados\nEn base a la salida anterior, podemos concluir que el meta-análisis realizado sobre 56 estudios individuales muestra que el rendimiento académico aumenta significativamente con la modificación del calendario escolar (\\(p &lt; 0.005\\)). La alta heterogeneidad estadística (\\(I^2 = 99,9\\%\\)) sugiere que la variabilidad observada se debe a diferencias reales entre estudios.\n\n\nRepresentación gráfica\nLos resultados del meta-análisis pueden visualizarse mediante forest plots, gráficos que representan la distribución de los estimadores de efecto de los estudios individuales y sus intervalos de confianza en relación con el estimador global. Además, proporcionan información sobre la heterogeneidad entre estudios, facilitando la interpretación de los resultados.\nEl paquete meta incluye la función forest(), que permite generar forest plots de forma rápida y con múltiples opciones de personalización. Para conocer todos los argumentos disponibles, se puede ejecutar ?forest en la consola de R.\nAlgunos de sus argumentos principales incluyen:\n\nforest(\n1  mod,\n2  sortvar,\n3  smlab,\n4  col.diamond,\n5  col.square,\n6  print.tau2 = TRUE,\n7  print.I2 = TRUE,\n8  print.Q = TRUE,\n9  digits = 2,\n  ...)\n\n\n1\n\nNombre del modelo de meta-análisis.\n\n2\n\nOrdenar los estudios según una variable numérica\n\n3\n\nEtiqueta a mostrar para el estimador de efecto.\n\n4\n\nColor para mostrar el símbolo del estimador de efecto global.\n\n5\n\nColor para mostrar el símbolo de los estimadores de efecto individuales.\n\n6\n\nMostrar tau-cuadrado (TRUE/FALSE).\n\n7\n\nMostrar I-cuadrado (TRUE/FALSE).\n\n8\n\nMostrar Q de Cochran (TRUE/FALSE).\n\n9\n\nEspecificar el número de decimales a mostrar en los resultados.\n\n\n\n\nA continuación, generaremos un forest plot para representar gráficamente el modelo que ajustamos. Para mejorar su visualización, vamos a usar colores personalizados para los argumentos col.diamond y col.square:\n\nforest(mod,\n       smlab = \"Diferencia de medias estandarizada\",\n       col.diamond = \"#8C0172\",\n       col.square = \"#6BD48C\"\n       )\n\n\n\n\n\n\n\n\nEl gráfico consta de tres paneles principales:\n\nPanel izquierdo:\n\nIdentificador de estudio (\"studlab\").\nColumnas adicionales dependientes del estimador de efecto utilizado.\n\nPanel central:\n\nLínea vertical de referencia que indica el valor de no efecto (0 en datos continuos, 1 en escalas logarítmicas).\nLínea punteada que representa el estimador global del meta-análisis.\nUn rombo que representa el estimador de efecto global, cuyo ancho indica el intervalo de confianza al 95%.\nCuadrados que representan los estimadores de los estudios individuales, con un tamaño proporcional al peso del estudio en el análisis.\nBigotes horizontales que indican los \\(95\\%~IC\\) de cada estudio.\n\nPanel derecho:\n\nEstimador de efecto e intervalo de confianza al 95% de cada estudio.\nPeso estadístico asignado a cada estudio en el modelo de efectos aleatorios.\n\n\nSe puede controlar la información que aparece en los lados del forest plot mediante los argumentos leftcols, rightcols, leftlabs y rightlabs. También es posible aplicar formatos predefinidos con layout = \"RevMan5\" o layout = \"JAMA\", que ajustan el diseño según estilos ampliamente utilizados en la literatura científica.\nLos gráficos generados con forest() no son compatibles con ggplot2 ni se autoescalan, lo que puede ser problemático si el número de estudios es grande, ya que el gráfico podría quedar ilegible en la vista predeterminada.\nPara evitar este problema, se recomienda exportar el gráfico a un archivo de imagen (por ejemplo, PDF o PNG) usando las funciones pdf() o png(), especificando un tamaño adecuado antes de ejecutarlo con forest(). En la última clase además veremos opciones de visualización avanzada para generar gráficos listos para su publicación.\nEn la siguiente sección, exploraremos las funciones de meta que permiten ajustar modelos de meta-análisis para distintos estimadores de efecto en epidemiología. Luego, abordaremos métodos para controlar la heterogeneidad, tales como el análisis de moderadores y la meta-regresión y aprenderemos qué es y como se mide el sesgo de publicación.",
    "crumbs": [
      "Introducción a la Revisión Sistemática con Meta-análisis",
      "Meta-análisis",
      "Modelos de meta-análisis"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introducción a la Revisión Sistemática con Meta-análisis",
    "section": "",
    "text": "Les damos la bienvenida al curso de “Introducción a la Revisión Sistemática con Meta-análisis”. Antes de profundizar en los temas específicos, recomendamos a quienes lo requieran repasar el material introductorio sobre inferencia estadística y primeros pasos en R y RStudio. ya que les proporcionará una base sólida para aprovechar al máximo el curso. ¡Esperamos que disfruten y enriquezcan sus conocimientos!\n\n\n\n Volver arribaReutilizaciónCC BY-NC 4.0"
  },
  {
    "objectID": "extras/intro_inferencia.html",
    "href": "extras/intro_inferencia.html",
    "title": "Introducción a la inferencia estadística",
    "section": "",
    "text": "Artwork por @allison_horst",
    "crumbs": [
      "Introducción a la Revisión Sistemática con Meta-análisis",
      "Material Introductorio",
      "Introducción a la inferencia estadística"
    ]
  },
  {
    "objectID": "extras/intro_inferencia.html#fundamentos",
    "href": "extras/intro_inferencia.html#fundamentos",
    "title": "Introducción a la inferencia estadística",
    "section": "Fundamentos",
    "text": "Fundamentos\nLa estadística inferencial es la rama de la estadística que permite extraer conclusiones sobre una población a partir de una muestra de datos. Este proceso se sustenta en dos procedimientos principales: la estimación y la prueba de hipótesis.\nLa población se define como el conjunto completo de individuos u observaciones de interés, mientras que la muestra es el subconjunto representativo de esa población, diseñado para reflejar sus características fundamentales. Para describir la población se utilizan parámetros, valores numéricos como la media poblacional \\((\\mu)\\), mientras que los datos muestrales se resumen con estadísticos, por ejemplo, la media muestral \\((\\bar{x})\\).",
    "crumbs": [
      "Introducción a la Revisión Sistemática con Meta-análisis",
      "Material Introductorio",
      "Introducción a la inferencia estadística"
    ]
  },
  {
    "objectID": "extras/intro_inferencia.html#estimación-de-parámetros",
    "href": "extras/intro_inferencia.html#estimación-de-parámetros",
    "title": "Introducción a la inferencia estadística",
    "section": "Estimación de parámetros",
    "text": "Estimación de parámetros\nLa estimación consiste en utilizar información muestral para inferir el valor de un parámetro poblacional. Existen dos tipos principales:\n\nEstimación puntual: proporciona un único valor estimado. Por ejemplo, la media muestral (\\(\\bar{x}\\)) como estimador de la media poblacional (\\(\\mu\\)).\nEstimación por intervalo de confianza: proporciona un rango de valores plausibles para el parámetro, con un nivel de confianza determinado.\n\nIntervalos de confianza\nAunque los intervalos de confianza son procedimientos inferenciales, están estrechamente ligados a la estadística descriptiva. Un intervalo de confianza indica un rango de valores dentro del cual se espera que se ubique el verdadero valor del parámetro poblacional, con una cierta probabilidad conocida como nivel de confianza.\nLa forma general de un IC es:\n\\[ IC = estimador~puntual \\pm (coeficiente~de~confiabilidad) * (error~ estandar) \\]\nEstimador puntual\n\nPara la media poblacional (\\(\\mu\\)): se utiliza la media muestral \\(\\bar{x}\\).\nPara una proporción poblacional (\\(p\\)): se utiliza la proporción muestral \\(\\hat{p}\\).\nCoeficiente de confiabilidad\nCorresponde al valor asociado al nivel de confianza deseado (por ejemplo, 90%, 95%, 99%). Se denota como \\(1 - \\alpha\\), siendo \\(\\alpha\\) el nivel de significación (probabilidad de error tipo I). Por ejemplo, para un 95% de confianza, \\(\\alpha = 0.05\\) y el coeficiente es \\(Z_{1 - \\alpha/2} \\approx 1.96\\).\nError estándar (SE)\nRepresenta la variabilidad de la distribución muestral y depende del parámetro.\nPor ejemplo, para la media se calcula:\n\\[\nSE = \\frac{\\sigma}{\\sqrt{n}}\n\\]\nDonde \\(\\sigma\\) es la desviación estándar poblacional y \\(n\\) el tamaño de la muestra.\nMientras que para una proporción se calcula como:\n\\[\nSE = \\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n}}\n\\]\nTeorema del límite central\nEl Teorema del Límite Central (TLC) establece que, para muestras suficientemente grandes, la distribución muestral de la media (\\(\\bar{x}\\)) es aproximadamente normal, con media \\(\\mu\\) y varianza \\(\\sigma^2/n\\). Esto permite utilizar la distribución normal estándar para calcular probabilidades e intervalos:\n\\[\nZ = \\frac{\\bar{x}-\\mu}{\\sigma}\n\\]\nDado esto, se sabe que en una distribución normal:\n\nAproximadamente el 68% de los valores se encuentran entre \\(\\mu \\pm \\sigma\\).\nAproximadamente el 95% entre \\(\\mu \\pm 2\\sigma\\).\nAproximadamente el 99% entre \\(\\mu \\pm 3\\sigma\\).\n\nEl siguiente gráfico ilustra lo explicado anteriormente:\n\n\n\n\n\n\n\n\nUn IC al 95% no significa que haya un 95% de probabilidad de que el parámetro esté dentro de un único intervalo calculado. Lo correcto es decir que, si repitiéramos muchas veces el procedimiento muestral, el 95% de los intervalos construidos de esa forma contendrían el verdadero valor del parámetro.\n¿Cómo se interpreta un IC?\nSi repitiéramos el muestreo muchas veces, tomando muestras del mismo tamaño y construyendo un IC en cada caso, aproximadamente el \\(100 * (1 − \\alpha)\\%\\) de esos intervalos contendrían el valor real del parámetro. Por ejemplo, un IC al 95% implica que, en el largo plazo, el 95% de los intervalos construidos con este método contendrán el valor verdadero.\nLa amplitud del IC está determinada por la precisión de la estimación, que se calcula como el producto entre el coeficiente de confiabilidad (vinculado al nivel de confianza) y el error estándar. La fórmula general para construir un intervalo de confianza es:\n\\[ IC = estimador~puntual \\pm (coeficiente~de~confiabilidad) * (error~ estandar) \\]\nEn el caso de la media:\n\nAumento del nivel de confianza: Si se incrementa el nivel de confianza (por ejemplo, del 95% al 99%), el coeficiente de confiabilidad aumenta (por ejemplo, de 1.96 a 2.58), lo que produce un intervalo más amplio.\n\nReducción del error estándar: Si se mantiene fijo el nivel de confianza, reducir la amplitud del IC requiere disminuir el error estándar. Para la media, este se calcula como:\n\\[ SE = \\frac{\\sigma}{\\sqrt{n}} \\]\ny considerando que \\(\\sigma\\) es constante, la única forma de disminuir el error estándar es aumentando el tamaño muestral (\\(n\\)).\n\n\nEl cálculo de los intervalos de confianza se basa en las distribuciones muestrales de los estimadores y en el error estándar correspondiente. Aunque las fórmulas pueden parecer complejas, los paquetes estadísticos (como R) permiten calcularlos de forma automática. Lo esencial es comprender de qué depende la amplitud del IC (nivel de confianza, error estándar y tamaño de la muestra) y cómo cada uno de estos factores influye en la precisión de la estimación.",
    "crumbs": [
      "Introducción a la Revisión Sistemática con Meta-análisis",
      "Material Introductorio",
      "Introducción a la inferencia estadística"
    ]
  },
  {
    "objectID": "extras/intro_inferencia.html#pruebas-de-hipótesis",
    "href": "extras/intro_inferencia.html#pruebas-de-hipótesis",
    "title": "Introducción a la inferencia estadística",
    "section": "Pruebas de Hipótesis",
    "text": "Pruebas de Hipótesis\nLas pruebas de hipótesis (también conocidas como tests o contrastes de hipótesis) permiten tomar decisiones sobre una población a partir de los datos obtenidos de una muestra.\nAntes de profundizar en los aspectos estadísticos, es importante distinguir entre dos tipos de hipótesis:\n\nHipótesis de investigación: representan la pregunta o problema que motiva el estudio.\nHipótesis estadística: es la formulación que puede ser evaluada mediante técnicas de estadística inferencial.\n\nEl contraste de hipótesis se basa en la comparación de dos hipótesis estadísticas:\n\nHipótesis nula (\\(H_0\\)): sostiene que no existen diferencias entre los grupos comparados (por ejemplo, \\(\\mu = \\mu_0\\)​); por lo tanto, cualquier diferencia observada se debe únicamente al azar.\nHipótesis alternativa (\\(H_1\\)): plantea que existen diferencias entre grupos (por ejemplo, \\(\\mu \\neq \\mu_0,~ \\mu &gt; \\mu_0~ ó~ \\mu &lt; \\mu_0\\)). Generalmente es la formulación matemática de nuestra hipótesis de investigación y es complementaria de \\(H_0\\). No se acepta ni se refuta de manera directa.\n\nEl método estadístico nos permite cuantificar la diferencia entre grupos bajo el supuesto de que, si repitiésemos el experimento infinitas veces y obtuviésemos todas las muestras posibles del mismo tamaño, las diferencias entre grupos “iguales” seguirían una distribución muestral teórica. A partir de esta distribución, se define un valor límite (por ejemplo, que abarca el 95% o el 99% de las diferencias esperadas).\n\nSi la diferencia observada excede ese límite, se considera demasiado grande para ser atribuida al azar y se rechaza la hipótesis nula (\\(H_0\\)).\nSi la diferencia cae dentro del rango esperado, no se rechaza \\(H_0\\), ya que podría deberse al azar. En estos casos, se concluye que los grupos “no son diferentes”, lo que no implica que “sean iguales”, ya que la variabilidad muestral impide demostrar una igualdad exacta.\n\nLos contrastes de hipótesis suelen realizarse suponiendo que se conoce a priori la distribución de la población y que se extrae una muestra aleatoria de la misma.\nEstadístico de prueba\nEs el valor calculado a partir de los datos muestrales que se utiliza para tomar la decisión respecto de \\(H_0\\). Cada situación tiene un estadístico adecuado cuya magnitud, al compararse con su distribución teórica permite determinar si las diferencias observadas son atribuibles al azar. Por ejemplo:\n\nPara variables categóricas se utiliza el estadístico chi-cuadrado (\\(\\chi^2\\)).\nPara variables numéricas, se emplean distribuciones como la normal (\\(Z\\)) o t de Student (\\(t\\)).\nErrores\nEn el razonamiento de los contrastes de hipótesis existen dos posibles errores:\n\nError tipo I (\\(\\alpha\\)): ocurre cuando se rechaza la hipótesis nula siendo esta verdadera. Es decir, se concluye erróneamente que existe una diferencia cuando en realidad no la hay. Para minimizar este riesgo, se elige un \\(\\alpha\\) pequeño (por ejemplo, 0,01; 0,05 o 0,10).\nError tipo II (\\(\\beta\\)): ocurre cuando no se rechaza la hipótesis nula siendo esta falsa, es decir, se falla en detectar una diferencia real. El valor de \\(\\beta\\) depende del valor real del parámetro, y suele ser mayor que \\(\\alpha\\); sin embargo, no se conoce con certeza una vez realizada la prueba.\n\nUna vez finalizado el análisis, no es posible saber si se ha cometido alguno de estos errores, ya que el verdadero estado de la población es desconocido. Sin embargo, si se ha utilizado un \\(\\alpha\\) bajo, podemos tener mayor confianza en que, si se rechazó \\(H_0\\), el error tipo I es poco probable.\nNivel de significancia\nEl nivel de significación (\\(\\alpha\\)) representa la probabilidad de cometer un error tipo I, es decir, rechazar \\(H_0\\) cuando en realidad es verdadera. Se define antes del análisis (comúnmente 0,05 o 0,01) y determina el límite entre la región de no rechazo y la región crítica.\nRegión crítica\nSe denomina región crítica (o región de rechazo) al conjunto de valores del estadístico de prueba que llevan al rechazo de \\(H_0\\). Esta región se define según el nivel de significación (\\(\\alpha\\)), e incluye los valores extremos del estadístico que serían poco probables si \\(H_0\\) fuera cierta. En una representación gráfica, la región crítica se ubica en una o ambas colas de la distribución, dependiendo del tipo de prueba\n\n\n\n\n\n\n\n\nLa regla de decisión es la siguiente:\n\nSi el valor calculado del estadístico cae dentro de la región crítica, se rechaza \\(H_0\\) y se concluye que las diferencias observadas son estadísticamente significativas.\nSi el valor no cae en la región crítica, no se rechaza \\(H_0\\). En ese caso, las diferencias observadas pueden explicarse por el azar, y no se consideran estadísticamente significativas.\nValor crítico\nEl valor crítico o p-valor es la probabilidad de obtener un resultado igual o más extremo que el observado, bajo la suposición de que \\(H_0\\) es verdadera. Representa el menor nivel de \\(\\alpha\\) para el cual puede rechazarse \\(H_0\\).\nSi el valor p es muy pequeño, indica que el resultado observado sería poco probable si \\(H_0\\) fuera cierta, por lo tanto, se rechaza la hipótesis nula.\nLa regla práctica es:\n\nSi \\(p \\leq \\alpha\\), se rechaza \\(H_0\\).\nSi \\(p &gt; \\alpha\\), no se rechaza \\(H_0\\).\nTipos de contraste\nLos contrastes de hipótesis se clasifican según la forma de la hipótesis alternativa (\\(H_1\\)). Esta clasificación determina si la prueba es unilateral (de cola izquierda o derecha) o bilateral (de dos colas).\nTest de cola izquierda\nLa hipótesis alternativa plantea que la media del primer grupo es significativamente menor que la del segundo:\n\\[\nH_1: \\mu_1 &lt; \\mu_2\n\\]\nLa región crítica se encuentra en el extremo izquierdo de la distribución. Todo el área crítica tiene un tamaño \\(\\alpha\\) con un valor crítico de \\(-1,645\\).\n\n\n\n\n\n\n\n\nTest de cola derecha\nLa hipótesis alternativa establece que la media del primer grupo es significativamente mayor que la del segundo:\n\\[ H_1: \\mu_1 &gt; \\mu_2 \\]\nLa región crítica se concentra en el extremo derecho de la distribución y toda el área crítica tiene un tamaño \\(\\alpha\\) con un valor crítico de \\(1,645\\).\n\n\n\n\n\n\n\n\nPruebas bilaterales\nLa hipótesis alternativa afirma que existen diferencias entre los grupos, sin especificar la dirección:\n\\[\nH_1: \\mu_1 \\neq \\mu_2\n\\]\nLa región crítica se divide entre ambos extremos de la distribución, con valores críticos de \\(\\pm 1,96\\). El nivel de significación total (\\(\\alpha\\)) se reparte en partes iguales entre las dos colas (\\(\\alpha/2\\) en cada una), lo que implica un 2,5% de probabilidad en cada cola si \\(H_0\\) es verdadera.\n\n\n\n\n\n\n\n\nPotencia estadística\nLa potencia estadística es la probabilidad de rechazar la hipótesis nula (\\(H_0\\)) cuando esta es falsa, es decir, de detectar un efecto real. Se calcula como \\(1 - \\beta\\), donde \\(\\beta\\) es la probabilidad de cometer un error de tipo II. Aumenta con el tamaño muestral, disminuye con la varianza, y depende de la magnitud del efecto que se desea detectar.\nMientras que \\(\\alpha\\) se fija antes del análisis, \\(\\beta\\) varía según el valor real del parámetro. La potencia se considera adecuada cuando alcanza al menos el 80%, lo que implica un 20% de riesgo de no detectar una diferencia real.\nNo es posible reducir simultáneamente \\(\\alpha\\) y \\(\\beta\\), por lo que el diseño de una prueba debe buscar un equilibrio entre ambos errores. La potencia proporciona un control adicional en la toma de decisiones, ya que no basta con obtener un valor p pequeño: también se requiere una potencia suficiente para respaldar la conclusión.\nLa siguiente tabla resume las posibles situaciones en un contraste de hipótesis:\n\n\n\n\n\nNo rechazar H0\nRechazar H0\n\n\n\nH0 es cierta\nCorrecto (1-α)\nError tipo I (α)\n\n\nH0 es falsa\nError tipo II (β)\nCorrecto (1-β)",
    "crumbs": [
      "Introducción a la Revisión Sistemática con Meta-análisis",
      "Material Introductorio",
      "Introducción a la inferencia estadística"
    ]
  },
  {
    "objectID": "extras/intro_inferencia.html#aplicaciones-e-interpretación",
    "href": "extras/intro_inferencia.html#aplicaciones-e-interpretación",
    "title": "Introducción a la inferencia estadística",
    "section": "Aplicaciones e Interpretación",
    "text": "Aplicaciones e Interpretación\nLa inferencia estadística permite responder preguntas de investigación tales como:\n\n¿Es significativa la diferencia entre dos medias?\n¿Existe una relación entre dos variables?\n¿Cómo se distribuyen los datos respecto a un parámetro de interés?\n\nAl aplicar estos métodos, es crucial tener en cuenta la calidad y representatividad de la muestra, así como la validez de las asunciones subyacentes (normalidad, homogeneidad de varianzas, etc.).\n\n\n\n\n\n\nEste apunte sintetiza los conceptos esenciales y las herramientas básicas para llevar a cabo un análisis inferencial, que sirve de base para la interpretación de modelos y resultados en análisis cuantitativos. Quienes necesiten profundizar más en los temas, les recomendamos consultar las siguientes fuentes:\n\nManual de Epidemiología: Fundamentos, Métodos y Aplicaciones (Instituto Nacional de Epidemiología 2015): Capítulo 3.\nEstadística 12A Edición (Triola 2018): Capítulos 8 y 9.\n\n\n\n\n\nRíus Díaz et al. (2012)\nDaniel (2002)\nGlantz, S (2006)\nAgresti (2015)",
    "crumbs": [
      "Introducción a la Revisión Sistemática con Meta-análisis",
      "Material Introductorio",
      "Introducción a la inferencia estadística"
    ]
  },
  {
    "objectID": "extras/intro_R.html",
    "href": "extras/intro_R.html",
    "title": "Introducción a R y RStudio",
    "section": "",
    "text": "Artwork por @allison_horst",
    "crumbs": [
      "Introducción a la Revisión Sistemática con Meta-análisis",
      "Material Introductorio",
      "Introducción a R y RStudio"
    ]
  },
  {
    "objectID": "extras/intro_R.html#qué-es-r",
    "href": "extras/intro_R.html#qué-es-r",
    "title": "Introducción a R y RStudio",
    "section": "¿Qué es R?",
    "text": "¿Qué es R?\nR (2025) es un lenguaje de programación interpretado, orientado a objetos, multiplataforma y de código abierto, diseñado específicamente para el análisis estadístico de datos. Cuenta con estructuras y sintaxis propias, y una extensa colección de funciones desarrolladas para aplicaciones estadísticas.\n\nComo lenguaje orientado a objetos, todo lo que manipulamos —variables, funciones, conjuntos de datos, resultados— se considera un objeto, lo que aporta flexibilidad y simplicidad al trabajo con información.\nAl ser un lenguaje interpretado, los scripts se ejecutan directamente sin necesidad de compilación, lo que favorece la exploración interactiva.\nR es multiplataforma: se puede instalar y ejecutar en Linux, Windows y macOS con un comportamiento consistente.\nAdemás, es software libre distribuido bajo licencia GNU-GPL, lo que permite su uso, modificación y redistribución sin restricciones.\n\nPara instalarlo en Windows, se debe descargar el instalador desde el sitio oficial del proyecto R (CRAN) y seguir los pasos guiados. Una vez finalizada la instalación, R estará listo para usarse desde cualquier entorno compatible. Sin embargo, si no se cuenta con experiencia previa en programación, no se recomienda utilizar R directamente desde su consola nativa.",
    "crumbs": [
      "Introducción a la Revisión Sistemática con Meta-análisis",
      "Material Introductorio",
      "Introducción a R y RStudio"
    ]
  },
  {
    "objectID": "extras/intro_R.html#qué-es-rstudio",
    "href": "extras/intro_R.html#qué-es-rstudio",
    "title": "Introducción a R y RStudio",
    "section": "¿Qué es RStudio?",
    "text": "¿Qué es RStudio?\nRStudio Desktop (2025, Posit Software) es un entorno de desarrollo integrado (IDE) diseñado específicamente para facilitar el trabajo con R. Proporciona una interfaz unificada que incluye editor de scripts, consola de R, entorno, explorador de archivos, panel de gráficos y ayuda, entre otros, optimizando el flujo de trabajo.\n\n\n\n\nEntre sus principales ventajas se encuentran:\n\n\nAsistente de código: al escribir en el editor o la consola, la tecla Tab activa el autocompletado de funciones, nombres de objetos y argumentos, agilizando la escritura y reduciendo errores de sintaxis. En versiones recientes, el asistente también permite la previsualización de colores en los gráficos, resaltar los paréntesis de cierre en funciones anidadas con distintos colores y gestionar automáticamente la indentación del código.\n\n\n\nAyuda en línea: al posicionar el cursor sobre el nombre de una función en el editor y presionar F1, se accede directamente a la documentación correspondiente en el panel Help (habitualmente ubicado en la esquina inferior derecha).\n\n\n\nHistorial de comandos: en la consola, al usar las teclas de flecha arriba/abajo, se puede navegar por los comandos ejecutados durante la sesión actual. Además, el panel History (parte superior derecha) almacena los comandos de todas las sesiones previas, permitiendo reutilizarlos con un clic en To Console (Enter) o To Source (Shift + Enter), según se desee insertarlos en la consola o en el script activo.\n\n\n\nRStudio es multiplataforma, de código abierto, y permite una integración fluida con herramientas del ecosistema R, como R Markdown, Quarto, control de versiones y manejo de proyectos.\n\n\n\n\n\n\nUna vez instalados R y RStudio, ya contamos con todo lo necesario para comenzar a trabajar. Aunque instalamos ambos programas, en la práctica sólo necesitamos abrir RStudio, que utiliza a R como motor de ejecución.\n\n\n\nProyectos en RStudio\nLos proyectos de RStudio permiten organizar de forma estructurada todo el material asociado a un análisis: scripts, informes, bases de datos, imágenes, etc. Cada proyecto se vincula a una carpeta específica del sistema de archivos, y RStudio la utiliza como directorio de trabajo por defecto. Esto facilita la importación de datos y evita errores relacionados con rutas relativas o absolutas.\nPara crear un nuevo proyecto, se puede utilizar el menú File &gt; New Project… o el acceso directo New Project… ubicado en la esquina superior derecha de la interfaz. En ambos casos, se abre un asistente con tres opciones:\n\n\n\n\n\nNew Directory: crea una nueva carpeta para el proyecto. Es la opción más habitual.\nExisting Directory: vincula el proyecto a una carpeta ya existente que contenga archivos previos.\nVersion Control: permite clonar un repositorio (Git o SVN). Esta opción no se utilizará en este curso.\n\nTrabajar con proyectos garantiza que, al importar archivos, RStudio los busque automáticamente dentro de la carpeta correspondiente. Además, cada proyecto mantiene su propio entorno de trabajo, lo que significa que al cerrar o cambiar de proyecto, se conserva la configuración previa sin interferencias.\nCuando un proyecto ya existe, dentro de la carpeta encontraremos un archivo con extensión .Rproj que al ejecutarlo abre una nueva sesión de RStudio con el proyecto activo. Otras opciones son abrir desde File &gt; Open Project… o desde el ícono  en la esquina superior derecha de RStudio. Esta última opción también mantiene un historial de los proyectos abiertos recientemente, lo que permite acceder rápidamente a ellos mediante accesos directos.\nScripts en RStudio\nUn script es un archivo de texto plano que contiene instrucciones escritas en R. Permite guardar, reutilizar y compartir el código, favoreciendo la reproducibilidad del análisis.\n\nCrear un nuevo script: podemos crear un script desde el menú File &gt; New File &gt; R Script (acceso rápido: Ctrl + Shift + N) o haciendo clic en el ícono de la hoja (📄) con símbolo “+” en la barra de herramientas.\nEjecutar código: la forma habitual de ejecutar un script es línea por línea, con Ctrl + Enter o el botón Run (). El cursor debe estar en cualquier punto de la línea a ejecutar. Tras la ejecución, el cursor avanza automáticamente a la siguiente línea de código.\nEditar un script: las líneas del script pueden editarse directamente. Cada vez que se realiza una modificación, es necesario volver a ejecutar esas líneas para actualizar los resultados.\nGuardar un script: Para guardar los cambios, se puede usar el ícono del diskette (💾), el menú File &gt; Save, o el atajo Ctrl + S. Para guardar con otro nombre o ubicación, utilizar File &gt; Save As…\nAbrir un script existente: Los archivos de script tienen extensión .R. Pueden abrirse desde el panel File &gt; Open File…, el panel Files o usando el atajo de teclado Ctrl + O. Al abrirse, se muestran en una nueva pestaña del editor.",
    "crumbs": [
      "Introducción a la Revisión Sistemática con Meta-análisis",
      "Material Introductorio",
      "Introducción a R y RStudio"
    ]
  },
  {
    "objectID": "extras/intro_R.html#funciones",
    "href": "extras/intro_R.html#funciones",
    "title": "Introducción a R y RStudio",
    "section": "Funciones",
    "text": "Funciones\nEn R, los comandos básicos se denominan funciones. Muchas de ellas están incluidas en el núcleo del lenguaje (conocido como R base) y se denominan integradas, mientras que otras forman parte de paquetes adicionales.\nCada función tiene un nombre y suele requerir uno o más argumentos (también llamados parámetros), que se escriben entre paréntesis y separados por comas. Incluso las funciones que no requieren argumentos deben escribirse con paréntesis vacíos.\n\n# Sintaxis general\nnombre_de_la_función(arg1, arg2, ...)\n\nLas funciones siempre ejecutan una acción o devuelven un valor, que puede ser visualizado, almacenado o utilizado en otras operaciones.\nReglas de sintaxis\nDado que R es un lenguaje interpretado, la sintaxis debe ser estrictamente correcta. Algunos puntos clave:\n\n\nLos argumentos pueden escribirse con el nombre del parámetro seguido de un signo igual:\n\nfuncion(arg1 = 32, arg2 = 5, arg3 = 65)\n\n\n\nTambién se pueden omitir los nombres y escribir directamente los valores. En ese caso, el orden importa y debe coincidir con el definido en la documentación de la función:\n\nfuncion(32, 5, 65)\n\n\nTipos de argumentos\nLos argumentos pueden ser:\n\nValores numéricos: 3, 10.5\nLógicos: TRUE, FALSE\nEspeciales: NA (faltante), NULL, Inf\nTexto: debe escribirse entre comillas, por ejemplo \"menos\"\n\nObjetos: como variables previamente creadas (x, datos, etc.)\n\nfuncion(arg1 = 3, arg2 = NA, arg3 = TRUE, arg4 = \"menos\", arg5 = x)",
    "crumbs": [
      "Introducción a la Revisión Sistemática con Meta-análisis",
      "Material Introductorio",
      "Introducción a R y RStudio"
    ]
  },
  {
    "objectID": "extras/intro_R.html#paquetes",
    "href": "extras/intro_R.html#paquetes",
    "title": "Introducción a R y RStudio",
    "section": "Paquetes",
    "text": "Paquetes\nR se compone de un sistema base y de paquetes (librerías) que amplían sus funcionalidades. Un paquete es una colección de funciones, datos y documentación que extiende las capacidades del lenguaje para tareas específicas.\nExisten distintos tipos de paquetes:\n\nBase: se instalan y activan junto con R.\nRecomendados: también se instalan por defecto, pero requieren ser cargados manualmente.\nAdicionales: más de 17.000 disponibles en el repositorio oficial CRAN, listos para ser instalados según necesidad. Además, algunos paquetes pueden descargarse desde otros repositorios como GitHub y Bioconductor.\n\nAl ser open source, cualquier persona puede desarrollar y publicar nuevos paquetes. Esto convierte a R en una herramienta en constante evolución.\nInstalación\nLos paquetes pueden instalarse desde R o RStudio o (si no hay acceso a internet o trabajamos con conexiones de uso medido) desde archivos locales .zip o .tar.gz, descargados previamente desde CRAN u otros repositorios.\nEn RStudio, los paquetes se gestionan desde la pestaña Packages (bloque inferior derecho). Para instalar uno nuevo:\n\nHacer clic en , se abrirá una ventana emergente:\n\n\n\n\n\n\nEspecificar el nombre del paquete a instalar.\nMarcar la opción Install dependencies para incluir automáticamente sus dependencias.\nAl presionar el botón Install, R internamente traduce esta acción a la función install.packages().\n\nLos paquetes deben instalarse una única vez por computadora cuando se los va a utilizar por primera vez. A partir de entonces, sólo es necesario cargarlos al inicio de cada sesión mediante la función library():\n\nlibrary(nombre_del_paquete)\n\nDependencias\nMuchos paquetes requieren funciones de otros paquetes para funcionar. Estos paquetes (dependencias) deben estar instaladas previamente, de lo contrario la ejecución de una función puede fallar por no encontrar otra interna. Por eso, es recomendable dejar seleccionada la opción Install dependencies al instalar.\nPaquetes a instalar\nPara trabajar durante el curso, deberemos instalar los siguientes paquetes y sus dependencias:\n\n# Manejo de datos\ninstall.packages(\"tidyverse\", dependencies = T)\n\ninstall.packages(\"janitor\", dependencies = T)\n\n# Modelos de meta-análisis\ninstall.packages(\"metafor\", dependencies = T)\n\ninstall.packages(\"meta\", dependencies = T)\n\n# Paletas aptas para daltonismo\ninstall.packages(\"scico\", dependencies = T)\n\n# Visualización avanzada\nremotes::install_github(\"daniel1noble/orchaRd\")",
    "crumbs": [
      "Introducción a la Revisión Sistemática con Meta-análisis",
      "Material Introductorio",
      "Introducción a R y RStudio"
    ]
  },
  {
    "objectID": "extras/intro_R.html#objetos",
    "href": "extras/intro_R.html#objetos",
    "title": "Introducción a R y RStudio",
    "section": "Objetos",
    "text": "Objetos\nEn R, los datos, resultados, funciones y estructuras se almacenan en objetos, que constituyen la unidad fundamental de trabajo en el lenguaje.\nPara crear un objeto, se utiliza el operador de asignación &lt;- (también se acepta = aunque no se recomienda) para asignar un valor a un nombre:\n\nx &lt;- 10 \n\nEn este ejemplo, el número 10 se asigna al objeto llamado x. A partir de ese momento, podemos utilizar x en otras operaciones:\n\nx + 5  # devuelve 15\n\nLos nombres de objetos:\n\nDeben comenzar con una letra y pueden incluir letras, números, puntos (.) y guiones bajos (_).\nNo deben coincidir con palabras reservadas a funciones del lenguaje.\nSon sensibles a mayúsculas/minúsculas: Edad y edad son objetos distintos.\n\nLos objetos contenedores de datos más simples pertenecen a cinco clases que se denominan atómicas y que son los siguientes tipos de datos:\n\ninteger: números enteros.\nnumeric: números reales (también llamados “doble precisión”).\ncomplex: números complejos.\ncharacter: cadenas de texto o caracteres.\n\nlogical: valores lógicos (TRUE o FALSE).\n\nnúmero &lt;- 25           # entero\ndecimal &lt;- 3.14        # numérico\ntexto &lt;- \"Hola\"        # carácter\nlogico &lt;- TRUE         # lógico (booleano)\n\n\n\nAdemás de los tipos atómicos, los datos pueden organizarse en estructuras contenedoras que permiten agrupar múltiples valores:\n\nVector: conjunto de elementos del mismo tipo, ordenados linealmente. Se construye con la función c().\nLista: colección ordenada de objetos de distinto tipo o longitud, creada con list().\n\nDataframe: estructura bidimensional donde cada columna es un vector del mismo largo (generalmente del mismo tipo). Se construye con data.frame() o, en el tidyverse, con tibble().\n\n# Vector\nvector  &lt;- c(1, 2, 3, 4)\n\n# Lista\nlista &lt;- list(vector, \"elemento_2\") # lista\n\n# Dataframe (R base)\ndataframe &lt;- data.frame(\n  var1 = vector,\n  var2 = vector + 5,\n  var3 = vector * vector^2\n)\n\n# Dataframe (tidyverse)\ntibble &lt;- tibble(\n  var1 = vector,\n  var2 = vector + 5,\n  var3 = vector * vector^2\n)",
    "crumbs": [
      "Introducción a la Revisión Sistemática con Meta-análisis",
      "Material Introductorio",
      "Introducción a R y RStudio"
    ]
  },
  {
    "objectID": "extras/intro_R.html#archivos-de-datos",
    "href": "extras/intro_R.html#archivos-de-datos",
    "title": "Introducción a R y RStudio",
    "section": "Archivos de datos",
    "text": "Archivos de datos\nR permite importar tablas de datos desde diversos formatos, tanto utilizando funciones de R base como funciones provistas por paquetes específicos.\nEl formato más común es el texto plano (ASCII), donde los valores están organizados en columnas separadas por caracteres delimitadores. Los separadores más habituales incluyen:\n\nComa (,)\nPunto y coma (;)\nTabulación (\\t)\nBarra vertical (|)\n\nEstos archivos suelen tener una cabecera (header) en la primera fila con los nombres de las variables, y cada columna debe contener datos del mismo tipo (números, texto, lógicos, etc.).\nPara importar correctamente un archivo es importante conocer su estructura:\n\nSi incluye o no cabecera.\nQué carácter se usa como separador.\nEl tipo de codificación (UTF-8, Latin1, etc.).\n\nDado que son archivos de texto, pueden visualizarse con editores simples como el Bloc de Notas o desde RStudio, lo que facilita su inspección previa.\nPara cargar los datos desde un archivo de texto plano o una hoja de cálculo de Excel usamos el código:\n\ndatos &lt;- read.xxx(\"mis_datos.txt\")\n\n(Se debe reemplazar read.xxx() por la función correspondiente: read.table(), read.csv(), read_delim(), read_excel(), etc., según el caso).\nR también permite cargar bases de datos incluidas en paquetes instalados mediante:\n\ndata(nombre_datos)\n\ndatos &lt;- nombre_datos",
    "crumbs": [
      "Introducción a la Revisión Sistemática con Meta-análisis",
      "Material Introductorio",
      "Introducción a R y RStudio"
    ]
  },
  {
    "objectID": "extras/intro_R.html#buenas-prácticas",
    "href": "extras/intro_R.html#buenas-prácticas",
    "title": "Introducción a R y RStudio",
    "section": "Buenas prácticas",
    "text": "Buenas prácticas\nAdoptar buenas prácticas desde el inicio mejora la reproducibilidad, facilita el trabajo colaborativo y reduce errores. Algunas recomendaciones clave son:\n\nTrabajar siempre dentro de un proyecto de RStudio (.Rproj). Esto permite organizar los archivos, mantener rutas relativas consistentes y acceder a funcionalidades específicas como control de versiones o panel de archivos integrados.\nIncluir al comienzo de cada script las líneas de activación de paquetes necesarios, utilizando la función library().\nCargar los datos una vez activados los paquetes, para garantizar que todas las funciones requeridas estén disponibles.\nDocumentar el código mediante comentarios iniciados con #. Esto permite entender qué hace cada bloque de código, facilitando futuras modificaciones o revisiones.\nUsar espacios e indentación adecuada para mejorar la legibilidad. Esto es especialmente importante en estructuras anidadas (como condicionales, bucles o funciones).\n\nUna guía de estilo ampliamente recomendada —aunque no oficial— es la de tidyverse. Incluye ejemplos concretos de buenas y malas prácticas para nombrar variables, manejar líneas largas, usar sangrías, entre otros aspectos. Puede consultarse en: https://style.tidyverse.org/\n\n\n\n\n\n\nImportante\n\n\n\nEste apunte ofrece un resumen general para quienes deseen repasar los aspectos básicos de R y RStudio.\nSi no cuentan con experiencia previa en R y necesitan una introducción más detallada, podés consultar los siguientes recursos:\n\nCurso de Epidemiología Nivel Avanzado - Unidad 1: Introducción a R\nEpiR Handbook – secciones Aspectos básicos y Gestión de datos.\n\nAnte cualquier duda específica, recuerden que pueden comunicarse con los/as docentes del curso.",
    "crumbs": [
      "Introducción a la Revisión Sistemática con Meta-análisis",
      "Material Introductorio",
      "Introducción a R y RStudio"
    ]
  },
  {
    "objectID": "unidad_2/01_intro.html",
    "href": "unidad_2/01_intro.html",
    "title": "Introducción",
    "section": "",
    "text": "El meta-análisis es una herramienta estadística que permite sintetizar cuantitativamente la evidencia proveniente de investigaciones independientes que abordan un mismo problema de investigación. Se lo ha definido como un “análisis de análisis” (Glass 1976), ya que su unidad de análisis no son individuos ni poblaciones, sino estudios científicos.\nSu objetivo principal es proporcionar un estimador numérico que resuma los resultados de los estudios incluidos, lo que permite evaluar la magnitud del efecto de una intervención o la relación entre variables en distintos contextos (Harrer et al. 2021). Es importante destacar que los meta-análisis son adecuados exclusivamente para investigaciones cuantitativas y, en general, requieren que los estudios analizados compartan un diseño similar y estimen medidas de asociación comparables.\nA continuación, se resumen algunas de las principales ventajas y limitaciones del meta-análisis:\n\n\n\n\nVentajas\nDesventajas\n\n\n\nPermite una síntesis cuantitativa de la evidencia disponible.\nLa validez de los resultados depende de la calidad metodológica de los estudios incluidos.\n\n\nAumenta la potencia estadística al combinar los datos de múltiples estudios.\nPuede estar afectado por sesgos de publicación.\n\n\nMejora la precisión de los estimadores al reducir la variabilidad aleatoria.\nLa heterogeneidad entre estudios puede dificultar la interpretación de los resultados.\n\n\nPermite identificar patrones no evidentes en estudios individuales.\nRequiere una metodología rigurosa y criterios estrictos de selección de estudios.\n\n\nEvalúa la consistencia de los resultados en diferentes poblaciones y contextos.\nNo corrige errores metodológicos de los estudios primarios.",
    "crumbs": [
      "Introducción a la Revisión Sistemática con Meta-análisis",
      "Meta-análisis",
      "Introducción"
    ]
  },
  {
    "objectID": "unidad_2/01_intro.html#qué-es-un-meta-análisis",
    "href": "unidad_2/01_intro.html#qué-es-un-meta-análisis",
    "title": "Introducción",
    "section": "",
    "text": "El meta-análisis es una herramienta estadística que permite sintetizar cuantitativamente la evidencia proveniente de investigaciones independientes que abordan un mismo problema de investigación. Se lo ha definido como un “análisis de análisis” (Glass 1976), ya que su unidad de análisis no son individuos ni poblaciones, sino estudios científicos.\nSu objetivo principal es proporcionar un estimador numérico que resuma los resultados de los estudios incluidos, lo que permite evaluar la magnitud del efecto de una intervención o la relación entre variables en distintos contextos (Harrer et al. 2021). Es importante destacar que los meta-análisis son adecuados exclusivamente para investigaciones cuantitativas y, en general, requieren que los estudios analizados compartan un diseño similar y estimen medidas de asociación comparables.\nA continuación, se resumen algunas de las principales ventajas y limitaciones del meta-análisis:\n\n\n\n\nVentajas\nDesventajas\n\n\n\nPermite una síntesis cuantitativa de la evidencia disponible.\nLa validez de los resultados depende de la calidad metodológica de los estudios incluidos.\n\n\nAumenta la potencia estadística al combinar los datos de múltiples estudios.\nPuede estar afectado por sesgos de publicación.\n\n\nMejora la precisión de los estimadores al reducir la variabilidad aleatoria.\nLa heterogeneidad entre estudios puede dificultar la interpretación de los resultados.\n\n\nPermite identificar patrones no evidentes en estudios individuales.\nRequiere una metodología rigurosa y criterios estrictos de selección de estudios.\n\n\nEvalúa la consistencia de los resultados en diferentes poblaciones y contextos.\nNo corrige errores metodológicos de los estudios primarios.",
    "crumbs": [
      "Introducción a la Revisión Sistemática con Meta-análisis",
      "Meta-análisis",
      "Introducción"
    ]
  },
  {
    "objectID": "unidad_2/01_intro.html#estimadores-de-efecto",
    "href": "unidad_2/01_intro.html#estimadores-de-efecto",
    "title": "Introducción",
    "section": "Estimadores de efecto",
    "text": "Estimadores de efecto\nEn estudios individuales, suele asumirse que las variables de interés fueron medidas de manera uniforme en todos los participantes. Esto permite aplicar técnicas de estadística descriptiva, como el análisis exploratorio de datos (EDA), para caracterizar la muestra, explorar relaciones entre variables y ajustar modelos de regresión acordes a la estructura de los datos.\nSin embargo, en los meta-análisis esta suposición rara vez se cumple. Aún cuando los criterios de inclusión sean estrictos, los estudios pueden diferir en su diseño, población, medición de variables o definición de resultados. Por esta razón, no es posible sintetizar la evidencia con herramientas de la estadística tradicional.\nPara integrar los resultados de diferentes estudios, los meta-análisis utilizan estimadores de efecto (Page et al. 2021), también conocidos como effect size o tamaño del efecto (Harrer et al. 2021)1. En algunos casos, estos valores pueden extraerse directamente de los artículos; sin embargo, a menudo es necesario calcularlos a partir de los datos reportados.\nUn buen estimador de efecto debe cumplir con las siguientes condiciones:\n\nComparable: debe ser consistente entre los estudios incluidos.\nComputable: debe poder calcularse a partir de la información disponible.\nConfiable: debe permitir la estimación de su error estándar.\nInterpretable: debe responder de manera clara a la pregunta de investigación.\n\nDesde una perspectiva estadística, los estimadores de efecto son análogos a los coeficientes en modelos de regresión o a las medidas de asociación en estudios epidemiológicos, ya que cuantifican la fuerza y dirección de la relación entre dos variables.\nEntre los estimadores de efecto más utilizados en investigación epidemiológica y aplicables a modelos de meta-análisis se encuentran: proporciones, tasas de incidencia, coeficientes de correlación, diferencias de medias, odds ratio (OR), riesgos relativos (RR) y hazard ratio.\nEn la próxima sección describiremos la estructura de los modelos de meta-análisis de efectos fijos y de efectos aleatorios. Luego, exploraremos cómo se ajustan estos modelos según cada tipo de estimador epidemiológico y con su implementación práctica en R.",
    "crumbs": [
      "Introducción a la Revisión Sistemática con Meta-análisis",
      "Meta-análisis",
      "Introducción"
    ]
  },
  {
    "objectID": "unidad_2/01_intro.html#footnotes",
    "href": "unidad_2/01_intro.html#footnotes",
    "title": "Introducción",
    "section": "Notas",
    "text": "Notas\n\nSi bien ambos términos son equivalentes, usaremos la denominación “estimador de efecto” presente en las normas PRISMA para evitar confusiones con los effect size calculados en los modelos de regresión tradicionales, que evalúan la magnitud del efecto de una variable independiente.↩︎",
    "crumbs": [
      "Introducción a la Revisión Sistemática con Meta-análisis",
      "Meta-análisis",
      "Introducción"
    ]
  },
  {
    "objectID": "unidad_2/03_tipos_estimador.html",
    "href": "unidad_2/03_tipos_estimador.html",
    "title": "Estimadores de efecto",
    "section": "",
    "text": "En esta sección repasaremos los principales estimadores de efecto utilizados en estudios epidemiológicos, junto con ejemplos prácticos para su ajuste e interpretación en R.\nComenzaremos por cargar el paquete meta, que permite realizar análisis de efectos fijos y aleatorios, así como representar los resultados mediante gráficos tipo forest plot:\n\nlibrary(meta)\n\nLoading required package: metadat\n\n\nLoading 'meta' package (version 8.1-0).\nType 'help(meta)' for a brief overview.\n\n\n\nAttaching package: 'meta'\n\n\nThe following object is masked from 'package:parameters':\n\n    ci\n\n\nThe following object is masked from 'package:effectsize':\n\n    nnt\n\n\nThe following object is masked from 'package:bayestestR':\n\n    ci\n\n\nPara facilitar la exploración y manipulación de datos, utilizaremos funciones del paquete tidyverse(Wickham et al. 2019):\n\nlibrary(tidyverse)\n\nEn secciones anteriores, exploramos cómo personalizar los colores de los forest plot mediante los argumentos col.diamond y col.square. Para garantizar que los gráficos resultantes sean accesibles a personas con deficiencia en la percepción del color, emplearemos paletas adaptadas (colorblind-friendly) del paquete scico (Pedersen y Crameri 2023):\n\n# Cargar el paquete\nlibrary(scico)\n\n# Mostrar paletas categóricas disponibles\nscico_palette_show(categorical = TRUE)\n\n\n\n\n\n\n\n\nEn los ejemplos siguientes, emplearemos la paleta \"hawaii\", que genera un gradiente entre tonos magenta y turquesa:\n\n# Paleta colorblind-friendly\npal &lt;- scico(n = 3, palette = \"hawaii\")",
    "crumbs": [
      "Introducción a la Revisión Sistemática con Meta-análisis",
      "Meta-análisis",
      "Estimadores de efecto"
    ]
  },
  {
    "objectID": "unidad_2/03_tipos_estimador.html#introducción",
    "href": "unidad_2/03_tipos_estimador.html#introducción",
    "title": "Estimadores de efecto",
    "section": "",
    "text": "En esta sección repasaremos los principales estimadores de efecto utilizados en estudios epidemiológicos, junto con ejemplos prácticos para su ajuste e interpretación en R.\nComenzaremos por cargar el paquete meta, que permite realizar análisis de efectos fijos y aleatorios, así como representar los resultados mediante gráficos tipo forest plot:\n\nlibrary(meta)\n\nLoading required package: metadat\n\n\nLoading 'meta' package (version 8.1-0).\nType 'help(meta)' for a brief overview.\n\n\n\nAttaching package: 'meta'\n\n\nThe following object is masked from 'package:parameters':\n\n    ci\n\n\nThe following object is masked from 'package:effectsize':\n\n    nnt\n\n\nThe following object is masked from 'package:bayestestR':\n\n    ci\n\n\nPara facilitar la exploración y manipulación de datos, utilizaremos funciones del paquete tidyverse(Wickham et al. 2019):\n\nlibrary(tidyverse)\n\nEn secciones anteriores, exploramos cómo personalizar los colores de los forest plot mediante los argumentos col.diamond y col.square. Para garantizar que los gráficos resultantes sean accesibles a personas con deficiencia en la percepción del color, emplearemos paletas adaptadas (colorblind-friendly) del paquete scico (Pedersen y Crameri 2023):\n\n# Cargar el paquete\nlibrary(scico)\n\n# Mostrar paletas categóricas disponibles\nscico_palette_show(categorical = TRUE)\n\n\n\n\n\n\n\n\nEn los ejemplos siguientes, emplearemos la paleta \"hawaii\", que genera un gradiente entre tonos magenta y turquesa:\n\n# Paleta colorblind-friendly\npal &lt;- scico(n = 3, palette = \"hawaii\")",
    "crumbs": [
      "Introducción a la Revisión Sistemática con Meta-análisis",
      "Meta-análisis",
      "Estimadores de efecto"
    ]
  },
  {
    "objectID": "unidad_2/03_tipos_estimador.html#meta-análisis-en-estudios-descriptivos",
    "href": "unidad_2/03_tipos_estimador.html#meta-análisis-en-estudios-descriptivos",
    "title": "Estimadores de efecto",
    "section": "Meta-análisis en estudios descriptivos",
    "text": "Meta-análisis en estudios descriptivos\nEn estudios descriptivos, los principales estimadores de efecto son la correlación, la prevalencia y la tasa de incidencia. A continuación, abordaremos cómo ajustar modelos de meta-análisis para cada uno de estos casos.\n\nCorrelaciones\nLa correlación mide la fuerza y dirección de la relación lineal entre dos variables numéricas continuas, y se calcula mediante la siguiente fórmula:\n\\[\nr_{xy} = \\frac{Cov_{xy}}{S_xS_y}\n\\tag{1}\\]\ndonde:\n\n\\(Cov_{xy}\\) es la covarianza entre las variables \\(x\\) e \\(y\\).\n\\(S_x\\) y \\(S_y\\) son los desvíos estándar de cada variable.\n\nDado que los coeficientes de correlación se encuentran en un rango entre -1 y 1, su distribución no es simétrica, lo cual puede afectar la estimación del error estándar en muestras pequeñas. Para corregir este sesgo y estabilizar la varianza, se utiliza la transformación z de Fisher.\nLa función metacor() permite ajustar modelos de meta-análisis para correlaciones y aplica automáticamente esta transformación cuando se especifica el argumento sm = \"ZCOR\".\nComo ejemplo, utilizaremos la base de datos dat.molloy2014, que recopila resultados de 16 estudios sobre la relación entre concienciación y adherencia a la medicación.\n\n# Cargar datos\ndatos_cor &lt;- dat.molloy2014\n\n# Explorar la estructura de los datos\nglimpse(datos_cor)\n\nRows: 16\nColumns: 10\n$ authors   &lt;chr&gt; \"Axelsson et al.\", \"Axelsson et al.\", \"Bruce et al.\", \"Chris…\n$ year      &lt;int&gt; 2009, 2011, 2010, 1999, 1995, 2004, 2005, 2007, 2006, 2011, …\n$ ni        &lt;int&gt; 109, 749, 55, 107, 72, 65, 174, 326, 58, 771, 56, 91, 116, 5…\n$ ri        &lt;dbl&gt; 0.187, 0.162, 0.340, 0.320, 0.270, 0.000, 0.175, 0.050, 0.26…\n$ controls  &lt;chr&gt; \"none\", \"none\", \"none\", \"none\", \"none\", \"none\", \"none\", \"mul…\n$ design    &lt;chr&gt; \"cross-sectional\", \"cross-sectional\", \"prospective\", \"cross-…\n$ a_measure &lt;chr&gt; \"self-report\", \"self-report\", \"other\", \"self-report\", \"other…\n$ c_measure &lt;chr&gt; \"other\", \"NEO\", \"NEO\", \"other\", \"NEO\", \"NEO\", \"NEO\", \"NEO\", …\n$ meanage   &lt;dbl&gt; 22.00, 53.59, 43.36, 41.70, 46.39, 41.20, 52.30, 41.00, 77.0…\n$ quality   &lt;int&gt; 1, 1, 2, 1, 2, 2, 1, 3, 2, 3, 2, 2, 1, 2, 3, 1\n\n\nLas principales variables de interés son:\n\nri: coeficiente de correlación.\nni: tamaño muestral de cada estudio.\nauthors: identificador del estudio.\n\nAjustamos un modelo de meta-análisis para correlaciones aplicando la transformación z de Fisher:\n\nmod_cor &lt;- metacor(\n1  cor = ri,\n2  n = ni,\n3  studlab = authors,\n4  data = datos_cor,\n5  sm = \"ZCOR\",\n6  common = TRUE,\n7  random = TRUE,\n8  backtransf = TRUE\n)\n\n\n1\n\nCoeficiente de correlación para cada estudio.\n\n2\n\nTamaño de la muestra en cada estudio.\n\n3\n\nIdentificador único del estudio.\n\n4\n\nConjunto de datos.\n\n5\n\nEstimador de efecto: transformación z de Fisher para correlaciones.\n\n6\n\nAjustar el modelo de efectos fijos (TRUE/FALSE).\n\n7\n\nAjustar el modelo de efectos aleatorios (TRUE/FALSE).\n\n8\n\nMostrar resultados en escala original de los datos (TRUE/FALSE).\n\n\n\n\nAnalicemos ahora la salida del modelo:\n\nmod_cor\n\nNumber of studies: k = 16\nNumber of observations: o = 3509\n\n                        COR           95%-CI    z  p-value\nCommon effect model  0.1245 [0.0916; 0.1572] 7.36 &lt; 0.0001\nRandom effects model 0.1488 [0.0878; 0.2087] 4.75 &lt; 0.0001\n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.0081 [0.0017; 0.0378]; tau = 0.0901 [0.0412; 0.1944]\n I^2 = 60.7% [32.1%; 77.2%]; H = 1.59 [1.21; 2.10]\n\nTest of heterogeneity:\n     Q d.f. p-value\n 38.16   15  0.0009\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n- Fisher's z transformation of correlations\n\n\nEl valor de \\(I^2\\) indica que los datos presentan una heterogeneidad moderada y debe descartarse el modelo de efectos fijos.\nA diferencia de lo que vimos para datos precalculados, la salida nos muestra no solo el número de estudios incluidos (k) sino también el número total de observaciones (o).\nDe acuerdo al modelo de efectos aleatorios, existe una correlación positiva baja entre la concienciación y la adherencia a la medicación.\nGeneramos el forest plot para visualizar los resultados:\n\nforest(\n  mod_cor, \n  col.diamond.random = pal[1], \n  col.square = pal[3],\n1  common = FALSE,\n2  smlab = \"Correlación de Pearson\",\n3  leftlabs = c(\"Estudio\", \"N\"),\n4  rightlabs = c(\"r\", \"95% IC\", \"Peso\"),\n5  hetlab = \"Heterogeneidad: \",\n6  text.random = \"Modelo de \\n efectos aleatorios\"\n)\n\n\n1\n\nOmitir modelo de efectos fijos.\n\n2\n\nPersonalizar etiqueta del estimador de efecto.\n\n3\n\nPersonalizar etiquetas del panel izquierdo.\n\n4\n\nPersonalizar etiquetas del panel derecho.\n\n5\n\nPersonalizar etiqueta indicadores de heterogeneidad.\n\n6\n\nPersonalizar etiqueta del estimador global.\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrevalencia\nLa prevalencia representa la proporción de individuos con un evento de interés dentro de una población:\n\\[\np = \\frac{k}{n}\n\\tag{2}\\]\ndonde:\n\n\\(k\\) es el número de individuos con la condición/evento.\n\\(n\\) es el tamaño total de la población o muestra.\n\nDado que las proporciones pueden estar cercanas a los valores extremos (0 o 1), su distribución es asimétrica, lo que afecta el cálculo del error estándar. Para corregir este problema, se aplica una transformación logit a los datos.\nLa función metaprop() permite ajustar modelos para prevalencias e incorpora automáticamente esta transformación con el argumento sm = \"PLOGIT\".\nPara ejemplificar, usaremos la base de datos dat.crisafulli2020, que contiene resultados de 26 estudios sobre la prevalencia de la distrofia muscular de Duchenne en recién nacidos:\n\n# Cargar datos\ndatos_prev &lt;- dat.crisafulli2020\n\n# Explorar estructura de los datos\nglimpse(datos_prev)\n\nRows: 26\nColumns: 7\n$ study   &lt;chr&gt; \"Brooks (1977)\", \"Danieli (1977)\", \"Takeshita (1977)\", \"Drummo…\n$ pubyear &lt;int&gt; 1977, 1977, 1977, 1979, 1980, 1980, 1981, 1982, 1983, 1983, 19…\n$ country &lt;fct&gt; UK, IT, JP, NZ, AU, IT, IT, CA, FR, IT, DE, IT, JP, CA, NO, IT…\n$ from    &lt;int&gt; 1953, 1952, 1956, NA, 1960, 1952, 1955, 1950, 1978, 1969, 1977…\n$ to      &lt;int&gt; 1968, 1972, 1970, NA, 1971, 1972, 1974, 1979, 1978, 1980, 1984…\n$ cases   &lt;int&gt; 47, 66, 19, 2, 99, 105, 73, 110, 12, 156, 48, 76, 50, 5, 16, 2…\n$ total   &lt;int&gt; 177413, 234396, 91157, 10000, 532302, 371698, 301283, 420374, …\n\n\nLas principales variables de interés son:\n\ncases: individuos con el evento.\ntotal: tamaño muestral.\nstudy: identificador de estudio.\n\nAjustamos el modelo de meta-análisis para proporciones aplicando la transformación logit:\n\nmod_prev &lt;- metaprop(\n1  event = cases,\n2  n = total,\n3  studlab = study,\n4  data = datos_prev,\n5  sm = \"PLOGIT\",\n6  common = TRUE,\n7  random = TRUE,\n8  backtransf = TRUE,\n9  pscale = 100\n)\n\n\n1\n\nCasos observados en cada estudio.\n\n2\n\nTamaño muestral del estudio.\n\n3\n\nIdentificador único del estudio.\n\n4\n\nConjunto de datos.\n\n5\n\nEstimador de efecto: logit-proporción.\n\n6\n\nAjustar el modelo de efectos fijos (TRUE/FALSE).\n\n7\n\nAjustar el modelo de efectos aleatorios (TRUE/FALSE).\n\n8\n\nMostrar resultados en escala original de los datos (TRUE/FALSE).\n\n9\n\nExpresar los resultados en porcentajes.\n\n\n\n\nAnalicemos ahora la salida del modelo:\n\nmod_prev\n\nNumber of studies: k = 26\nNumber of observations: o = 6831388\nNumber of events: e = 1545\n\n                     events           95%-CI\nCommon effect model  0.0226 [0.0215; 0.0238]\nRandom effects model 0.0222 [0.0206; 0.0240]\n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.0126; tau = 0.1121; I^2 = 33.2% [0.0%; 58.6%]; H = 1.22 [1.00; 1.55]\n\nTest of heterogeneity:\n          Q d.f. p-value\n Wald 37.41   25  0.0527\n LRT  39.01   25  0.0368\n\nDetails of meta-analysis methods:\n- Random intercept logistic regression model\n- Maximum-likelihood estimator for tau^2\n- Calculation of I^2 based on Q\n- Logit transformation\n- Events per 100 observations\n\n\nEl valor de \\(I^2\\) indica que los datos presentan una heterogeneidad moderada y debe descartarse el modelo de efectos fijos.\nEl coeficiente del modelo de efectos aleatorios muestra una prevalencia del evento del 0,022%, por lo que vamos a expresarla en casos por 100 000 habitantes al momento de realizar el forest plot.\n\nforest(\n  mod_prev, \n  col.diamond.random = pal[1], \n  col.square = pal[3],\n1  common = FALSE,\n2  smlab = \"Prevalencia \\n (por 100 000 hab.)\",\n3  leftlabs = c(\"Estudio\", \"Eventos\", \"N\"),\n4  rightlabs = c(\"Prev.\", \"95% IC\"),\n5  hetlab = \"Heterogeneidad: \",\n6  text.random = \"Modelo de \\n efectos aleatorios\",\n7  pscale = 100000\n)\n\n\n1\n\nOmitir modelo de efectos fijos.\n\n2\n\nPersonalizar etiqueta del estimador de efecto.\n\n3\n\nPersonalizar etiquetas del panel izquierdo.\n\n4\n\nPersonalizar etiquetas del panel derecho.\n\n5\n\nPersonalizar etiqueta indicadores de heterogeneidad.\n\n6\n\nPersonalizar etiqueta del estimador global.\n\n7\n\nExpresar coeficientes en casos cada 100000 habitantes.\n\n\n\n\n\n\n\n\n\n\n\n\n\nTasa de incidencia\nLa tasa de incidencia o incidence rate (IR) se utiliza para eventos que ocurren a lo largo del tiempo y se define como:\n\\[\nIR = \\frac {k}{T}\n\\tag{3}\\]\ndonde:\n\n\\(k\\) es el número de eventos observados.\n\\(T\\) es la suma del tiempo-persona en riesgo en cada estudio.\n\nDado que las tasas de incidencia pueden ser pequeñas y asimétricas, se recomienda aplicar una transformación logarítmica a los datos para estabilizar su varianza.\nLa función metarate() ajusta modelos de meta-análisis para tasas de incidencia, aplicando esta transformación (sm = \"IRLN\").\nComo ejemplo, usamos la base dat.nielweise2008, que contiene 9 estudios sobre la incidencia de infecciones sanguíneas asociadas al uso de catéteres:\n\n# Cargar datos\ndatos_inc &lt;- dat.nielweise2008\n\n# Explorar estructura de los datos\nglimpse(datos_inc)\n\nRows: 9\nColumns: 7\n$ study   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9\n$ authors &lt;chr&gt; \"Bong et al.\", \"Ciresi et al.\", \"Hanna et al.\", \"Harter et al.…\n$ year    &lt;int&gt; 2003, 1996, 2004, 2002, 2001, 2005, 1997, 2005, 1996\n$ x1i     &lt;int&gt; 7, 8, 3, 6, 1, 1, 17, 3, 2\n$ t1i     &lt;int&gt; 1344, 1600, 12012, 1536, 370, 729, 6760, 1107, 320\n$ x2i     &lt;int&gt; 11, 8, 14, 10, 1, 8, 15, 7, 3\n$ t2i     &lt;int&gt; 1988, 1461, 10962, 1503, 483, 913, 6840, 1015, 440\n\n\nLas principales variables de interés son:\n\nx2i: casos observados en el grupo i.\nt2i: años-persona en riesgo en el grupo i.\nauthors: identificador de estudio.\n\nAjustamos el modelo de meta-análisis para tasas de incidencia aplicando la transformación logarítmica:\n\nmod_inc &lt;- metarate(\n1  event = x2i,\n2  time = t2i,\n3  studlab = authors,\n4  data = datos_inc,\n5  sm = \"IRLN\",\n6  common = TRUE,\n7  random = TRUE,\n8  backtransf = TRUE\n)\n\n\n1\n\nCasos observados en cada estudio.\n\n2\n\nTiempo-persona en riesgo en cada estudio.\n\n3\n\nIdentificador único del estudio.\n\n4\n\nConjunto de datos.\n\n5\n\nEstimador de efecto: log-tasa de incidencia.\n\n6\n\nAjustar el modelo de efectos fijos (TRUE/FALSE).\n\n7\n\nAjustar el modelo de efectos aleatorios (TRUE/FALSE).\n\n8\n\nMostrar resultados en escala original de los datos (TRUE/FALSE).\n\n\n\n\nAnalicemos ahora la salida del modelo:\n\nmod_inc\n\nNumber of studies: k = 9\nNumber of events: e = 77\n\n                       rate           95%-CI\nCommon effect model  0.0039 [0.0031; 0.0048]\nRandom effects model 0.0043 [0.0027; 0.0070]\n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.3699 [0.0940; 1.5145]; tau = 0.6082 [0.3065; 1.2307]\n I^2 = 78.0% [58.4%; 88.4%]; H = 2.13 [1.55; 2.93]\n\nTest of heterogeneity:\n     Q d.f.  p-value\n 36.38    8 &lt; 0.0001\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n- Log transformation\n\n\nEl valor de \\(I^2\\) indica que los datos presentan una heterogeneidad alta y debe descartarse el modelo de efectos fijos.\nEl coeficiente del modelo de efectos aleatorio muestra que la tasa de incidencia del evento es muy baja dentro del grupo estudiado, por lo que vamos a expresarla en casos por 1000 años-persona cuando ajustemos el forest plot.\n\nforest(\n  mod_inc, \n  col.diamond.random = pal[1], \n  col.square = pal[3],\n1  common = FALSE,\n2  smlab = \"Tasa de incidencia \\n (1000 años-persona)\",\n3  leftlabs = c(\"Estudio\", \"Eventos\", \"Tiempo\"),\n4  rightlabs = c(\"Tasa\", \"95% IC\", \"Peso\"),\n5  hetlab = \"Heterogeneidad: \",\n6  text.random = \"Modelo de \\n efectos aleatorios\",\n7  pscale = 1000\n)\n\n\n1\n\nOmitir modelo de efectos fijos.\n\n2\n\nPersonalizar etiqueta del estimador de efecto.\n\n3\n\nPersonalizar etiquetas del panel izquierdo.\n\n4\n\nPersonalizar etiquetas del panel derecho.\n\n5\n\nPersonalizar etiqueta indicadores de heterogeneidad.\n\n6\n\nPersonalizar etiqueta del estimador global.\n\n7\n\nExpresar coeficientes en casos cada 1000 años-persona.",
    "crumbs": [
      "Introducción a la Revisión Sistemática con Meta-análisis",
      "Meta-análisis",
      "Estimadores de efecto"
    ]
  },
  {
    "objectID": "unidad_2/03_tipos_estimador.html#meta-análisis-en-estudios-analíticos",
    "href": "unidad_2/03_tipos_estimador.html#meta-análisis-en-estudios-analíticos",
    "title": "Estimadores de efecto",
    "section": "Meta-análisis en estudios analíticos",
    "text": "Meta-análisis en estudios analíticos\nDentro de los estudios analíticos (observacionales y/o experimentales), los estimadores de efecto más comunes son la diferencia de medias, el odds-ratio (OR), el riesgo relativo (RR) y la razón de tasas de incidencia (IRR). A continuación, mostraremos su implementación en R.\n\nDiferencia de medias\nLa diferencia de medias entre dos grupos de exposición se define como:\n\\[\nMD = \\bar{x_e} - \\bar{x_c}\n\\tag{4}\\]\ndonde:\n\n\\(\\bar{x_e}\\) es la media muestral del grupo expuesto o tratado.\n\\(\\bar{x_c}\\) es la media muestral del grupo no expuesto o control.\n\nEl cálculo de la diferencia de medias requiere que todas las mediciones se hayan tomado en la misma escala. Para los modelos de meta-análisis, se utiliza la diferencia de medias estandarizada, que elimina la dependencia de las unidades de medición al ponderar por el desvío estándar.\nLa función metacont() ajusta modelos de meta-análisis para diferencias de medias estandarizadas con el argumento sm = \"SMD\".\nComo ejemplo, utilizaremos la base de datos dat.furukawa2003, que contiene resultados de 17 estudios sobre la efectividad de la dosis de antidepresivos tricíclicos en casos de depresión severa.\n\n# Cargar datos\ndatos_md &lt;- dat.furukawa2003\n\n# Explorar estructura de los datos\nglimpse(datos_md)\n\nRows: 17\nColumns: 7\n$ author &lt;chr&gt; \"Blashki(75&150)\", \"Hormazabal(86)\", \"Jacobson(75-100)\", \"Jenki…\n$ Ne     &lt;int&gt; 13, 17, 10, 7, 73, 26, 17, 11, 105, 22, 13, 29, 13, 78, 23, 11,…\n$ Me     &lt;dbl&gt; 6.40, 11.00, 17.50, 12.30, 15.70, 8.50, 25.50, 6.20, -8.10, 13.…\n$ Se     &lt;dbl&gt; 5.40, 8.20, 8.80, 9.90, 10.60, 11.00, 24.00, 7.60, 3.90, 2.30, …\n$ Nc     &lt;int&gt; 18, 16, 6, 7, 73, 28, 10, 10, 46, 19, 15, 39, 13, 71, 23, 11, 18\n$ Mc     &lt;dbl&gt; 11.40, 19.00, 23.00, 20.00, 18.70, 14.50, 53.20, 10.00, -8.50, …\n$ Sc     &lt;dbl&gt; 9.60, 8.20, 8.80, 10.50, 10.60, 11.00, 11.20, 7.60, 5.20, 1.30,…\n\n\nLas principales variables de interés son:\n\nMe: media muestral en grupo expuesto/tratamiento.\nSe: desvío estándar de la media en grupo expuesto/tratamiento.\nNe: tamaño muestral en grupo expuesto/tratamiento.\nMc: media muestral en grupo no expuesto/control.\nSc: desvío estándar de la media en grupo no expuesto/control.\nNc: tamaño muestral en grupo no expuesto/control.\nauthor: identificador de estudio.\n\nAjustamos el modelo de meta-análisis para diferencia de medias estandarizada:\n\nmod_md &lt;- metacont(\n1  n.e = Ne,\n2  mean.e = Me,\n3  sd.e = Se,\n4  n.c = Nc,\n5  mean.c = Mc,\n6  sd.c = Sc,\n7  studlab = author,\n8  data = datos_md,\n9  sm = \"SMD\",\n10  common = TRUE,\n11  random = TRUE,\n12  backtransf = TRUE\n)\n\n\n1\n\nTamaño muestral del grupo expuesto en cada estudio.\n\n2\n\nMedia del grupo expuesto en cada estudio.\n\n3\n\nDesvío estándar del grupo expuesto en cada estudio.\n\n4\n\nTamaño muestral del grupo no expuesto o control en cada estudio.\n\n5\n\nMedia del grupo no expuesto o control en cada estudio.\n\n6\n\nDesvío estándar del grupo no expuesto o control en cada estudio.\n\n7\n\nIdentificador único del estudio.\n\n8\n\nConjunto de datos.\n\n9\n\nEstimador de efecto: diferencia de medias estandarizada.\n\n10\n\nAjustar el modelo de efectos fijos (TRUE/FALSE).\n\n11\n\nAjustar el modelo de efectos aleatorios (TRUE/FALSE).\n\n12\n\nMostrar resultados en escala original de los datos (TRUE/FALSE).\n\n\n\n\nAnalicemos ahora la salida del modelo:\n\nmod_md\n\nNumber of studies: k = 17\nNumber of observations: o = 902 (o.e = 479, o.c = 423)\n\n                         SMD             95%-CI     z  p-value\nCommon effect model  -0.3918 [-0.5286; -0.2551] -5.62 &lt; 0.0001\nRandom effects model -0.6056 [-0.9326; -0.2787] -3.63   0.0003\n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.3415 [0.1422; 1.1791]; tau = 0.5844 [0.3771; 1.0859]\n I^2 = 72.6% [55.5%; 83.1%]; H = 1.91 [1.50; 2.43]\n\nTest of heterogeneity:\n     Q d.f.  p-value\n 58.38   16 &lt; 0.0001\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n- Hedges' g (bias corrected standardised mean difference; using exact formulae)\n\n\nEl valor de \\(I^2\\) indica que los datos presentan una heterogeneidad alta y debe descartarse el modelo de efectos fijos.\nLos coeficientes del modelo de efectos aleatorios indican que el grupo tratado presenta un promedio significativamente menor de infecciones asociadas al uso de catéteres que el grupo control \\((p&lt;0,001)\\).\nGeneramos el forest plot para visualizar los resultados:\n\nforest(\n  mod_md, \n  col.diamond.random = pal[1], \n  col.square = pal[3],\n1  common = FALSE,\n2  smlab = \"Diferencia de medias \\n estandarizada\",\n  leftlabs = c(\"Estudio\", \n3               rep(c(\"Total\", \"Media\", \"SD\"),2)),\n4  rightlabs = c(\"SMD\", \"95% IC\", \"Peso\"),\n5  hetlab = \"Heterogeneidad: \",\n6  text.random = \"Modelo de \\n efectos aleatorios\",\n)\n\n\n1\n\nOmitir modelo de efectos fijos.\n\n2\n\nPersonalizar etiqueta del estimador de efecto.\n\n3\n\nPersonalizar etiquetas del panel izquierdo.\n\n4\n\nPersonalizar etiquetas del panel derecho.\n\n5\n\nPersonalizar etiqueta indicadores de heterogeneidad.\n\n6\n\nPersonalizar etiqueta del estimador global.\n\n\n\n\n\n\n\n\n\n\n\nPara mejorar la visualización, podemos modificar el argumento leftcols para mostrar solamente el identificador de estudio en el panel izquierdo:\n\nforest(\n  mod_md,\n  common = FALSE,        \n  col.diamond = pal[1],\n  col.square = pal[3],\n  smlab = \"Diferencia de medias \\n estandarizada\",\n  leftlabs = \"Estudio\",\n  rightlabs = c(\"SMD\", \"95% IC\", \"Peso\"),\n  hetlab = \"Heterogeneidad: \",\n  text.random = \"Modelo de efectos aleatorios\",\n  leftcols = \"studlab\"\n  )\n\n\n\n\n\n\n\n\n\n\nOdds-ratio\nEl odds ratio (OR) o razón de productos cruzados se define como el cociente entre los odds del evento en el grupo expuesto/tratamiento y en el grupo no expuesto/control:\n\\[\nOR =  \\frac{a/b}{c/d}\n\\tag{5}\\]\ndonde:\n\n\\(a\\) es el número de eventos en el grupo expuesto/tratamiento.\n\\(b\\) es el número de individuos sin el evento en el grupo expuesto/tratamiento.\n\\(c\\) es el número de eventos en el grupo no expuesto/control.\n\\(d\\) es el número de individuos sin el evento en el grupo no expuesto/control.\n\nEl OR solo puede tomar valores positivos \\((0-\\infty)\\), donde:\n\n\\(OR = 1\\) indica ausencia de efecto.\n\\(OR &gt;1\\) sugiere un aumento en la probabilidad de ocurrencia del evento en el grupo expuesto.\n\\(OR &lt; 1\\) sugiere un posible efecto protector de la exposición o tratamiento.\n\nDado que el OR sigue una distribución asimétrica, su análisis estadístico puede ser complejo. Para estabilizar la varianza y aproximar una distribución normal, se aplica una transformación logarítmica.\nLa función metabin() ajusta modelos de meta-análisis para OR e incorpora automáticamente esta transformación mediante el argumento sm = \"OR\". Además, incluye una corrección de continuidad para manejar estudios con valores de eventos iguales a cero.\nEl siguiente ejemplo utiliza la base de datos dat.collins1985b, que contiene información de 9 estudios sobre el efecto de los diuréticos en la prevención de preeclampsia.\nComenzamos cargando los datos y explorando su estructura:\n\n# Carga datos\ndatos_or &lt;- dat.collins1985b\n\n# Explorar estructura de los datos\nglimpse(datos_or)\n\nRows: 9\nColumns: 16\n$ id      &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9\n$ author  &lt;chr&gt; \"Weseley & Douglas\", \"Flowers et al.\", \"Menzies\", \"Fallis et a…\n$ year    &lt;int&gt; 1962, 1962, 1964, 1964, 1964, 1965, 1966, 1971, 1975\n$ pre.nti &lt;int&gt; 131, 385, 57, 38, 1011, 1370, 506, 108, 153\n$ pre.nci &lt;int&gt; 136, 134, 48, 40, 760, 1336, 524, 103, 102\n$ pre.xti &lt;int&gt; 14, 21, 14, 6, 12, 138, 15, 6, 65\n$ pre.xci &lt;int&gt; 14, 17, 24, 18, 35, 175, 20, 2, 40\n$ oedema  &lt;int&gt; 0, 0, 1, 0, 1, 0, 0, 0, 0\n$ fup.nti &lt;int&gt; 131, 335, 57, 34, 1011, 1370, 506, 108, 153\n$ fup.nci &lt;int&gt; 136, 110, 48, 40, 760, 1336, 524, 103, 102\n$ ped.xti &lt;int&gt; 1, 6, 3, 1, 14, 24, 14, 0, 0\n$ ped.xci &lt;int&gt; 4, 3, 2, 3, 13, 19, 16, 0, 0\n$ stb.xti &lt;int&gt; 1, 3, 1, 0, 6, NA, 6, 0, 0\n$ stb.xci &lt;int&gt; 2, 2, 1, 1, 5, NA, 9, 0, 0\n$ ned.xti &lt;int&gt; 0, 3, 2, 1, 8, NA, 8, 0, 0\n$ ned.xci &lt;int&gt; 2, 1, 1, 2, 8, NA, 7, 0, 0\n\n\nLas variables de interés son:\n\npre.xti: número de eventos en el grupo expuesto/tratamiento.\npre.nti: tamaño muestral en el grupo expuesto/tratamiento.\npre.xci: número de eventos en el grupo no expuesto/control.\npre.nti: tamaño muestral en el grupo no expuesto/control.\nauthor: identificador del estudio.\n\nAjustamos el modelo de meta-análisis para OR:\n\nmod_or &lt;- metabin(\n1  event.e = pre.xti,\n2  n.e = pre.nti,\n3  event.c = pre.xci,\n4  n.c = pre.nci,\n5  studlab = author,\n6  data = datos_or,\n7  sm = \"OR\",\n8  common = TRUE,\n9  random = TRUE,\n10  backtransf = TRUE\n)\n\n\n1\n\nEventos en el grupo expuesto en cada estudio.\n\n2\n\nTamaño muestral del grupo expuesto en cada estudio.\n\n3\n\nEventos en el grupo no expuesto/control en cada estudio.\n\n4\n\nTamaño muestral del grupo no expuesto/control en cada estudio.\n\n5\n\nIdentificador único del estudio.\n\n6\n\nConjunto de datos.\n\n7\n\nEstimador de efecto: log-odds ratio.\n\n8\n\nAjustar el modelo de efectos fijos (TRUE/FALSE).\n\n9\n\nAjustar el modelo de efectos aleatorios (TRUE/FALSE).\n\n10\n\nMostrar resultados en escala original de los datos (TRUE/FALSE).\n\n\n\n\nAnalicemos ahora la salida del modelo:\n\nmod_or\n\nNumber of studies: k = 9\nNumber of observations: o = 6942 (o.e = 3759, o.c = 3183)\nNumber of events: e = 636\n\n                         OR           95%-CI     z  p-value\nCommon effect model  0.6677 [0.5620; 0.7932] -4.60 &lt; 0.0001\nRandom effects model 0.5956 [0.3843; 0.9233] -2.32   0.0205\n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.3008 [0.0723; 2.2027]; tau = 0.5484 [0.2689; 1.4842]\n I^2 = 70.7% [41.8%; 85.2%]; H = 1.85 [1.31; 2.60]\n\nTest of heterogeneity:\n     Q d.f. p-value\n 27.26    8  0.0006\n\nDetails of meta-analysis methods:\n- Mantel-Haenszel method (common effect model)\n- Inverse variance method (random effects model)\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n\n\nLa salida del modelo nos muestra el número de estudios (k), el número de observaciones total (o) y por grupo de exposición (o.e y o.c) y el número de eventos.\nEl valor de \\(I^2\\) indica que los datos presentan una heterogeneidad alta y debe descartarse el modelo de efectos fijos.\nDe acuerdo al coeficiente del modelo de efectos aleatorios, el uso de diuréticos reduce significativamente las probabilidades de preeclampsia en comparación con el grupo control \\((p = 0,021)\\).\nGeneramos el forest plot para visualizar los resultados:\n\nforest(\n  mod_md, \n  col.diamond.random = pal[1], \n  col.square = pal[3],\n1  common = FALSE,\n2  smlab = \"Odds-ratio\",\n3  leftcols = \"studlab\",\n4  leftlabs = \"Estudio\",\n5  rightlabs = c(\"OR\", \"95% IC\", \"Peso\"),\n6  hetlab = \"Heterogeneidad: \",\n7  text.random = \"Modelo de \\n efectos aleatorios\",\n)\n\n\n1\n\nOmitir modelo de efectos fijos.\n\n2\n\nPersonalizar etiqueta del estimador de efecto.\n\n3\n\nMostrar solo el identificador de estudio en el panel izquierdo.\n\n4\n\nPersonalizar etiquetas del panel izquierdo.\n\n5\n\nPersonalizar etiquetas del panel derecho.\n\n6\n\nPersonalizar etiqueta indicadores de heterogeneidad.\n\n7\n\nPersonalizar etiqueta del estimador global.\n\n\n\n\n\n\n\n\n\n\n\n\n\nRiesgo relativo\nEl riesgo relativo (RR) o risk ratio mide la razón entre las probabilidades de desarrollar un evento en el grupo expuesto y en el grupo control:\n\\[\nRR =  \\frac{a/(a + b)}{c/(c + d)}\n\\]\ndonde:\n\n\\(a\\) es el número de eventos en el grupo expuesto/tratamiento.\n\\(b\\) es el número de individuos sin el evento en el grupo expuesto/tratamiento.\n\\(c\\) es el número de eventos en el grupo no expuesto/control.\n\\(d\\) es el número de individuos sin el evento en el grupo no expuesto/control.\n\nAl igual que el OR, el RR es una medida asimétrica y solo toma valores positivos \\((0-\\infty)\\). Para estabilizar la varianza y mejorar la interpretación estadística, se usa una transformación logarítmica, lo que permite modelar el RR en un intervalo simétrico y facilita la comparación entre estudios.\nLa función metabin() permite calcular el RR mediante el argumento sm = \"RR\", que aplica automáticamente la transformación logarítmica. Debido a la similitud en el cálculo con el OR, omitiremos el ejemplo para esta medida de asociación.\n\n\nRazón de tasas de incidencia\nLa razón de tasas de incidencia (incidence rate ratio o IRR) compara la frecuencia de eventos en dos grupos considerando el tiempo-persona de exposición:\n\\[\nIRR = \\frac{IR_e}{IR_c}\n\\]\ndonde:\n\n\\(IR_e\\) es la tasa de incidencia en el grupo expuesto/tratamiento.\n\\(IR_c\\) es la tasa de incidencia en el grupo no expuesto/control.\n\nAl igual que para la tasa de incidencia, se recomienda realizar la transformación logarítmica de los datos para aproximarlos a una distribución normal.\nEn meta, la función metainc() ajusta modelos de IRR con sm = \"IRR\", aplicando automáticamente la transformación logarítmica.\nA modo de ejemplo, volveremos a usar la base datos_inc, esta vez comparando entre grupo de exposición y control.\nLas principales variables de interés para este caso son:\n\nx1i: casos observados en grupo expuesto/tratamiento.\nt1i: años-persona en grupo expuesto/tratamiento.\nx2i: casos observados en grupo no expuesto/control.\nt2i: años-persona en grupo no expuesto/control.\nauthors: identificador de estudio.\n\nAjustamos el modelo de meta-análisis para IRR aplicando la transformación logarítmica:\n\n# Ajusta modelo\nmod_irr &lt;- metainc(\n1  event.e = x1i,\n2  time.e = t1i,\n3  event.c = x2i,\n4  time.c = t2i,\n5  studlab = authors,\n6  data = datos_inc,\n7  sm = \"IRR\",\n8  common = TRUE,\n9  random = TRUE,\n10  backtransf = TRUE,\n  )\n\n\n1\n\nCasos observados en el grupo expuesto de cada estudio.\n\n2\n\nTiempo-persona en riesgo en el grupo expuesto de cada estudio.\n\n3\n\nCasos observados en el grupo no expuesto/control de cada estudio.\n\n4\n\nTiempo-persona en riesgo en el grupono expuesto/control de cada estudio.\n\n5\n\nIdentificador único del estudio.\n\n6\n\nConjunto de datos.\n\n7\n\nEstimador de efecto: log-razón de tasas de incidencia.\n\n8\n\nAjustar el modelo de efectos fijos (TRUE/FALSE).\n\n9\n\nAjustar el modelo de efectos aleatorios (TRUE/FALSE).\n\n10\n\nMostrar resultados en escala original de los datos (TRUE/FALSE).\n\n\n\n\nAnalicemos ahora la salida del modelo:\n\nmod_irr\n\nNumber of studies: k = 9\nNumber of events: e = 125\n\n                        IRR           95%-CI     z p-value\nCommon effect model  0.6602 [0.4608; 0.9459] -2.26  0.0236\nRandom effects model 0.6728 [0.4314; 1.0494] -1.75  0.0806\n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.0936 [0.0000; 1.4845]; tau = 0.3060 [0.0000; 1.2184]\n I^2 = 17.5% [0.0%; 59.5%]; H = 1.10 [1.00; 1.57]\n\nTest of heterogeneity:\n    Q d.f. p-value\n 9.70    8  0.2869\n\nDetails of meta-analysis methods:\n- Mantel-Haenszel method (common effect model)\n- Inverse variance method (random effects model)\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n\n\nEl valor de \\(I^2\\) indica que los datos presentan una heterogeneidad baja y puede conservarse el modelo de efectos fijos.\nLos coeficientes del modelo de efectos fijos muestran una disminución estadísticamente significativa del riesgo en el grupo tratado \\((p = 0,24)\\), pero la misma deja de ser significativa en el de efectos aleatorios \\((p = 0,81)\\).\nGeneramos el forest plot para visualizar los resultados, usando los argumentos col.diamond.random y col.diamond.common para mostrar en diferentes colores los estimadores globales del modelo de efectos fijos y el modelo de efectos aleatorios:\n\nforest(\n  mod_irr,\n1  col.diamond.random = pal[1],\n2  col.diamond.common = pal[2],\n  col.square = pal[3],          \n3  smlab = \"Razón de tasas de incidencia\",\n4  leftcols = \"studlab\",\n5  leftlabs = \"Estudio\",\n  rightlabs = c(\"IRR\", \"95% IC\", \n6                \"Peso (fijo)\", \"Peso (aleatorio)\"),\n7  hetlab = \"Heterogeneidad: \",\n8  text.random = \"Modelo de efectos aleatorios\",\n9  text.common = \"Modelo de efectos fijos\"\n)\n\n\n1\n\nColor para el símbolo del estimador de efecto global del modelo de efectos aleatorios.\n\n2\n\nColor para el símbolo del estimador de efecto global del modelo de efectos fijos.\n\n3\n\nPersonalizar etiqueta del estimador de efecto.\n\n4\n\nMostrar solo el identificador de estudio en el panel izquierdo.\n\n5\n\nPersonalizar etiquetas del panel izquierdo.\n\n6\n\nPersonalizar etiquetas del panel derecho.\n\n7\n\nPersonalizar etiqueta indicadores de heterogeneidad.\n\n8\n\nPersonalizar etiqueta del estimador global para el modelo de efectos aleatorios.\n\n9\n\nPersonalizar etiqueta del estimador global para el modelo de efectos fijos.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNota\n\n\n\n\nDebido a la extensión del curso, nos enfocaremos exclusivamente en la implementación en R de los modelos para cada medida de asociación. Quienes deseen profundizar en el desarrollo matemático de estos modelos pueden consultar los capítulos 3 y 4.2 de Harrer et al. (2021).\nActualmente, el paquete meta no incluye funciones específicas para modelar el tiempo hasta el evento (hazard ratio, HR). Sin embargo, si los estudios reportan el log-HR y su error estándar, es posible utilizar la función metagen() con el argumento sm = \"HR\" para obtener una estimación combinada del efecto. Para una explicación detallada del proceso, pueden consultar el capítulo 2.6.1 de Schwarzer, Carpenter, y Rücker (2015).",
    "crumbs": [
      "Introducción a la Revisión Sistemática con Meta-análisis",
      "Meta-análisis",
      "Estimadores de efecto"
    ]
  }
]