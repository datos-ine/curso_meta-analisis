[
  {
    "objectID": "unidad_2/05_graficos_avanzados.html",
    "href": "unidad_2/05_graficos_avanzados.html",
    "title": "Herramientas avanzadas",
    "section": "",
    "text": "Esta secci√≥n es opcional y est√° dirigida a personas con conocimientos m√°s avanzados de R. Presentaremos una serie de paquetes adicionales que permiten generar visualizaciones m√°s flexibles y listas para incluir en informes t√©cnicos o publicaciones cient√≠ficas, as√≠ como funciones complementarias para trabajar con modelos multinivel y metarregresiones m√∫ltiples.\nPara utilizarlos, es necesario reajustar los modelos usando el paquete metafor, ya que no son compatibles con la salida de meta.",
    "crumbs": [
      "Introducci√≥n a la Revisi√≥n Sistem√°tica con Meta-an√°lisis",
      "Meta-an√°lisis",
      "Herramientas avanzadas"
    ]
  },
  {
    "objectID": "unidad_2/05_graficos_avanzados.html#introducci√≥n",
    "href": "unidad_2/05_graficos_avanzados.html#introducci√≥n",
    "title": "Herramientas avanzadas",
    "section": "",
    "text": "Esta secci√≥n es opcional y est√° dirigida a personas con conocimientos m√°s avanzados de R. Presentaremos una serie de paquetes adicionales que permiten generar visualizaciones m√°s flexibles y listas para incluir en informes t√©cnicos o publicaciones cient√≠ficas, as√≠ como funciones complementarias para trabajar con modelos multinivel y metarregresiones m√∫ltiples.\nPara utilizarlos, es necesario reajustar los modelos usando el paquete metafor, ya que no son compatibles con la salida de meta.",
    "crumbs": [
      "Introducci√≥n a la Revisi√≥n Sistem√°tica con Meta-an√°lisis",
      "Meta-an√°lisis",
      "Herramientas avanzadas"
    ]
  },
  {
    "objectID": "unidad_2/05_graficos_avanzados.html#ejemplo-pr√°ctico-en-r",
    "href": "unidad_2/05_graficos_avanzados.html#ejemplo-pr√°ctico-en-r",
    "title": "Herramientas avanzadas",
    "section": "Ejemplo pr√°ctico en R",
    "text": "Ejemplo pr√°ctico en R\n\nInstalaci√≥n de paquetes\n\n# Instalar paquetes adicionales\ninstall.packages(\"metaviz\")\n\nremotes::install_github(\"MathiasHarrer/dmetar\")\n\nremotes::install_github(\"daniel1noble/orchaRd\")\n\n\n\nCarga de paquetes\n\n# Cargar paquetes\npacman::p_load(metafor,\n               orchaRd,\n               metaviz,\n               dmetar,\n               scico,\n               tidyverse)\n\n\n\nAjuste del modelo\nTrabajaremos nuevamente con el dataset dat.bornmann2007, que analiza el sesgo de g√©nero en la adjudicaci√≥n de subsidios para investigaci√≥n:\n\n# Cargar datos\ndatos &lt;- dat.bornmann2007 |&gt; \n  # Crear identificador √∫nico\n  rowid_to_column(var = \"id\")\n\nEl paquete metafor no cuenta con funciones espec√≠ficas para cada medida de asociaci√≥n, por lo que es necesario calcular previamente los estimadores de efecto usando la funci√≥n escalc():\n\n1datos &lt;- escalc(measure = \"OR\",\n2                ai = waward,\n3                n1i = wtotal,\n4                ci = maward,\n5                n2i = mtotal,\n                data = datos,\n                slab = study)\n\n\n1\n\nmeasure: medida de asociaci√≥n a usar como estimador de efecto.\n\n2\n\nai: n√∫mero de eventos en el grupo expuesto.\n\n3\n\nn1i: tama√±o muestral en el grupo expuesto.\n\n4\n\nci: n√∫mero de eventos en el grupo no expuesto.\n\n5\n\nn2i: tama√±o muestral en el grupo no expuesto.\n\n\n\n\nSi no tuvi√©ramos el tama√±o muestral en cada grupo, podr√≠amos reemplazar n1i por bi (expuestos sin el evento) y n2i por di (no expuestos con el evento).\n\nLos argumentos a completar van a depender de la medida de asociaci√≥n que especificamos en el argumento measure.\nPara acceder a la ayuda de la funci√≥n y ver opciones disponibles, ejecutar el comando ?escalc en la consola de R.\n\nExploremos el resultado:\n\nglimpse(datos)\n\nRows: 66\nColumns: 16\n$ id         &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, ‚Ä¶\n$ study      &lt;chr&gt; \"Ackers (2000)\", \"Ackers (2000)\", \"Ackers (2000)\", \"Ackers ‚Ä¶\n$ obs        &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 1, 1, 2, 3, 4,‚Ä¶\n$ doctype    &lt;chr&gt; \"Grey\", \"Grey\", \"Grey\", \"Grey\", \"Grey\", \"Grey\", \"Grey\", \"Ar‚Ä¶\n$ gender     &lt;chr&gt; \"M&F\", \"M&F\", \"M&F\", \"M&F\", \"M&F\", \"M&F\", \"M&F\", \"M&F\", \"M&‚Ä¶\n$ year       &lt;dbl&gt; 1996.0, 1996.0, 1996.0, 1996.0, 1996.0, 1996.0, 1996.0, 199‚Ä¶\n$ org        &lt;chr&gt; \"MSCA\", \"MSCA\", \"MSCA\", \"MSCA\", \"MSCA\", \"MSCA\", \"MSCA\", \"DF‚Ä¶\n$ country    &lt;chr&gt; \"Europe\", \"Europe\", \"Europe\", \"Europe\", \"Europe\", \"Europe\",‚Ä¶\n$ type       &lt;chr&gt; \"Fellowship\", \"Fellowship\", \"Fellowship\", \"Fellowship\", \"Fe‚Ä¶\n$ discipline &lt;chr&gt; \"Physical Sciences\", \"Physical Sciences\", \"Physical Science‚Ä¶\n$ waward     &lt;int&gt; 139, 45, 44, 63, 157, 114, 381, 8, 5, 6, 8, 4, 20, 5, 11, 2‚Ä¶\n$ wtotal     &lt;int&gt; 711, 258, 236, 251, 910, 589, 2027, 13, 8, 8, 16, 11, 44, 1‚Ä¶\n$ maward     &lt;int&gt; 274, 166, 219, 96, 252, 460, 489, 53, 53, 63, 53, 43, 55, 7‚Ä¶\n$ mtotal     &lt;int&gt; 1029, 908, 928, 507, 1118, 2244, 2275, 72, 82, 97, 94, 92, ‚Ä¶\n$ yi         &lt;dbl&gt; -0.40107542, -0.05726822, -0.29852194, 0.36093779, -0.33336‚Ä¶\n$ vi         &lt;dbl&gt; 0.013916635, 0.034288863, 0.033912253, 0.034041922, 0.01282‚Ä¶\n\n\nSe a√±adieron dos nuevas variables, que utilizaremos para ajustar el modelo:\n\nyi: estimador de efecto individual en escala logar√≠tmica (log-OR).\nvi: varianza del estimador.\n\nComo los datos incluyen m√°s de una observaci√≥n por estudio, usaremos la funci√≥n rma.mv() para ajustar un modelo multinivel:\n\n1mod &lt;- rma.mv(yi = yi,\n2              V = vi,\n3              data = datos,\n4              slab = study,\n5              mods = ~ type,\n6              random = ~ 1|study/id,\n7              intercept = TRUE\n              )\n\n\n1\n\nyi: estimador de efecto individual.\n\n2\n\nV: varianza del estimador.\n\n3\n\ndata: tabla de datos.\n\n4\n\nslab: identificador √∫nico del estudio.\n\n5\n\nmods: especifica el moderador/es para metarregresi√≥n o an√°lisis de subgrupos.\n\n6\n\nrandom: define la estructura jer√°rquica de los datos:\n\n7\n\nintercept: calcular el intercepto (TRUE por defecto/ FALSE).\n\n\n\n\n\nPara conocer otros tipos de modelos disponibles, se recomienda consultar las vi√±etas de ayuda del paquete metafor y las funciones rma(), rma.uni(), rma.mv(), etc.",
    "crumbs": [
      "Introducci√≥n a la Revisi√≥n Sistem√°tica con Meta-an√°lisis",
      "Meta-an√°lisis",
      "Herramientas avanzadas"
    ]
  },
  {
    "objectID": "unidad_2/05_graficos_avanzados.html#visualizaci√≥n-avanzada-de-resultados",
    "href": "unidad_2/05_graficos_avanzados.html#visualizaci√≥n-avanzada-de-resultados",
    "title": "Herramientas avanzadas",
    "section": "Visualizaci√≥n avanzada de resultados",
    "text": "Visualizaci√≥n avanzada de resultados\n\nPaquete orchaRd\nEl paquete orchaRd (Nakagawa et¬†al. 2023) permite crear gr√°ficos visualmente atractivos y altamente personalizable basados en el motor gr√°fico ggplot2.\nLa funci√≥n orchard_plot() genera un gr√°fico donde el estimador global se representa por un punto de color con ‚Äúramas‚Äù horizontales representando el intervalo de confianza (l√≠nea gruesa) y el intervalo de predicci√≥n (l√≠nea fina). Cada estimador individual se representa con puntos m√°s claros, cuyo tama√±o depende de la precisi√≥n del estudio.\nLos argumentos principales son:\n\norchard_plot(\n1  object = mod,\n2  mod = \"1\",\n3  group = \"study\",\n4  xlab = \"log(OR)\",\n5  k = TRUE,\n6  g = TRUE\n)\n\n\n1\n\nobject: modelo de meta-an√°lisis o tabla de resultados (obligatorio).\n\n2\n\nmod: moderador/es del modelo (\"1\" para mostrar solo el estimador global).\n\n3\n\ngroup: identificador del estudio o cl√∫ster (obligatorio).\n\n4\n\nxlab: t√≠tulo a mostrar en el eje \\(X\\) (obligatorio).\n\n5\n\nk: mostrar etiqueta con n√∫mero de estudios (TRUE/FALSE).\n\n6\n\ng: mostrar etiqueta con n√∫mero de cl√∫sters (TRUE/FALSE).\n\n\n\n\n\n\n\n\n\n\n\nPodemos agregar el moderador categ√≥rico a√±adiendo en nombre de la variable entre comillas en el argumento mod. Adem√°s, vamos a a√±adir escalas de colores personalizadas:\n\n# Guardar orchard plot en un objeto\ng1 &lt;- orchard_plot(\n  mod,\n  mod = \"type\",\n  group = \"study\",\n  xlab = \"log(OR)\",\n  k = TRUE,              \n  g = TRUE)\n\n# Personalizar con ggplot2\ng1 +\n  # Escalas colorblind-friendly\n  scale_color_scico_d(palette = \"hawaii\") + # color de borde\n  scale_fill_scico_d(palette = \"hawaii\") +  # color de relleno\n  \n  theme_bw()\n\n\n\n\n\n\n\n\nLa funci√≥n caterpillars() genera un gr√°fico similar al forest plot donde se muestra el estimador de efecto individual con su \\(95\\%~IC\\) y el estimador global, omitiendo las tablas de resultados, lo cual resulta de gran utilidad cuando el n√∫mero de estudios es grande:\n\ncaterpillars(\n  mod,    \n1  mod = \"1\",\n2  group = \"study\",\n3  xlab = \"log(OR)\",\n4  k = TRUE,\n5  g = TRUE\n  )\n\n\n1\n\nmod: moderador/es del modelo (\"1\" para mostrar solo el estimador global).\n\n2\n\ngroup: identificador del estudio o cl√∫ster (obligatorio).\n\n3\n\nxlab: t√≠tulo a mostrar en el eje \\(X\\) (obligatorio).\n\n4\n\nk: mostrar etiqueta con n√∫mero de estudios (TRUE/FALSE).\n\n5\n\ng: mostrar etiqueta con n√∫mero de cl√∫sters (TRUE/FALSE).\n\n\n\n\n\n\n\n\n\n\n\nPodemos a√±adir los estimadores de efecto globales por nivel del moderador categ√≥rico usando el argumento mod y modificar los colres con los argumentos colerrorbar, colpoint y colpoly. La opci√≥n por defecto no muestra los identificadores de estudio, pero al estar basado en ggplot2, podemos a√±adirlo como una capa de anotaci√≥n de texto:\n\ncaterpillars(mod,    \n             mod = \"type\",\n             group = \"study\",      \n             xlab = \"log(OR)\",   \n             k = TRUE,              \n             g = TRUE,\n             colerrorbar = \"#705C52\",\n             colpoint = \"#1B0D33\",\n             colpoly = \"#87B666\") +\n  \n  # A√±adir capa identificador de estudio\n  geom_text(aes(label = mod$slab), \n            size = 2, \n            nudge_x = 1,\n            check_overlap = T)\n\n\n\n\n\n\n\n\nLa funci√≥n bubble_plot() nos permite generar bubble plots para moderadores continuos:\n\n# A√±adir moderador continuo\nmod1 &lt;- update(mod, mods = ~ type + year)\n  \n# Bubble plot\nbubble_plot(\n  mod1,          \n  group = \"study\",      \n1  xlab = \"A√±o de publicaci√≥n\",\n  k = TRUE,              \n  g = TRUE,\n  transfm = \"invlogit\",  \n  mod = \"year\",\n2  est.col = \"orange\",\n3  ci.col = \"magenta\",\n4  pi.col = \"purple\",\n5  ci.lwd = 0.75,\n6  pi.lwd = 0.75\n  )\n\n\n1\n\nxlab: nombre del moderador continuo.\n\n2\n\nest.col: color de la l√≠nea de regresi√≥n.\n\n3\n\nci.col: color para el intervalo de confianza de la l√≠nea de regresi√≥n.\n\n4\n\npi.col: color para el intervalo de predicci√≥n de la l√≠nea de regresi√≥n.\n\n5\n\nci.lwd: grosor de l√≠nea para el intervalo de confianza de la l√≠nea de regresi√≥n.\n\n6\n\npi.lwd: grosor de l√≠nea para el intervalo de predicci√≥n de la l√≠nea de regresi√≥n.\n\n\n\n\n\n\n\n\n\n\n\nPuedo estratificar los bubble plot seg√∫n niveles del moderador categ√≥rico usando el argumento by:\n\nbubble_plot(\n  mod1,          \n  group = \"study\",      \n  xlab = \"A√±o de publicaci√≥n\",\n  k = TRUE,              \n  g = TRUE,\n  transfm = \"invlogit\",  \n  mod = \"year\",\n  est.col = \"orange\",           \n  ci.col = \"magenta\",           \n  pi.col = \"purple\",            \n  ci.lwd = 0.75,                \n  pi.lwd = 0.75,\n  by = \"type\"\n  ) +\n  \n  # Color de las burbujas\n  scale_fill_scico_d()\n\n\n\n\n\n\n\n\n\nAn√°lisis de sensibilidad\nLa funci√≥n leave_one_out() del paquete orchaRd permite realizar un an√°lisis de sensibilidad del modelo de meta-an√°lisis, especificando en el argumento group el nombre de la variable que queremos usar para remover estudios iterativamente:\n\nleave_one &lt;- leave_one_out(mod, group = \"study\")\n\nEste procedimiento ayuda a identificar si alg√∫n estudio influye de manera desproporcionada en los resultados del meta-an√°lisis. Podemos graficar los resultados usando la funci√≥n orchard_leave1out():\n\norchard_leave1out(leave1out = leave_one,    \n                  xlab = \"log(OR)\")\n\n\n\n\n\n\n\n\nEn el gr√°fico, el eje \\(Y\\) representa cada elemento del grupo (en este caso, cada estudio), mientras que el eje \\(X\\) muestra el estimador de efecto. Para cada estudio, se presenta el resultado del modelo al excluirlo: estimador de efecto global, su intervalo de confianza, el intervalo de predicci√≥n, y los ‚Äúpuntos fantasma‚Äù, que marcan la ubicaci√≥n del estudio excluido.\n\nüîó Otras opciones de gr√°ficos con orchaRd: LINK\n\n\n\n\nPaquete metaviz\nEl paquete metaviz (Kossmeier, Tran, y Voracek 2020) proporciona funciones para generar gr√°ficos altamente personalizables y compatibles con ggplot2, ideales para informes t√©cnicos y publicaciones cient√≠ficas.\nUna de sus principales funciones es viz_forest(), que permite crear forest plots con gran control est√©tico. Es importante tener en cuenta que no es compatible con modelos multinivel, por lo que debe utilizarse con estimadores individuales previamente calculados mediante escalc() del paquete metafor.\n\n# Forest plot b√°sico\nviz_forest(x = datos |&gt; select(yi, vi),\n           study_labels = datos$study,\n           group = datos$type,\n           method = \"REML\",\n           x_trans_function = exp,\n           annotate_CI = TRUE,\n           type = \"standard\")\n\n\n\n\n\n\n\n\n\nx: columnas con el estimador (yi) y su varianza (vi).\nstudy_labels: etiquetas para los estudios individuales (opcional).\ngroup: variable categ√≥rica para agrupar y colorear las observaciones (opcional).\nmethod: m√©todo para estimar la heterogeneidad (por ej., \"REML\").\nx_trans_function: transforma los valores del eje \\(X\\) (e.g., exp para OR).\nannotate_CI: agrega una tabla con los estimadores de efecto y sus \\(95\\%~CI\\).\ntype: tipo de gr√°fico a mostrar (\"standard\", \"study_only\", \"summary_only\", etc.).\n\nEl argumento variant puede tomar valores \"classic\", \"thick\" o \"rain\" para cambiar el estilo visual del gr√°fico. Tambi√©n podemos modificarlo usando las funciones espec√≠ficas viz_thickforet() y viz_rainforest().\n\n# Estilo \"thick\"\nviz_thickforest(\n  x = datos |&gt; select(yi, vi),\n  group = datos$type,\n  method = \"REML\",\n  x_trans_function = exp,\n  annotate_CI = TRUE,\n  type = \"summary_only\"\n)\n\n\n\n\n\n\n\n# Estilo \"rainforest\"\nviz_rainforest(\n  x = datos |&gt; select(yi, vi),\n  group = datos$type,\n  method = \"REML\",\n  x_trans_function = exp,\n  annotate_CI = TRUE,\n  type = \"summary_only\"\n)\n\n\n\n\n\n\n\n\nmetaviz tambi√©n ofrece funciones para crear funnel plots m√°s informativos y est√©ticamente atractivos. Por ejemplo viz_funnel():\n\n1viz_funnel(x = datos |&gt; select(yi, vi),\n2           group = datos$type,\n3           contours_col = \"Purples\") +\n  # Cambiar colores de los puntos\n  scale_color_viridis_d()\n\n\n1\n\nx: columnas que contienen los estimadores de efecto individuales y su varianza.\n\n2\n\ngroup: columna con la variable moderadora.\n\n3\n\ncontours_col: sombreado para el intervalo de confianza del funnel plot.\n\n\n\n\n\n\n\n\n\n\n\nLa funci√≥n viz_sunset() genera una visualizaci√≥n alternativa al funnel plot, incorporando informaci√≥n sobre la potencia estad√≠stica de cada estudio:\n\nviz_sunset(x = datos |&gt; select(yi, vi))\n\n\n\n\n\n\n\n\nEste gr√°fico es especialmente √∫til para detectar estudios con bajo poder estad√≠stico o que podr√≠an estar influyendo en la asimetr√≠a del funnel plot.",
    "crumbs": [
      "Introducci√≥n a la Revisi√≥n Sistem√°tica con Meta-an√°lisis",
      "Meta-an√°lisis",
      "Herramientas avanzadas"
    ]
  },
  {
    "objectID": "unidad_2/05_graficos_avanzados.html#funciones-adicionales",
    "href": "unidad_2/05_graficos_avanzados.html#funciones-adicionales",
    "title": "Herramientas avanzadas",
    "section": "Funciones adicionales",
    "text": "Funciones adicionales\nEl paquete orchaRd permite generar una tabla de resultados del modelo con la funci√≥n mod_results():\n\nmod_results(mod, \n            group = \"study\", \n            mod = \"type\")\n\n        name    estimate    lowerCL     upperCL    lowerPR      upperPR\n1 Fellowship -0.20101927 -0.2851769 -0.11686163 -0.3957853 -0.006253206\n2      Grant -0.01203987 -0.0869243  0.06284457 -0.2029822  0.178902506\n\n\nTamni√©n podemos calcular la bondad de ajuste (\\(R^2\\)) usando la funci√≥n r2_ml():\n\nr2_ml(mod)\n\n   R2_marginal R2_conditional \n     0.5187737      0.7874844 \n\n\nSi queremos obtener el \\(I^2\\) correspondiente a la heterogeneidad intra-cl√∫ster (\\(I^2_{nivel2}\\)) e inter-cl√∫ster (\\(I^2_{nivel3}\\)) para el modelo multinivel podemos usar la funci√≥n i2_ml() de orchaRd:\n\ni2_ml(mod)\n\n   I2_Total    I2_study I2_study/id \n   56.13549    31.34535    24.79014 \n\n\nEl paquete dmetar (Harrer et¬†al. 2019) tambi√©n permite calcular estos \\(I^2\\) usando la funci√≥n mlm.variance.distribution():\n\nmlm.variance.distribution(mod)\n\n        % of total variance    I2\nLevel 1            43.86451   ---\nLevel 2            24.79014 24.79\nLevel 3            31.34535 31.35\nTotal I2: 56.14% \n\n\nTambi√©n podemos graficar el aporte de cada componente a la varianza:\n\ni2 &lt;- mlm.variance.distribution(mod) \n\nplot(i2)\n\n\n\n\n\n\n\n\nLa funci√≥n find.outliers() del paquete dmetar permite detectar outliers en modelos de efectos aleatorios ajustados con meta o metafor (no permite estructuras multinivel):\n\n# Reajustar modelo\nmod2 &lt;- rma(yi = yi,               \n           vi = vi,     \n           method = \"REML\",\n           mods = ~ type,         \n           data = datos)\n\n# Detectar outliers\nfind.outliers(mod2)\n\nIdentified outliers (REML) \n------------------------- \n\"Allmendinger (2002).7\", \"Bornmann (2005)\", \"Brouns (2000).3\", \"Brouns (2000).4\", \"Friesen (1998).1\", \"Friesen (1998).3\", \"Goldsmith (2002).2\", \"NSF (2005).2\", \"NSF (2005).3\", \"NSF (2005).4\", \"NSF (2005).6\", \"NSF (2005).7\", \"NSF (2005).8\", \"Viner (2004).1\", \"Willems (2001).1\", \"Willems (2001).3\" \n \nResults with outliers removed \n----------------------------- \n\nRandom-Effects Model (k = 50; tau^2 estimator: REML)\n\ntau^2 (estimated amount of total heterogeneity): 0.0213 (SE = 0.0105)\ntau (square root of estimated tau^2 value):      0.1458\nI^2 (total heterogeneity / total variability):   57.76%\nH^2 (total variability / sampling variability):  2.37\n\nTest for Heterogeneity:\nQ(df = 49) = 144.2567, p-val &lt; .0001\n\nModel Results:\n\nestimate      se     zval    pval    ci.lb    ci.ub     \n -0.0961  0.0371  -2.5933  0.0095  -0.1688  -0.0235  ** \n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\npodemos obtener la tabla de coeficientes del modelo usando la funci√≥n mod_results():",
    "crumbs": [
      "Introducci√≥n a la Revisi√≥n Sistem√°tica con Meta-an√°lisis",
      "Meta-an√°lisis",
      "Herramientas avanzadas"
    ]
  },
  {
    "objectID": "unidad_2/03_tipos_estimador.html",
    "href": "unidad_2/03_tipos_estimador.html",
    "title": "Estimadores de efecto",
    "section": "",
    "text": "En esta secci√≥n repasaremos los principales estimadores de efecto utilizados en estudios epidemiol√≥gicos, junto con ejemplos pr√°cticos para su ajuste e interpretaci√≥n en R.\nComenzaremos por cargar el paquete meta, que permite realizar an√°lisis de efectos fijos y aleatorios, as√≠ como representar los resultados mediante gr√°ficos tipo forest plot:\n\nlibrary(meta)\n\nLoading required package: metadat\n\n\nLoading 'meta' package (version 8.1-0).\nType 'help(meta)' for a brief overview.\n\n\n\nAttaching package: 'meta'\n\n\nThe following object is masked from 'package:parameters':\n\n    ci\n\n\nThe following object is masked from 'package:effectsize':\n\n    nnt\n\n\nThe following object is masked from 'package:bayestestR':\n\n    ci\n\n\nPara facilitar la exploraci√≥n y manipulaci√≥n de datos, utilizaremos funciones del paquete tidyverse(Wickham et¬†al. 2019):\n\nlibrary(tidyverse)\n\nEn secciones anteriores, exploramos c√≥mo personalizar los colores de los forest plot mediante los argumentos col.diamond y col.square. Para garantizar que los gr√°ficos resultantes sean accesibles a personas con deficiencia en la percepci√≥n del color, emplearemos paletas adaptadas (colorblind-friendly) del paquete scico (Pedersen y Crameri 2023):\n\n# Cargar el paquete\nlibrary(scico)\n\n# Mostrar paletas categ√≥ricas disponibles\nscico_palette_show(categorical = TRUE)\n\n\n\n\n\n\n\n\nEn los ejemplos siguientes, emplearemos la paleta \"hawaii\", que genera un gradiente entre tonos magenta y turquesa:\n\n# Paleta colorblind-friendly\npal &lt;- scico(n = 3, palette = \"hawaii\")",
    "crumbs": [
      "Introducci√≥n a la Revisi√≥n Sistem√°tica con Meta-an√°lisis",
      "Meta-an√°lisis",
      "Estimadores de efecto"
    ]
  },
  {
    "objectID": "unidad_2/03_tipos_estimador.html#introducci√≥n",
    "href": "unidad_2/03_tipos_estimador.html#introducci√≥n",
    "title": "Estimadores de efecto",
    "section": "",
    "text": "En esta secci√≥n repasaremos los principales estimadores de efecto utilizados en estudios epidemiol√≥gicos, junto con ejemplos pr√°cticos para su ajuste e interpretaci√≥n en R.\nComenzaremos por cargar el paquete meta, que permite realizar an√°lisis de efectos fijos y aleatorios, as√≠ como representar los resultados mediante gr√°ficos tipo forest plot:\n\nlibrary(meta)\n\nLoading required package: metadat\n\n\nLoading 'meta' package (version 8.1-0).\nType 'help(meta)' for a brief overview.\n\n\n\nAttaching package: 'meta'\n\n\nThe following object is masked from 'package:parameters':\n\n    ci\n\n\nThe following object is masked from 'package:effectsize':\n\n    nnt\n\n\nThe following object is masked from 'package:bayestestR':\n\n    ci\n\n\nPara facilitar la exploraci√≥n y manipulaci√≥n de datos, utilizaremos funciones del paquete tidyverse(Wickham et¬†al. 2019):\n\nlibrary(tidyverse)\n\nEn secciones anteriores, exploramos c√≥mo personalizar los colores de los forest plot mediante los argumentos col.diamond y col.square. Para garantizar que los gr√°ficos resultantes sean accesibles a personas con deficiencia en la percepci√≥n del color, emplearemos paletas adaptadas (colorblind-friendly) del paquete scico (Pedersen y Crameri 2023):\n\n# Cargar el paquete\nlibrary(scico)\n\n# Mostrar paletas categ√≥ricas disponibles\nscico_palette_show(categorical = TRUE)\n\n\n\n\n\n\n\n\nEn los ejemplos siguientes, emplearemos la paleta \"hawaii\", que genera un gradiente entre tonos magenta y turquesa:\n\n# Paleta colorblind-friendly\npal &lt;- scico(n = 3, palette = \"hawaii\")",
    "crumbs": [
      "Introducci√≥n a la Revisi√≥n Sistem√°tica con Meta-an√°lisis",
      "Meta-an√°lisis",
      "Estimadores de efecto"
    ]
  },
  {
    "objectID": "unidad_2/03_tipos_estimador.html#meta-an√°lisis-en-estudios-descriptivos",
    "href": "unidad_2/03_tipos_estimador.html#meta-an√°lisis-en-estudios-descriptivos",
    "title": "Estimadores de efecto",
    "section": "Meta-an√°lisis en estudios descriptivos",
    "text": "Meta-an√°lisis en estudios descriptivos\nEn estudios descriptivos, los principales estimadores de efecto son la correlaci√≥n, la prevalencia y la tasa de incidencia. A continuaci√≥n, abordaremos c√≥mo ajustar modelos de meta-an√°lisis para cada uno de estos casos.\n\nCorrelaciones\nLa correlaci√≥n mide la fuerza y direcci√≥n de la relaci√≥n lineal entre dos variables num√©ricas continuas, y se calcula mediante la siguiente f√≥rmula:\n\\[\nr_{xy} = \\frac{Cov_{xy}}{S_xS_y}\n\\tag{1}\\]\ndonde:\n\n\\(Cov_{xy}\\) es la covarianza entre las variables \\(x\\) e \\(y\\).\n\\(S_x\\) y \\(S_y\\) son los desv√≠os est√°ndar de cada variable.\n\nDado que los coeficientes de correlaci√≥n se encuentran en un rango entre -1 y 1, su distribuci√≥n no es sim√©trica, lo cual puede afectar la estimaci√≥n del error est√°ndar en muestras peque√±as. Para corregir este sesgo y estabilizar la varianza, se utiliza la transformaci√≥n z de Fisher.\nLa funci√≥n metacor() permite ajustar modelos de meta-an√°lisis para correlaciones y aplica autom√°ticamente esta transformaci√≥n cuando se especifica el argumento sm = \"ZCOR\".\nComo ejemplo, utilizaremos la base de datos dat.molloy2014, que recopila resultados de 16 estudios sobre la relaci√≥n entre concienciaci√≥n y adherencia a la medicaci√≥n.\n\n# Cargar datos\ndatos_cor &lt;- dat.molloy2014\n\n# Explorar la estructura de los datos\nglimpse(datos_cor)\n\nRows: 16\nColumns: 10\n$ authors   &lt;chr&gt; \"Axelsson et al.\", \"Axelsson et al.\", \"Bruce et al.\", \"Chris‚Ä¶\n$ year      &lt;int&gt; 2009, 2011, 2010, 1999, 1995, 2004, 2005, 2007, 2006, 2011, ‚Ä¶\n$ ni        &lt;int&gt; 109, 749, 55, 107, 72, 65, 174, 326, 58, 771, 56, 91, 116, 5‚Ä¶\n$ ri        &lt;dbl&gt; 0.187, 0.162, 0.340, 0.320, 0.270, 0.000, 0.175, 0.050, 0.26‚Ä¶\n$ controls  &lt;chr&gt; \"none\", \"none\", \"none\", \"none\", \"none\", \"none\", \"none\", \"mul‚Ä¶\n$ design    &lt;chr&gt; \"cross-sectional\", \"cross-sectional\", \"prospective\", \"cross-‚Ä¶\n$ a_measure &lt;chr&gt; \"self-report\", \"self-report\", \"other\", \"self-report\", \"other‚Ä¶\n$ c_measure &lt;chr&gt; \"other\", \"NEO\", \"NEO\", \"other\", \"NEO\", \"NEO\", \"NEO\", \"NEO\", ‚Ä¶\n$ meanage   &lt;dbl&gt; 22.00, 53.59, 43.36, 41.70, 46.39, 41.20, 52.30, 41.00, 77.0‚Ä¶\n$ quality   &lt;int&gt; 1, 1, 2, 1, 2, 2, 1, 3, 2, 3, 2, 2, 1, 2, 3, 1\n\n\nLas principales variables de inter√©s son:\n\nri: coeficiente de correlaci√≥n.\nni: tama√±o muestral de cada estudio.\nauthors: identificador del estudio.\n\nAjustamos un modelo de meta-an√°lisis para correlaciones aplicando la transformaci√≥n z de Fisher:\n\nmod_cor &lt;- metacor(\n1  cor = ri,\n2  n = ni,\n3  studlab = authors,\n4  data = datos_cor,\n5  sm = \"ZCOR\",\n6  common = TRUE,\n7  random = TRUE,\n8  backtransf = TRUE,\n9  prediction = TRUE\n)\n\n\n1\n\nCoeficiente de correlaci√≥n para cada estudio.\n\n2\n\nTama√±o de la muestra en cada estudio.\n\n3\n\nIdentificador √∫nico del estudio.\n\n4\n\nConjunto de datos.\n\n5\n\nEstimador de efecto (\"ZCOR\" por defecto/\"COR\").\n\n6\n\nAjustar el modelo de efectos fijos (TRUE por defecto /FALSE).\n\n7\n\nAjustar el modelo de efectos aleatorios (TRUE por defecto /FALSE).\n\n8\n\nMostrar resultados en escala original de los datos (TRUE por defecto /FALSE).\n\n9\n\nCalcular el intervalo de predicci√≥n (TRUE/FALSE por defecto).\n\n\n\n\n\n\n\n\n\n\nNo es necesario especificar los argumentos common, random, sm, backstransf o prediction a menos que se desee cambiar las opciones por defecto.\nEl siguiente c√≥digo genera los mismos resultados que el ejemplo:\n\nmetacor(\n  cor = ri,           \n  n = ni,\n  studlab = authors,\n  data = datos_cor,\n  prediction = TRUE\n)\n\nNumber of studies: k = 16\nNumber of observations: o = 3509\n\n                        COR            95%-CI    z  p-value\nCommon effect model  0.1245 [ 0.0916; 0.1572] 7.36 &lt; 0.0001\nRandom effects model 0.1488 [ 0.0878; 0.2087] 4.75 &lt; 0.0001\nPrediction interval         [-0.0534; 0.3393]              \n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.0081 [0.0017; 0.0378]; tau = 0.0901 [0.0412; 0.1944]\n I^2 = 60.7% [32.1%; 77.2%]; H = 1.59 [1.21; 2.10]\n\nTest of heterogeneity:\n     Q d.f. p-value\n 38.16   15  0.0009\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n- Prediction interval based on t-distribution (df = 15)\n- Fisher's z transformation of correlations\n\n\n\n\n\nAnalicemos ahora la salida del modelo:\n\nmod_cor\n\nNumber of studies: k = 16\nNumber of observations: o = 3509\n\n                        COR            95%-CI    z  p-value\nCommon effect model  0.1245 [ 0.0916; 0.1572] 7.36 &lt; 0.0001\nRandom effects model 0.1488 [ 0.0878; 0.2087] 4.75 &lt; 0.0001\nPrediction interval         [-0.0534; 0.3393]              \n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.0081 [0.0017; 0.0378]; tau = 0.0901 [0.0412; 0.1944]\n I^2 = 60.7% [32.1%; 77.2%]; H = 1.59 [1.21; 2.10]\n\nTest of heterogeneity:\n     Q d.f. p-value\n 38.16   15  0.0009\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n- Prediction interval based on t-distribution (df = 15)\n- Fisher's z transformation of correlations\n\n\nEl valor de \\(I^2\\) indica que los datos presentan una heterogeneidad moderada y debe descartarse el modelo de efectos fijos.\nA diferencia de lo que vimos para datos precalculados, la salida nos muestra no solo el n√∫mero de estudios incluidos (k) sino tambi√©n el n√∫mero total de observaciones (o).\nDe acuerdo al modelo de efectos aleatorios, existe una correlaci√≥n positiva baja entre la concienciaci√≥n y la adherencia a la medicaci√≥n. Sin embargo, el intervalo de predicci√≥n incluye la posibilidad de que futuros estudios reporten correlaciones negativas.\nGeneramos el forest plot para visualizar los resultados:\n\nforest(\n  mod_cor, \n  col.diamond.random = pal[1], \n  col.square = pal[3],\n1  common = FALSE,\n2  smlab = \"Correlaci√≥n de Pearson\",\n3  leftlabs = c(\"Estudio\", \"N\"),\n4  rightlabs = c(\"r\", \"95% IC\", \"Peso\"),\n5  hetlab = \"Heterogeneidad: \",\n6  text.random = \"Modelo de \\n efectos aleatorios\",\n7  prediction = TRUE\n)\n\n\n1\n\nOmitir modelo de efectos fijos.\n\n2\n\nPersonalizar etiqueta del estimador de efecto.\n\n3\n\nPersonalizar etiquetas del panel izquierdo.\n\n4\n\nPersonalizar etiquetas del panel derecho.\n\n5\n\nPersonalizar etiqueta indicadores de heterogeneidad.\n\n6\n\nPersonalizar etiqueta del estimador global.\n\n7\n\nMostrar intervalo de predicci√≥n (opcional).\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrevalencia\nLa prevalencia representa la proporci√≥n de individuos con un evento de inter√©s dentro de una poblaci√≥n:\n\\[\np = \\frac{k}{n}\n\\tag{2}\\]\ndonde:\n\n\\(k\\) es el n√∫mero de individuos con la condici√≥n/evento.\n\\(n\\) es el tama√±o total de la poblaci√≥n o muestra.\n\nDado que las proporciones pueden estar cercanas a los valores extremos (0 o 1), su distribuci√≥n es asim√©trica, lo que afecta el c√°lculo del error est√°ndar. Para corregir este problema, se aplica una transformaci√≥n logit a los datos.\nLa funci√≥n metaprop() permite ajustar modelos para prevalencias e incorpora autom√°ticamente esta transformaci√≥n con el argumento sm = \"PLOGIT\".\nPara ejemplificar, usaremos la base de datos dat.crisafulli2020, que contiene resultados de 26 estudios sobre la prevalencia de la distrofia muscular de Duchenne en reci√©n nacidos:\n\n# Cargar datos\ndatos_prev &lt;- dat.crisafulli2020\n\n# Explorar estructura de los datos\nglimpse(datos_prev)\n\nRows: 26\nColumns: 7\n$ study   &lt;chr&gt; \"Brooks (1977)\", \"Danieli (1977)\", \"Takeshita (1977)\", \"Drummo‚Ä¶\n$ pubyear &lt;int&gt; 1977, 1977, 1977, 1979, 1980, 1980, 1981, 1982, 1983, 1983, 19‚Ä¶\n$ country &lt;fct&gt; UK, IT, JP, NZ, AU, IT, IT, CA, FR, IT, DE, IT, JP, CA, NO, IT‚Ä¶\n$ from    &lt;int&gt; 1953, 1952, 1956, NA, 1960, 1952, 1955, 1950, 1978, 1969, 1977‚Ä¶\n$ to      &lt;int&gt; 1968, 1972, 1970, NA, 1971, 1972, 1974, 1979, 1978, 1980, 1984‚Ä¶\n$ cases   &lt;int&gt; 47, 66, 19, 2, 99, 105, 73, 110, 12, 156, 48, 76, 50, 5, 16, 2‚Ä¶\n$ total   &lt;int&gt; 177413, 234396, 91157, 10000, 532302, 371698, 301283, 420374, ‚Ä¶\n\n\nLas principales variables de inter√©s son:\n\ncases: individuos con el evento.\ntotal: tama√±o muestral.\nstudy: identificador de estudio.\n\nAjustamos el modelo de meta-an√°lisis para proporciones aplicando la transformaci√≥n logit:\n\nmod_prev &lt;- metaprop(\n1  event = cases,\n2  n = total,\n3  studlab = study,\n4  data = datos_prev,\n5  sm = \"PLOGIT\",\n6  prediction = TRUE,\n7  pscale = 100\n)\n\n\n1\n\nCasos observados en cada estudio.\n\n2\n\nTama√±o muestral del estudio.\n\n3\n\nIdentificador √∫nico del estudio.\n\n4\n\nConjunto de datos.\n\n5\n\nEstimador de efecto (\"PLOGIT\" por defecto, ver ayuda de la funci√≥n para otras opciones).\n\n6\n\nCalcular intervalos de predicci√≥n (TRUE/FALSE por defecto).\n\n7\n\nExpresar los estimadores de efecto como porcentajes.\n\n\n\n\nAnalicemos ahora la salida del modelo:\n\nmod_prev\n\nNumber of studies: k = 26\nNumber of observations: o = 6831388\nNumber of events: e = 1545\n\n                     events           95%-CI\nCommon effect model  0.0226 [0.0215; 0.0238]\nRandom effects model 0.0222 [0.0206; 0.0240]\nPrediction interval         [0.0174; 0.0284]\n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.0126; tau = 0.1121; I^2 = 33.2% [0.0%; 58.6%]; H = 1.22 [1.00; 1.55]\n\nTest of heterogeneity:\n          Q d.f. p-value\n Wald 37.41   25  0.0527\n LRT  39.01   25  0.0368\n\nDetails of meta-analysis methods:\n- Random intercept logistic regression model\n- Maximum-likelihood estimator for tau^2\n- Calculation of I^2 based on Q\n- Prediction interval based on t-distribution (df = 25)\n- Logit transformation\n- Events per 100 observations\n\n\nEl valor de \\(I^2\\) indica que los datos presentan una heterogeneidad moderada y puede descartarse el modelo de efectos fijos. Como la heterogeneidad no es demasiado alta, el intervalo de predicci√≥n es similar al intervalo de confianza del modelo de efectos aleatorios.\nEl coeficiente del modelo de efectos aleatorios muestra una prevalencia del evento del 0,022%, por lo que vamos a expresarla en casos por 100 000 habitantes al momento de realizar el forest plot.\n\nforest(\n  mod_prev, \n  col.diamond.random = pal[1], \n  col.square = pal[3],\n1  common = FALSE,\n2  smlab = \"Prevalencia \\n (por 100 000 hab.)\",\n3  leftlabs = c(\"Estudio\", \"Eventos\", \"N\"),\n4  rightlabs = c(\"Prev.\", \"95% IC\"),\n5  hetlab = \"Heterogeneidad: \",\n6  text.random = \"Modelo de \\n efectos aleatorios\",\n7  pscale = 100000\n)\n\n\n1\n\nOmitir modelo de efectos fijos.\n\n2\n\nPersonalizar etiqueta del estimador de efecto.\n\n3\n\nPersonalizar etiquetas del panel izquierdo.\n\n4\n\nPersonalizar etiquetas del panel derecho.\n\n5\n\nPersonalizar etiqueta indicadores de heterogeneidad.\n\n6\n\nPersonalizar etiqueta del estimador global.\n\n7\n\nExpresar coeficientes en casos cada 100000 habitantes.\n\n\n\n\n\n\n\n\n\n\n\n\n\nTasa de incidencia\nLa tasa de incidencia o incidence rate (IR) se utiliza para eventos que ocurren a lo largo del tiempo y se define como:\n\\[\nIR = \\frac {k}{T}\n\\tag{3}\\]\ndonde:\n\n\\(k\\) es el n√∫mero de eventos observados.\n\\(T\\) es la suma del tiempo-persona en riesgo en cada estudio.\n\nDado que las tasas de incidencia pueden ser peque√±as y asim√©tricas, se recomienda aplicar una transformaci√≥n logar√≠tmica a los datos para estabilizar su varianza.\nLa funci√≥n metarate() ajusta modelos de meta-an√°lisis para tasas de incidencia, aplicando esta transformaci√≥n (sm = \"IRLN\").\nComo ejemplo, usamos la base dat.nielweise2008, que contiene 9 estudios sobre la incidencia de infecciones sangu√≠neas asociadas al uso de cat√©teres:\n\n# Cargar datos\ndatos_inc &lt;- dat.nielweise2008\n\n# Explorar estructura de los datos\nglimpse(datos_inc)\n\nRows: 9\nColumns: 7\n$ study   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9\n$ authors &lt;chr&gt; \"Bong et al.\", \"Ciresi et al.\", \"Hanna et al.\", \"Harter et al.‚Ä¶\n$ year    &lt;int&gt; 2003, 1996, 2004, 2002, 2001, 2005, 1997, 2005, 1996\n$ x1i     &lt;int&gt; 7, 8, 3, 6, 1, 1, 17, 3, 2\n$ t1i     &lt;int&gt; 1344, 1600, 12012, 1536, 370, 729, 6760, 1107, 320\n$ x2i     &lt;int&gt; 11, 8, 14, 10, 1, 8, 15, 7, 3\n$ t2i     &lt;int&gt; 1988, 1461, 10962, 1503, 483, 913, 6840, 1015, 440\n\n\nLas principales variables de inter√©s son:\n\nx2i: casos observados en el grupo i.\nt2i: a√±os-persona en riesgo en el grupo i.\nauthors: identificador de estudio.\n\nAjustamos el modelo de meta-an√°lisis para tasas de incidencia aplicando la transformaci√≥n logar√≠tmica:\n\nmod_inc &lt;- metarate(\n1  event = x2i,\n2  time = t2i,\n3  studlab = authors,\n4  data = datos_inc,\n5  sm = \"IRLN\",\n6  prediction = TRUE\n)\n\n\n1\n\nCasos observados en cada estudio.\n\n2\n\nTiempo-persona en riesgo en cada estudio.\n\n3\n\nIdentificador √∫nico del estudio.\n\n4\n\nConjunto de datos.\n\n5\n\nEstimador de efecto (\"IRLN\" por defecto, ver ayuda de la funci√≥n para otras opciones).\n\n6\n\nCalcular intervalos de predicci√≥n (TRUE/FALSE por defecto).\n\n\n\n\nAnalicemos ahora la salida del modelo:\n\nmod_inc\n\nNumber of studies: k = 9\nNumber of events: e = 77\n\n                       rate           95%-CI\nCommon effect model  0.0039 [0.0031; 0.0048]\nRandom effects model 0.0043 [0.0027; 0.0070]\nPrediction interval         [0.0010; 0.0196]\n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.3699 [0.0940; 1.5145]; tau = 0.6082 [0.3065; 1.2307]\n I^2 = 78.0% [58.4%; 88.4%]; H = 2.13 [1.55; 2.93]\n\nTest of heterogeneity:\n     Q d.f.  p-value\n 36.38    8 &lt; 0.0001\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n- Prediction interval based on t-distribution (df = 8)\n- Log transformation\n\n\nEl valor de \\(I^2\\) indica que los datos presentan una heterogeneidad alta y debe descartarse el modelo de efectos fijos. El intervalo de predicci√≥n muestra que se pueden esperar tasas m√°s altas o bajas en estudios futuros.\nEl coeficiente del modelo de efectos aleatorio muestra que la tasa de incidencia del evento es muy baja dentro del grupo estudiado, por lo que vamos a expresarla en casos por 1000 a√±os-persona cuando ajustemos el forest plot.\n\nforest(\n  mod_inc, \n  col.diamond.random = pal[1], \n  col.square = pal[3],\n1  common = FALSE,\n2  smlab = \"Tasa de incidencia \\n (1000 a√±os-persona)\",\n3  leftlabs = c(\"Estudio\", \"Eventos\", \"Tiempo\"),\n4  rightlabs = c(\"Tasa\", \"95% IC\", \"Peso\"),\n5  hetlab = \"Heterogeneidad: \",\n6  text.random = \"Modelo de \\n efectos aleatorios\",\n7  pscale = 1000\n)\n\n\n1\n\nOmitir modelo de efectos fijos.\n\n2\n\nPersonalizar etiqueta del estimador de efecto.\n\n3\n\nPersonalizar etiquetas del panel izquierdo.\n\n4\n\nPersonalizar etiquetas del panel derecho.\n\n5\n\nPersonalizar etiqueta indicadores de heterogeneidad.\n\n6\n\nPersonalizar etiqueta del estimador global.\n\n7\n\nExpresar coeficientes en casos cada 1000 a√±os-persona.",
    "crumbs": [
      "Introducci√≥n a la Revisi√≥n Sistem√°tica con Meta-an√°lisis",
      "Meta-an√°lisis",
      "Estimadores de efecto"
    ]
  },
  {
    "objectID": "unidad_2/03_tipos_estimador.html#meta-an√°lisis-en-estudios-anal√≠ticos",
    "href": "unidad_2/03_tipos_estimador.html#meta-an√°lisis-en-estudios-anal√≠ticos",
    "title": "Estimadores de efecto",
    "section": "Meta-an√°lisis en estudios anal√≠ticos",
    "text": "Meta-an√°lisis en estudios anal√≠ticos\nDentro de los estudios anal√≠ticos (observacionales y/o experimentales), los estimadores de efecto m√°s comunes son la diferencia de medias, el odds-ratio (OR), el riesgo relativo (RR) y la raz√≥n de tasas de incidencia (IRR). A continuaci√≥n, mostraremos su implementaci√≥n en R.\n\nDiferencia de medias\nLa diferencia de medias entre dos grupos de exposici√≥n se define como:\n\\[\nMD = \\bar{x_e} - \\bar{x_c}\n\\tag{4}\\]\ndonde:\n\n\\(\\bar{x_e}\\) es la media muestral del grupo expuesto o tratado.\n\\(\\bar{x_c}\\) es la media muestral del grupo no expuesto o control.\n\nEl c√°lculo de la diferencia de medias requiere que todas las mediciones se hayan tomado en la misma escala. Para los modelos de meta-an√°lisis, se utiliza la diferencia de medias estandarizada, que elimina la dependencia de las unidades de medici√≥n al ponderar por el desv√≠o est√°ndar.\nLa funci√≥n metacont() ajusta modelos de meta-an√°lisis para diferencias de medias estandarizadas con el argumento sm = \"SMD\".\nComo ejemplo, utilizaremos la base de datos dat.furukawa2003, que contiene resultados de 17 estudios sobre la efectividad de la dosis de antidepresivos tric√≠clicos en casos de depresi√≥n severa.\n\n# Cargar datos\ndatos_md &lt;- dat.furukawa2003\n\n# Explorar estructura de los datos\nglimpse(datos_md)\n\nRows: 17\nColumns: 7\n$ author &lt;chr&gt; \"Blashki(75&150)\", \"Hormazabal(86)\", \"Jacobson(75-100)\", \"Jenki‚Ä¶\n$ Ne     &lt;int&gt; 13, 17, 10, 7, 73, 26, 17, 11, 105, 22, 13, 29, 13, 78, 23, 11,‚Ä¶\n$ Me     &lt;dbl&gt; 6.40, 11.00, 17.50, 12.30, 15.70, 8.50, 25.50, 6.20, -8.10, 13.‚Ä¶\n$ Se     &lt;dbl&gt; 5.40, 8.20, 8.80, 9.90, 10.60, 11.00, 24.00, 7.60, 3.90, 2.30, ‚Ä¶\n$ Nc     &lt;int&gt; 18, 16, 6, 7, 73, 28, 10, 10, 46, 19, 15, 39, 13, 71, 23, 11, 18\n$ Mc     &lt;dbl&gt; 11.40, 19.00, 23.00, 20.00, 18.70, 14.50, 53.20, 10.00, -8.50, ‚Ä¶\n$ Sc     &lt;dbl&gt; 9.60, 8.20, 8.80, 10.50, 10.60, 11.00, 11.20, 7.60, 5.20, 1.30,‚Ä¶\n\n\nLas principales variables de inter√©s son:\n\nMe: media muestral en grupo expuesto/tratamiento.\nSe: desv√≠o est√°ndar de la media en grupo expuesto/tratamiento.\nNe: tama√±o muestral en grupo expuesto/tratamiento.\nMc: media muestral en grupo no expuesto/control.\nSc: desv√≠o est√°ndar de la media en grupo no expuesto/control.\nNc: tama√±o muestral en grupo no expuesto/control.\nauthor: identificador de estudio.\n\nAjustamos el modelo de meta-an√°lisis para diferencia de medias estandarizada:\n\nmod_md &lt;- metacont(\n1  n.e = Ne,\n2  mean.e = Me,\n3  sd.e = Se,\n4  n.c = Nc,\n5  mean.c = Mc,\n6  sd.c = Sc,\n7  studlab = author,\n8  data = datos_md,\n9  sm = \"SMD\",\n10  prediction = TRUE\n)\n\n\n1\n\nTama√±o muestral del grupo expuesto en cada estudio.\n\n2\n\nMedia del grupo expuesto en cada estudio.\n\n3\n\nDesv√≠o est√°ndar del grupo expuesto en cada estudio.\n\n4\n\nTama√±o muestral del grupo no expuesto o control en cada estudio.\n\n5\n\nMedia del grupo no expuesto o control en cada estudio.\n\n6\n\nDesv√≠o est√°ndar del grupo no expuesto o control en cada estudio.\n\n7\n\nIdentificador √∫nico del estudio.\n\n8\n\nConjunto de datos.\n\n9\n\nEstimador de efecto (\"SMD\" por defecto, ver ayuda de la funci√≥n para otras opciones).\n\n10\n\nCalcular intervalos de predicci√≥n (TRUE/FALSE por defecto).\n\n\n\n\nAnalicemos ahora la salida del modelo:\n\nmod_md\n\nNumber of studies: k = 17\nNumber of observations: o = 902 (o.e = 479, o.c = 423)\n\n                         SMD             95%-CI     z  p-value\nCommon effect model  -0.3918 [-0.5286; -0.2551] -5.62 &lt; 0.0001\nRandom effects model -0.6056 [-0.9326; -0.2787] -3.63   0.0003\nPrediction interval          [-1.8940;  0.6827]               \n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.3415 [0.1422; 1.1791]; tau = 0.5844 [0.3771; 1.0859]\n I^2 = 72.6% [55.5%; 83.1%]; H = 1.91 [1.50; 2.43]\n\nTest of heterogeneity:\n     Q d.f.  p-value\n 58.38   16 &lt; 0.0001\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n- Prediction interval based on t-distribution (df = 16)\n- Hedges' g (bias corrected standardised mean difference; using exact formulae)\n\n\nEl valor de \\(I^2\\) indica que los datos presentan una heterogeneidad alta y debe descartarse el modelo de efectos fijos.\nLos coeficientes del modelo de efectos aleatorios indican que el grupo tratado con antidepresivos tric√≠clicos presenta una reducci√≥n en los s√≠ntomas respecto del grupo control \\((p&lt;0,001)\\). El intervalo de predicci√≥n muestra que es posible que estudios futuros encuentren el efecto inverso al estimado.\nGeneramos el forest plot para visualizar los resultados:\n\nforest(\n  mod_md, \n  col.diamond.random = pal[1], \n  col.square = pal[3],\n1  common = FALSE,\n2  smlab = \"Diferencia de medias \\n estandarizada\",\n  leftlabs = c(\"Estudio\", \n3               rep(c(\"Total\", \"Media\", \"SD\"),2)),\n4  rightlabs = c(\"SMD\", \"95% IC\", \"Peso\"),\n5  hetlab = \"Heterogeneidad: \",\n6  text.random = \"Modelo de \\n efectos aleatorios\",\n)\n\n\n1\n\nOmitir modelo de efectos fijos.\n\n2\n\nPersonalizar etiqueta del estimador de efecto.\n\n3\n\nPersonalizar etiquetas del panel izquierdo.\n\n4\n\nPersonalizar etiquetas del panel derecho.\n\n5\n\nPersonalizar etiqueta indicadores de heterogeneidad.\n\n6\n\nPersonalizar etiqueta del estimador global.\n\n\n\n\n\n\n\n\n\n\n\nPara mejorar la visualizaci√≥n, podemos modificar el argumento leftcols para mostrar solamente el identificador de estudio en el panel izquierdo:\n\nforest(\n  mod_md,\n  common = FALSE,        \n  col.diamond = pal[1],\n  col.square = pal[3],\n  smlab = \"Diferencia de medias \\n estandarizada\",\n  leftlabs = \"Estudio\",\n  rightlabs = c(\"SMD\", \"95% IC\", \"Peso\"),\n  hetlab = \"Heterogeneidad: \",\n  text.random = \"Modelo de efectos aleatorios\",\n  leftcols = \"studlab\"\n  )\n\n\n\n\n\n\n\n\n\n\nOdds-ratio\nEl odds ratio (OR) o raz√≥n de productos cruzados se define como el cociente entre los odds del evento en el grupo expuesto/tratamiento y en el grupo no expuesto/control:\n\\[\nOR =  \\frac{a/b}{c/d}\n\\tag{5}\\]\ndonde:\n\n\\(a\\) es el n√∫mero de eventos en el grupo expuesto/tratamiento.\n\\(b\\) es el n√∫mero de individuos sin el evento en el grupo expuesto/tratamiento.\n\\(c\\) es el n√∫mero de eventos en el grupo no expuesto/control.\n\\(d\\) es el n√∫mero de individuos sin el evento en el grupo no expuesto/control.\n\nEl OR solo puede tomar valores positivos \\((0-\\infty)\\), donde:\n\n\\(OR = 1\\) indica ausencia de efecto.\n\\(OR &gt;1\\) sugiere un aumento en la probabilidad de ocurrencia del evento en el grupo expuesto.\n\\(OR &lt; 1\\) sugiere un posible efecto protector de la exposici√≥n o tratamiento.\n\nDado que el OR sigue una distribuci√≥n asim√©trica, su an√°lisis estad√≠stico puede ser complejo. Para estabilizar la varianza y aproximar una distribuci√≥n normal, se aplica una transformaci√≥n logar√≠tmica.\nLa funci√≥n metabin() ajusta modelos de meta-an√°lisis para OR e incorpora autom√°ticamente esta transformaci√≥n mediante el argumento sm = \"OR\". Adem√°s, incluye una correcci√≥n de continuidad para manejar estudios con valores de eventos iguales a cero.\nEl siguiente ejemplo utiliza la base de datos dat.collins1985b, que contiene informaci√≥n de 9 estudios sobre el efecto de los diur√©ticos en la prevenci√≥n de preeclampsia.\nComenzamos cargando los datos y explorando su estructura:\n\n# Carga datos\ndatos_or &lt;- dat.collins1985b\n\n# Explorar estructura de los datos\nglimpse(datos_or)\n\nRows: 9\nColumns: 16\n$ id      &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9\n$ author  &lt;chr&gt; \"Weseley & Douglas\", \"Flowers et al.\", \"Menzies\", \"Fallis et a‚Ä¶\n$ year    &lt;int&gt; 1962, 1962, 1964, 1964, 1964, 1965, 1966, 1971, 1975\n$ pre.nti &lt;int&gt; 131, 385, 57, 38, 1011, 1370, 506, 108, 153\n$ pre.nci &lt;int&gt; 136, 134, 48, 40, 760, 1336, 524, 103, 102\n$ pre.xti &lt;int&gt; 14, 21, 14, 6, 12, 138, 15, 6, 65\n$ pre.xci &lt;int&gt; 14, 17, 24, 18, 35, 175, 20, 2, 40\n$ oedema  &lt;int&gt; 0, 0, 1, 0, 1, 0, 0, 0, 0\n$ fup.nti &lt;int&gt; 131, 335, 57, 34, 1011, 1370, 506, 108, 153\n$ fup.nci &lt;int&gt; 136, 110, 48, 40, 760, 1336, 524, 103, 102\n$ ped.xti &lt;int&gt; 1, 6, 3, 1, 14, 24, 14, 0, 0\n$ ped.xci &lt;int&gt; 4, 3, 2, 3, 13, 19, 16, 0, 0\n$ stb.xti &lt;int&gt; 1, 3, 1, 0, 6, NA, 6, 0, 0\n$ stb.xci &lt;int&gt; 2, 2, 1, 1, 5, NA, 9, 0, 0\n$ ned.xti &lt;int&gt; 0, 3, 2, 1, 8, NA, 8, 0, 0\n$ ned.xci &lt;int&gt; 2, 1, 1, 2, 8, NA, 7, 0, 0\n\n\nLas variables de inter√©s son:\n\npre.xti: n√∫mero de eventos en el grupo expuesto/tratamiento.\npre.nti: tama√±o muestral en el grupo expuesto/tratamiento.\npre.xci: n√∫mero de eventos en el grupo no expuesto/control.\npre.nti: tama√±o muestral en el grupo no expuesto/control.\nauthor: identificador del estudio.\n\nAjustamos el modelo de meta-an√°lisis para OR:\n\nmod_or &lt;- metabin(\n1  event.e = pre.xti,\n2  n.e = pre.nti,\n3  event.c = pre.xci,\n4  n.c = pre.nci,\n5  studlab = author,\n6  data = datos_or,\n7  sm = \"OR\",\n8  prediction = TRUE\n)\n\n\n1\n\nEventos en el grupo expuesto en cada estudio.\n\n2\n\nTama√±o muestral del grupo expuesto en cada estudio.\n\n3\n\nEventos en el grupo no expuesto/control en cada estudio.\n\n4\n\nTama√±o muestral del grupo no expuesto/control en cada estudio.\n\n5\n\nIdentificador √∫nico del estudio.\n\n6\n\nConjunto de datos.\n\n7\n\nEstimador de efecto (\"OR\" para Odds-ratio, \"RR\" para riesgo relativo, ver ayuda de la funci√≥n para otras opciones).\n\n8\n\nCalcular intervalos de predicci√≥n (TRUE/FALSE por defecto).\n\n\n\n\nAnalicemos ahora la salida del modelo:\n\nmod_or\n\nNumber of studies: k = 9\nNumber of observations: o = 6942 (o.e = 3759, o.c = 3183)\nNumber of events: e = 636\n\n                         OR           95%-CI     z  p-value\nCommon effect model  0.6677 [0.5620; 0.7932] -4.60 &lt; 0.0001\nRandom effects model 0.5956 [0.3843; 0.9233] -2.32   0.0205\nPrediction interval         [0.1520; 2.3343]               \n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.3008 [0.0723; 2.2027]; tau = 0.5484 [0.2689; 1.4842]\n I^2 = 70.7% [41.8%; 85.2%]; H = 1.85 [1.31; 2.60]\n\nTest of heterogeneity:\n     Q d.f. p-value\n 27.26    8  0.0006\n\nDetails of meta-analysis methods:\n- Mantel-Haenszel method (common effect model)\n- Inverse variance method (random effects model)\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n- Prediction interval based on t-distribution (df = 8)\n\n\nLa salida del modelo nos muestra el n√∫mero de estudios (k), el n√∫mero de observaciones total (o) y por grupo de exposici√≥n (o.e y o.c) y el n√∫mero de eventos.\nEl valor de \\(I^2\\) indica que los datos presentan una heterogeneidad alta y debe descartarse el modelo de efectos fijos.\nDe acuerdo al coeficiente del modelo de efectos aleatorios, el uso de diur√©ticos reduce significativamente las probabilidades de preeclampsia en comparaci√≥n con el grupo control \\((p = 0,021)\\). Sin embargo, el intervalo de predicci√≥n no descarta que futuros estudios encuentren la relaci√≥n inversa.\nGeneramos el forest plot para visualizar los resultados:\n\nforest(\n  mod_md, \n  col.diamond.random = pal[1], \n  col.square = pal[3],\n1  common = FALSE,\n2  smlab = \"Odds-ratio\",\n3  leftcols = \"studlab\",\n4  leftlabs = \"Estudio\",\n5  rightlabs = c(\"OR\", \"95% IC\", \"Peso\"),\n6  hetlab = \"Heterogeneidad: \",\n7  text.random = \"Modelo de \\n efectos aleatorios\",\n)\n\n\n1\n\nOmitir modelo de efectos fijos.\n\n2\n\nPersonalizar etiqueta del estimador de efecto.\n\n3\n\nMostrar solo el identificador de estudio en el panel izquierdo.\n\n4\n\nPersonalizar etiquetas del panel izquierdo.\n\n5\n\nPersonalizar etiquetas del panel derecho.\n\n6\n\nPersonalizar etiqueta indicadores de heterogeneidad.\n\n7\n\nPersonalizar etiqueta del estimador global.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportante\n\n\n\nLa funci√≥n metabin() tambi√©n permite estimar el riesgo relativo mediante el argumento sm = \"RR\", as√≠ como otros estimadores de efecto para variables binomiales, como la diferencia de riesgos (\"RD\"), la efectividad de vacunas (\"VE\"), entre otros. Dado que su implementaci√≥n es an√°loga a la utilizada para la raz√≥n de odds (\"OR\"), no se desarrollar√°n ejemplos espec√≠ficos para las mismas.\n\n\n\n\nRaz√≥n de tasas de incidencia\nLa raz√≥n de tasas de incidencia (incidence rate ratio o IRR) compara la frecuencia de eventos en dos grupos considerando el tiempo-persona de exposici√≥n:\n\\[\nIRR = \\frac{IR_e}{IR_c}\n\\]\ndonde:\n\n\\(IR_e\\) es la tasa de incidencia en el grupo expuesto/tratamiento.\n\\(IR_c\\) es la tasa de incidencia en el grupo no expuesto/control.\n\nAl igual que para la tasa de incidencia, se recomienda realizar la transformaci√≥n logar√≠tmica de los datos para aproximarlos a una distribuci√≥n normal.\nEn meta, la funci√≥n metainc() ajusta modelos de IRR con sm = \"IRR\", aplicando autom√°ticamente la transformaci√≥n logar√≠tmica.\nA modo de ejemplo, volveremos a usar la base datos_inc, esta vez comparando entre grupo de exposici√≥n y control.\nLas principales variables de inter√©s para este caso son:\n\nx1i: casos observados en grupo expuesto/tratamiento.\nt1i: a√±os-persona en grupo expuesto/tratamiento.\nx2i: casos observados en grupo no expuesto/control.\nt2i: a√±os-persona en grupo no expuesto/control.\nauthors: identificador de estudio.\n\nAjustamos el modelo de meta-an√°lisis para IRR aplicando la transformaci√≥n logar√≠tmica:\n\n# Ajusta modelo\nmod_irr &lt;- metainc(\n1  event.e = x1i,\n2  time.e = t1i,\n3  event.c = x2i,\n4  time.c = t2i,\n5  studlab = authors,\n6  data = datos_inc,\n7  sm = \"IRR\",\n8  prediction = TRUE\n  )\n\n\n1\n\nCasos observados en el grupo expuesto de cada estudio.\n\n2\n\nTiempo-persona en riesgo en el grupo expuesto de cada estudio.\n\n3\n\nCasos observados en el grupo no expuesto/control de cada estudio.\n\n4\n\nTiempo-persona en riesgo en el grupono expuesto/control de cada estudio.\n\n5\n\nIdentificador √∫nico del estudio.\n\n6\n\nConjunto de datos.\n\n7\n\nEstimador de efecto (\"IRR\" para raz√≥n de tasas de incidencia, ver ayuda de la funci√≥n para otras opciones).\n\n8\n\nCalcular intervalos de predicci√≥n (TRUE/FALSE por defecto).\n\n\n\n\nAnalicemos ahora la salida del modelo:\n\nmod_irr\n\nNumber of studies: k = 9\nNumber of events: e = 125\n\n                        IRR           95%-CI     z p-value\nCommon effect model  0.6602 [0.4608; 0.9459] -2.26  0.0236\nRandom effects model 0.6728 [0.4314; 1.0494] -1.75  0.0806\nPrediction interval         [0.2796; 1.6192]              \n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.0936 [0.0000; 1.4845]; tau = 0.3060 [0.0000; 1.2184]\n I^2 = 17.5% [0.0%; 59.5%]; H = 1.10 [1.00; 1.57]\n\nTest of heterogeneity:\n    Q d.f. p-value\n 9.70    8  0.2869\n\nDetails of meta-analysis methods:\n- Mantel-Haenszel method (common effect model)\n- Inverse variance method (random effects model)\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n- Prediction interval based on t-distribution (df = 8)\n\n\nEl valor de \\(I^2\\) indica que los datos presentan una heterogeneidad baja y puede conservarse el modelo de efectos fijos.\nLos coeficientes del modelo de efectos fijos muestran una disminuci√≥n estad√≠sticamente significativa del riesgo en el grupo tratado \\((p = 0,24)\\), pero la misma deja de ser significativa en el de efectos aleatorios \\((p = 0,81)\\). El intervalo de predicci√≥n muestra que futuros estudios pueden detectar un efecto inverso al estimado.\nGeneramos el forest plot para visualizar los resultados, usando los argumentos col.diamond.random y col.diamond.common para mostrar en diferentes colores los estimadores globales del modelo de efectos fijos y el modelo de efectos aleatorios:\n\nforest(\n  mod_irr,\n1  col.diamond.random = pal[1],\n2  col.diamond.common = pal[2],\n  col.square = pal[3],          \n3  smlab = \"Raz√≥n de tasas de incidencia\",\n4  leftcols = \"studlab\",\n5  leftlabs = \"Estudio\",\n  rightlabs = c(\"IRR\", \"95% IC\", \n6                \"Peso (fijo)\", \"Peso (aleatorio)\"),\n7  hetlab = \"Heterogeneidad: \",\n8  text.random = \"Modelo de efectos aleatorios\",\n9  text.common = \"Modelo de efectos fijos\"\n)\n\n\n1\n\nColor para el s√≠mbolo del estimador de efecto global del modelo de efectos aleatorios.\n\n2\n\nColor para el s√≠mbolo del estimador de efecto global del modelo de efectos fijos.\n\n3\n\nPersonalizar etiqueta del estimador de efecto.\n\n4\n\nMostrar solo el identificador de estudio en el panel izquierdo.\n\n5\n\nPersonalizar etiquetas del panel izquierdo.\n\n6\n\nPersonalizar etiquetas del panel derecho.\n\n7\n\nPersonalizar etiqueta indicadores de heterogeneidad.\n\n8\n\nPersonalizar etiqueta del estimador global para el modelo de efectos aleatorios.\n\n9\n\nPersonalizar etiqueta del estimador global para el modelo de efectos fijos.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNota\n\n\n\n\nDebido a la extensi√≥n del curso, nos enfocaremos exclusivamente en la implementaci√≥n en R de los modelos para cada medida de asociaci√≥n. Quienes deseen profundizar en el desarrollo matem√°tico de estos modelos pueden consultar los cap√≠tulos 3 y 4.2 de Harrer et¬†al. (2021).\nActualmente, el paquete meta no incluye funciones espec√≠ficas para modelar el tiempo hasta el evento (hazard ratio, HR). Sin embargo, si los estudios reportan el log-HR y su error est√°ndar, es posible utilizar la funci√≥n metagen() con el argumento sm = \"HR\" para obtener una estimaci√≥n combinada del efecto. Para una explicaci√≥n detallada del proceso, pueden consultar el cap√≠tulo 2.6.1 de Schwarzer, Carpenter, y R√ºcker (2015).",
    "crumbs": [
      "Introducci√≥n a la Revisi√≥n Sistem√°tica con Meta-an√°lisis",
      "Meta-an√°lisis",
      "Estimadores de efecto"
    ]
  },
  {
    "objectID": "unidad_2/01_intro.html",
    "href": "unidad_2/01_intro.html",
    "title": "Introducci√≥n",
    "section": "",
    "text": "El meta-an√°lisis es una herramienta estad√≠stica que permite sintetizar cuantitativamente la evidencia proveniente de investigaciones independientes que abordan un mismo problema de investigaci√≥n. Se lo ha definido como un ‚Äúan√°lisis de an√°lisis‚Äù (Glass 1976), ya que su unidad de an√°lisis no son individuos ni poblaciones, sino estudios cient√≠ficos.\nSu objetivo principal es proporcionar un estimador num√©rico que resuma los resultados de los estudios incluidos, lo que permite evaluar la magnitud del efecto de una intervenci√≥n o la relaci√≥n entre variables en distintos contextos (Harrer et¬†al. 2021). Es importante destacar que los meta-an√°lisis son adecuados exclusivamente para investigaciones cuantitativas y, en general, requieren que los estudios analizados compartan un dise√±o similar y estimen medidas de asociaci√≥n comparables.\nA continuaci√≥n, se resumen algunas de las principales ventajas y limitaciones del meta-an√°lisis:\n\n\n\n\nVentajas\nDesventajas\n\n\n\nPermite una s√≠ntesis cuantitativa de la evidencia disponible.\nLa validez de los resultados depende de la calidad metodol√≥gica de los estudios incluidos.\n\n\nAumenta la potencia estad√≠stica al combinar los datos de m√∫ltiples estudios.\nPuede estar afectado por sesgos de publicaci√≥n.\n\n\nMejora la precisi√≥n de los estimadores al reducir la variabilidad aleatoria.\nLa heterogeneidad entre estudios puede dificultar la interpretaci√≥n de los resultados.\n\n\nPermite identificar patrones no evidentes en estudios individuales.\nRequiere una metodolog√≠a rigurosa y criterios estrictos de selecci√≥n de estudios.\n\n\nEval√∫a la consistencia de los resultados en diferentes poblaciones y contextos.\nNo corrige errores metodol√≥gicos de los estudios primarios.",
    "crumbs": [
      "Introducci√≥n a la Revisi√≥n Sistem√°tica con Meta-an√°lisis",
      "Meta-an√°lisis",
      "Introducci√≥n"
    ]
  },
  {
    "objectID": "unidad_2/01_intro.html#qu√©-es-un-meta-an√°lisis",
    "href": "unidad_2/01_intro.html#qu√©-es-un-meta-an√°lisis",
    "title": "Introducci√≥n",
    "section": "",
    "text": "El meta-an√°lisis es una herramienta estad√≠stica que permite sintetizar cuantitativamente la evidencia proveniente de investigaciones independientes que abordan un mismo problema de investigaci√≥n. Se lo ha definido como un ‚Äúan√°lisis de an√°lisis‚Äù (Glass 1976), ya que su unidad de an√°lisis no son individuos ni poblaciones, sino estudios cient√≠ficos.\nSu objetivo principal es proporcionar un estimador num√©rico que resuma los resultados de los estudios incluidos, lo que permite evaluar la magnitud del efecto de una intervenci√≥n o la relaci√≥n entre variables en distintos contextos (Harrer et¬†al. 2021). Es importante destacar que los meta-an√°lisis son adecuados exclusivamente para investigaciones cuantitativas y, en general, requieren que los estudios analizados compartan un dise√±o similar y estimen medidas de asociaci√≥n comparables.\nA continuaci√≥n, se resumen algunas de las principales ventajas y limitaciones del meta-an√°lisis:\n\n\n\n\nVentajas\nDesventajas\n\n\n\nPermite una s√≠ntesis cuantitativa de la evidencia disponible.\nLa validez de los resultados depende de la calidad metodol√≥gica de los estudios incluidos.\n\n\nAumenta la potencia estad√≠stica al combinar los datos de m√∫ltiples estudios.\nPuede estar afectado por sesgos de publicaci√≥n.\n\n\nMejora la precisi√≥n de los estimadores al reducir la variabilidad aleatoria.\nLa heterogeneidad entre estudios puede dificultar la interpretaci√≥n de los resultados.\n\n\nPermite identificar patrones no evidentes en estudios individuales.\nRequiere una metodolog√≠a rigurosa y criterios estrictos de selecci√≥n de estudios.\n\n\nEval√∫a la consistencia de los resultados en diferentes poblaciones y contextos.\nNo corrige errores metodol√≥gicos de los estudios primarios.",
    "crumbs": [
      "Introducci√≥n a la Revisi√≥n Sistem√°tica con Meta-an√°lisis",
      "Meta-an√°lisis",
      "Introducci√≥n"
    ]
  },
  {
    "objectID": "unidad_2/01_intro.html#estimadores-de-efecto",
    "href": "unidad_2/01_intro.html#estimadores-de-efecto",
    "title": "Introducci√≥n",
    "section": "Estimadores de efecto",
    "text": "Estimadores de efecto\nEn estudios individuales, suele asumirse que las variables de inter√©s fueron medidas de manera uniforme en todos los participantes. Esto permite aplicar t√©cnicas de estad√≠stica descriptiva, como el an√°lisis exploratorio de datos (EDA), para caracterizar la muestra, explorar relaciones entre variables y ajustar modelos de regresi√≥n acordes a la estructura de los datos.\nSin embargo, en los meta-an√°lisis esta suposici√≥n rara vez se cumple. A√∫n cuando los criterios de inclusi√≥n sean estrictos, los estudios pueden diferir en su dise√±o, poblaci√≥n, medici√≥n de variables o definici√≥n de resultados. Por esta raz√≥n, no es posible sintetizar la evidencia con herramientas de la estad√≠stica tradicional.\nPara integrar los resultados de diferentes estudios, los meta-an√°lisis utilizan estimadores de efecto (Page et¬†al. 2021), tambi√©n conocidos como effect size o tama√±o del efecto (Harrer et¬†al. 2021)1. En algunos casos, estos valores pueden extraerse directamente de los art√≠culos; sin embargo, a menudo es necesario calcularlos a partir de los datos reportados.\nUn buen estimador de efecto debe cumplir con las siguientes condiciones:\n\nComparable: debe ser consistente entre los estudios incluidos.\nComputable: debe poder calcularse a partir de la informaci√≥n disponible.\nConfiable: debe permitir la estimaci√≥n de su error est√°ndar.\nInterpretable: debe responder de manera clara a la pregunta de investigaci√≥n.\n\nDesde una perspectiva estad√≠stica, los estimadores de efecto son an√°logos a los coeficientes en modelos de regresi√≥n o a las medidas de asociaci√≥n en estudios epidemiol√≥gicos, ya que cuantifican la fuerza y direcci√≥n de la relaci√≥n entre dos variables.\nEntre los estimadores de efecto m√°s utilizados en investigaci√≥n epidemiol√≥gica y aplicables a modelos de meta-an√°lisis se encuentran: proporciones, tasas de incidencia, coeficientes de correlaci√≥n, diferencias de medias, odds ratio (OR), riesgos relativos (RR) y hazard ratio.\nEn la pr√≥xima secci√≥n describiremos la estructura de los modelos de meta-an√°lisis de efectos fijos y de efectos aleatorios. Luego, exploraremos c√≥mo se ajustan estos modelos seg√∫n cada tipo de estimador epidemiol√≥gico y con su implementaci√≥n pr√°ctica en R.",
    "crumbs": [
      "Introducci√≥n a la Revisi√≥n Sistem√°tica con Meta-an√°lisis",
      "Meta-an√°lisis",
      "Introducci√≥n"
    ]
  },
  {
    "objectID": "unidad_2/01_intro.html#footnotes",
    "href": "unidad_2/01_intro.html#footnotes",
    "title": "Introducci√≥n",
    "section": "Notas",
    "text": "Notas\n\nSi bien ambos t√©rminos son equivalentes, usaremos la denominaci√≥n ‚Äúestimador de efecto‚Äù presente en las normas PRISMA para evitar confusiones con los effect size calculados en los modelos de regresi√≥n tradicionales, que eval√∫an la magnitud del efecto de una variable independiente.‚Ü©Ô∏é",
    "crumbs": [
      "Introducci√≥n a la Revisi√≥n Sistem√°tica con Meta-an√°lisis",
      "Meta-an√°lisis",
      "Introducci√≥n"
    ]
  },
  {
    "objectID": "extras/intro_R.html",
    "href": "extras/intro_R.html",
    "title": "Introducci√≥n a R y RStudio",
    "section": "",
    "text": "Artwork por @allison_horst",
    "crumbs": [
      "Introducci√≥n a la Revisi√≥n Sistem√°tica con Meta-an√°lisis",
      "Material Introductorio",
      "Introducci√≥n a R y RStudio"
    ]
  },
  {
    "objectID": "extras/intro_R.html#qu√©-es-r",
    "href": "extras/intro_R.html#qu√©-es-r",
    "title": "Introducci√≥n a R y RStudio",
    "section": "¬øQu√© es R?",
    "text": "¬øQu√© es R?\nR (2025) es un lenguaje de programaci√≥n interpretado, orientado a objetos, multiplataforma y de c√≥digo abierto, dise√±ado espec√≠ficamente para el an√°lisis estad√≠stico de datos. Cuenta con estructuras y sintaxis propias, y una extensa colecci√≥n de funciones desarrolladas para aplicaciones estad√≠sticas.\n\nComo lenguaje orientado a objetos, todo lo que manipulamos ‚Äîvariables, funciones, conjuntos de datos, resultados‚Äî se considera un objeto, lo que aporta flexibilidad y simplicidad al trabajo con informaci√≥n.\nAl ser un lenguaje interpretado, los scripts se ejecutan directamente sin necesidad de compilaci√≥n, lo que favorece la exploraci√≥n interactiva.\nR es multiplataforma: se puede instalar y ejecutar en Linux, Windows y macOS con un comportamiento consistente.\nAdem√°s, es software libre distribuido bajo licencia GNU-GPL, lo que permite su uso, modificaci√≥n y redistribuci√≥n sin restricciones.\n\nPara instalarlo en Windows, se debe descargar el instalador desde el sitio oficial del proyecto R (CRAN) y seguir los pasos guiados. Una vez finalizada la instalaci√≥n, R estar√° listo para usarse desde cualquier entorno compatible. Sin embargo, si no se cuenta con experiencia previa en programaci√≥n, no se recomienda utilizar R directamente desde su consola nativa.",
    "crumbs": [
      "Introducci√≥n a la Revisi√≥n Sistem√°tica con Meta-an√°lisis",
      "Material Introductorio",
      "Introducci√≥n a R y RStudio"
    ]
  },
  {
    "objectID": "extras/intro_R.html#qu√©-es-rstudio",
    "href": "extras/intro_R.html#qu√©-es-rstudio",
    "title": "Introducci√≥n a R y RStudio",
    "section": "¬øQu√© es RStudio?",
    "text": "¬øQu√© es RStudio?\nRStudio Desktop (2025, Posit Software) es un entorno de desarrollo integrado (IDE) dise√±ado espec√≠ficamente para facilitar el trabajo con R. Proporciona una interfaz unificada que incluye editor de scripts, consola de R, entorno, explorador de archivos, panel de gr√°ficos y ayuda, entre otros, optimizando el flujo de trabajo.\n\n\n\n\nEntre sus principales ventajas se encuentran:\n\n\nAsistente de c√≥digo: al escribir en el editor o la consola, la tecla Tab activa el autocompletado de funciones, nombres de objetos y argumentos, agilizando la escritura y reduciendo errores de sintaxis. En versiones recientes, el asistente tambi√©n permite la previsualizaci√≥n de colores en los gr√°ficos, resaltar los par√©ntesis de cierre en funciones anidadas con distintos colores y gestionar autom√°ticamente la indentaci√≥n del c√≥digo.\n\n\n\nAyuda en l√≠nea: al posicionar el cursor sobre el nombre de una funci√≥n en el editor y presionar F1, se accede directamente a la documentaci√≥n correspondiente en el panel Help (habitualmente ubicado en la esquina inferior derecha).\n\n\n\nHistorial de comandos: en la consola, al usar las teclas de flecha arriba/abajo, se puede navegar por los comandos ejecutados durante la sesi√≥n actual. Adem√°s, el panel History (parte superior derecha) almacena los comandos de todas las sesiones previas, permitiendo reutilizarlos con un clic en To Console (Enter) o To Source (Shift + Enter), seg√∫n se desee insertarlos en la consola o en el script activo.\n\n\n\nRStudio es multiplataforma, de c√≥digo abierto, y permite una integraci√≥n fluida con herramientas del ecosistema R, como R Markdown, Quarto, control de versiones y manejo de proyectos.\n\n\n\n\n\n\nUna vez instalados R y RStudio, ya contamos con todo lo necesario para comenzar a trabajar. Aunque instalamos ambos programas, en la pr√°ctica s√≥lo necesitamos abrir RStudio, que utiliza a R como motor de ejecuci√≥n.\n\n\n\nProyectos en RStudio\nLos proyectos de RStudio permiten organizar de forma estructurada todo el material asociado a un an√°lisis: scripts, informes, bases de datos, im√°genes, etc. Cada proyecto se vincula a una carpeta espec√≠fica del sistema de archivos, y RStudio la utiliza como directorio de trabajo por defecto. Esto facilita la importaci√≥n de datos y evita errores relacionados con rutas relativas o absolutas.\nPara crear un nuevo proyecto, se puede utilizar el men√∫ File &gt; New Project‚Ä¶ o el acceso directo New Project‚Ä¶ ubicado en la esquina superior derecha de la interfaz. En ambos casos, se abre un asistente con tres opciones:\n\n\n\n\n\nNew Directory: crea una nueva carpeta para el proyecto. Es la opci√≥n m√°s habitual.\nExisting Directory: vincula el proyecto a una carpeta ya existente que contenga archivos previos.\nVersion Control: permite clonar un repositorio (Git o SVN). Esta opci√≥n no se utilizar√° en este curso.\n\nTrabajar con proyectos garantiza que, al importar archivos, RStudio los busque autom√°ticamente dentro de la carpeta correspondiente. Adem√°s, cada proyecto mantiene su propio entorno de trabajo, lo que significa que al cerrar o cambiar de proyecto, se conserva la configuraci√≥n previa sin interferencias.\nCuando un proyecto ya existe, dentro de la carpeta encontraremos un archivo con extensi√≥n .Rproj que al ejecutarlo abre una nueva sesi√≥n de RStudio con el proyecto activo. Otras opciones son abrir desde File &gt; Open Project‚Ä¶ o desde el √≠cono  en la esquina superior derecha de RStudio. Esta √∫ltima opci√≥n tambi√©n mantiene un historial de los proyectos abiertos recientemente, lo que permite acceder r√°pidamente a ellos mediante accesos directos.\nScripts en RStudio\nUn script es un archivo de texto plano que contiene instrucciones escritas en R. Permite guardar, reutilizar y compartir el c√≥digo, favoreciendo la reproducibilidad del an√°lisis.\n\nCrear un nuevo script: podemos crear un script desde el men√∫ File &gt; New File &gt; R Script (acceso r√°pido: Ctrl + Shift + N) o haciendo clic en el √≠cono de la hoja (üìÑ) con s√≠mbolo ‚Äú+‚Äù en la barra de herramientas.\nEjecutar c√≥digo: la forma habitual de ejecutar un script es l√≠nea por l√≠nea, con Ctrl + Enter o el bot√≥n Run (). El cursor debe estar en cualquier punto de la l√≠nea a ejecutar. Tras la ejecuci√≥n, el cursor avanza autom√°ticamente a la siguiente l√≠nea de c√≥digo.\nEditar un script: las l√≠neas del script pueden editarse directamente. Cada vez que se realiza una modificaci√≥n, es necesario volver a ejecutar esas l√≠neas para actualizar los resultados.\nGuardar un script: Para guardar los cambios, se puede usar el √≠cono del diskette (üíæ), el men√∫ File &gt; Save, o el atajo Ctrl + S. Para guardar con otro nombre o ubicaci√≥n, utilizar File &gt; Save As‚Ä¶\nAbrir un script existente: Los archivos de script tienen extensi√≥n .R. Pueden abrirse desde el panel File &gt; Open File‚Ä¶, el panel Files o usando el atajo de teclado Ctrl + O. Al abrirse, se muestran en una nueva pesta√±a del editor.",
    "crumbs": [
      "Introducci√≥n a la Revisi√≥n Sistem√°tica con Meta-an√°lisis",
      "Material Introductorio",
      "Introducci√≥n a R y RStudio"
    ]
  },
  {
    "objectID": "extras/intro_R.html#funciones",
    "href": "extras/intro_R.html#funciones",
    "title": "Introducci√≥n a R y RStudio",
    "section": "Funciones",
    "text": "Funciones\nEn R, los comandos b√°sicos se denominan funciones. Muchas de ellas est√°n incluidas en el n√∫cleo del lenguaje (conocido como R base) y se denominan integradas, mientras que otras forman parte de paquetes adicionales.\nCada funci√≥n tiene un nombre y suele requerir uno o m√°s argumentos (tambi√©n llamados par√°metros), que se escriben entre par√©ntesis y separados por comas. Incluso las funciones que no requieren argumentos deben escribirse con par√©ntesis vac√≠os.\n\n# Sintaxis general\nnombre_de_la_funci√≥n(arg1, arg2, ...)\n\nLas funciones siempre ejecutan una acci√≥n o devuelven un valor, que puede ser visualizado, almacenado o utilizado en otras operaciones.\nReglas de sintaxis\nDado que R es un lenguaje interpretado, la sintaxis debe ser estrictamente correcta. Algunos puntos clave:\n\n\nLos argumentos pueden escribirse con el nombre del par√°metro seguido de un signo igual:\n\nfuncion(arg1 = 32, arg2 = 5, arg3 = 65)\n\n\n\nTambi√©n se pueden omitir los nombres y escribir directamente los valores. En ese caso, el orden importa y debe coincidir con el definido en la documentaci√≥n de la funci√≥n:\n\nfuncion(32, 5, 65)\n\n\nTipos de argumentos\nLos argumentos pueden ser:\n\nValores num√©ricos: 3, 10.5\nL√≥gicos: TRUE, FALSE\nEspeciales: NA (faltante), NULL, Inf\nTexto: debe escribirse entre comillas, por ejemplo \"menos\"\n\nObjetos: como variables previamente creadas (x, datos, etc.)\n\nfuncion(arg1 = 3, arg2 = NA, arg3 = TRUE, arg4 = \"menos\", arg5 = x)",
    "crumbs": [
      "Introducci√≥n a la Revisi√≥n Sistem√°tica con Meta-an√°lisis",
      "Material Introductorio",
      "Introducci√≥n a R y RStudio"
    ]
  },
  {
    "objectID": "extras/intro_R.html#paquetes",
    "href": "extras/intro_R.html#paquetes",
    "title": "Introducci√≥n a R y RStudio",
    "section": "Paquetes",
    "text": "Paquetes\nR se compone de un sistema base y de paquetes (librer√≠as) que ampl√≠an sus funcionalidades. Un paquete es una colecci√≥n de funciones, datos y documentaci√≥n que extiende las capacidades del lenguaje para tareas espec√≠ficas.\nExisten distintos tipos de paquetes:\n\nBase: se instalan y activan junto con R.\nRecomendados: tambi√©n se instalan por defecto, pero requieren ser cargados manualmente.\nAdicionales: m√°s de 17.000 disponibles en el repositorio oficial CRAN, listos para ser instalados seg√∫n necesidad. Adem√°s, algunos paquetes pueden descargarse desde otros repositorios como GitHub y Bioconductor.\n\nAl ser open source, cualquier persona puede desarrollar y publicar nuevos paquetes. Esto convierte a R en una herramienta en constante evoluci√≥n.\nInstalaci√≥n\nLos paquetes pueden instalarse desde R o RStudio o (si no hay acceso a internet o trabajamos con conexiones de uso medido) desde archivos locales .zip o .tar.gz, descargados previamente desde CRAN u otros repositorios.\nEn RStudio, los paquetes se gestionan desde la pesta√±a Packages (bloque inferior derecho). Para instalar uno nuevo:\n\nHacer clic en , se abrir√° una ventana emergente:\n\n\n\n\n\n\nEspecificar el nombre del paquete a instalar.\nMarcar la opci√≥n Install dependencies para incluir autom√°ticamente sus dependencias.\nAl presionar el bot√≥n Install, R internamente traduce esta acci√≥n a la funci√≥n install.packages().\n\nLos paquetes deben instalarse una √∫nica vez por computadora cuando se los va a utilizar por primera vez. A partir de entonces, s√≥lo es necesario cargarlos al inicio de cada sesi√≥n mediante la funci√≥n library():\n\nlibrary(nombre_del_paquete)\n\nDependencias\nMuchos paquetes requieren funciones de otros paquetes para funcionar. Estos paquetes (dependencias) deben estar instaladas previamente, de lo contrario la ejecuci√≥n de una funci√≥n puede fallar por no encontrar otra interna. Por eso, es recomendable dejar seleccionada la opci√≥n Install dependencies al instalar.\nPaquetes a instalar\nPara trabajar durante el curso, deberemos instalar los siguientes paquetes y sus dependencias:\n\n# Manejo de datos\ninstall.packages(\"tidyverse\", dependencies = T)\n\ninstall.packages(\"janitor\", dependencies = T)\n\n# Modelos de meta-an√°lisis\ninstall.packages(\"metafor\", dependencies = T)\n\ninstall.packages(\"meta\", dependencies = T)\n\n# Paletas aptas para daltonismo\ninstall.packages(\"scico\", dependencies = T)\n\n# Visualizaci√≥n avanzada\nremotes::install_github(\"daniel1noble/orchaRd\")",
    "crumbs": [
      "Introducci√≥n a la Revisi√≥n Sistem√°tica con Meta-an√°lisis",
      "Material Introductorio",
      "Introducci√≥n a R y RStudio"
    ]
  },
  {
    "objectID": "extras/intro_R.html#objetos",
    "href": "extras/intro_R.html#objetos",
    "title": "Introducci√≥n a R y RStudio",
    "section": "Objetos",
    "text": "Objetos\nEn R, los datos, resultados, funciones y estructuras se almacenan en objetos, que constituyen la unidad fundamental de trabajo en el lenguaje.\nPara crear un objeto, se utiliza el operador de asignaci√≥n &lt;- (tambi√©n se acepta = aunque no se recomienda) para asignar un valor a un nombre:\n\nx &lt;- 10 \n\nEn este ejemplo, el n√∫mero 10 se asigna al objeto llamado x. A partir de ese momento, podemos utilizar x en otras operaciones:\n\nx + 5  # devuelve 15\n\nLos nombres de objetos:\n\nDeben comenzar con una letra y pueden incluir letras, n√∫meros, puntos (.) y guiones bajos (_).\nNo deben coincidir con palabras reservadas a funciones del lenguaje.\nSon sensibles a may√∫sculas/min√∫sculas: Edad y edad son objetos distintos.\n\nLos objetos contenedores de datos m√°s simples pertenecen a cinco clases que se denominan at√≥micas y que son los siguientes tipos de datos:\n\ninteger: n√∫meros enteros.\nnumeric: n√∫meros reales (tambi√©n llamados ‚Äúdoble precisi√≥n‚Äù).\ncomplex: n√∫meros complejos.\ncharacter: cadenas de texto o caracteres.\n\nlogical: valores l√≥gicos (TRUE o FALSE).\n\nn√∫mero &lt;- 25           # entero\ndecimal &lt;- 3.14        # num√©rico\ntexto &lt;- \"Hola\"        # car√°cter\nlogico &lt;- TRUE         # l√≥gico (booleano)\n\n\n\nAdem√°s de los tipos at√≥micos, los datos pueden organizarse en estructuras contenedoras que permiten agrupar m√∫ltiples valores:\n\nVector: conjunto de elementos del mismo tipo, ordenados linealmente. Se construye con la funci√≥n c().\nLista: colecci√≥n ordenada de objetos de distinto tipo o longitud, creada con list().\n\nDataframe: estructura bidimensional donde cada columna es un vector del mismo largo (generalmente del mismo tipo). Se construye con data.frame() o, en el tidyverse, con tibble().\n\n# Vector\nvector  &lt;- c(1, 2, 3, 4)\n\n# Lista\nlista &lt;- list(vector, \"elemento_2\") # lista\n\n# Dataframe (R base)\ndataframe &lt;- data.frame(\n  var1 = vector,\n  var2 = vector + 5,\n  var3 = vector * vector^2\n)\n\n# Dataframe (tidyverse)\ntibble &lt;- tibble(\n  var1 = vector,\n  var2 = vector + 5,\n  var3 = vector * vector^2\n)",
    "crumbs": [
      "Introducci√≥n a la Revisi√≥n Sistem√°tica con Meta-an√°lisis",
      "Material Introductorio",
      "Introducci√≥n a R y RStudio"
    ]
  },
  {
    "objectID": "extras/intro_R.html#archivos-de-datos",
    "href": "extras/intro_R.html#archivos-de-datos",
    "title": "Introducci√≥n a R y RStudio",
    "section": "Archivos de datos",
    "text": "Archivos de datos\nR permite importar tablas de datos desde diversos formatos, tanto utilizando funciones de R base como funciones provistas por paquetes espec√≠ficos.\nEl formato m√°s com√∫n es el texto plano (ASCII), donde los valores est√°n organizados en columnas separadas por caracteres delimitadores. Los separadores m√°s habituales incluyen:\n\nComa (,)\nPunto y coma (;)\nTabulaci√≥n (\\t)\nBarra vertical (|)\n\nEstos archivos suelen tener una cabecera (header) en la primera fila con los nombres de las variables, y cada columna debe contener datos del mismo tipo (n√∫meros, texto, l√≥gicos, etc.).\nPara importar correctamente un archivo es importante conocer su estructura:\n\nSi incluye o no cabecera.\nQu√© car√°cter se usa como separador.\nEl tipo de codificaci√≥n (UTF-8, Latin1, etc.).\n\nDado que son archivos de texto, pueden visualizarse con editores simples como el Bloc de Notas o desde RStudio, lo que facilita su inspecci√≥n previa.\nPara cargar los datos desde un archivo de texto plano o una hoja de c√°lculo de Excel usamos el c√≥digo:\n\ndatos &lt;- read.xxx(\"mis_datos.txt\")\n\n(Se debe reemplazar read.xxx() por la funci√≥n correspondiente: read.table(), read.csv(), read_delim(), read_excel(), etc., seg√∫n el caso).\nR tambi√©n permite cargar bases de datos incluidas en paquetes instalados mediante:\n\ndata(nombre_datos)\n\ndatos &lt;- nombre_datos",
    "crumbs": [
      "Introducci√≥n a la Revisi√≥n Sistem√°tica con Meta-an√°lisis",
      "Material Introductorio",
      "Introducci√≥n a R y RStudio"
    ]
  },
  {
    "objectID": "extras/intro_R.html#buenas-pr√°cticas",
    "href": "extras/intro_R.html#buenas-pr√°cticas",
    "title": "Introducci√≥n a R y RStudio",
    "section": "Buenas pr√°cticas",
    "text": "Buenas pr√°cticas\nAdoptar buenas pr√°cticas desde el inicio mejora la reproducibilidad, facilita el trabajo colaborativo y reduce errores. Algunas recomendaciones clave son:\n\nTrabajar siempre dentro de un proyecto de RStudio (.Rproj). Esto permite organizar los archivos, mantener rutas relativas consistentes y acceder a funcionalidades espec√≠ficas como control de versiones o panel de archivos integrados.\nIncluir al comienzo de cada script las l√≠neas de activaci√≥n de paquetes necesarios, utilizando la funci√≥n library().\nCargar los datos una vez activados los paquetes, para garantizar que todas las funciones requeridas est√©n disponibles.\nDocumentar el c√≥digo mediante comentarios iniciados con #. Esto permite entender qu√© hace cada bloque de c√≥digo, facilitando futuras modificaciones o revisiones.\nUsar espacios e indentaci√≥n adecuada para mejorar la legibilidad. Esto es especialmente importante en estructuras anidadas (como condicionales, bucles o funciones).\n\nUna gu√≠a de estilo ampliamente recomendada ‚Äîaunque no oficial‚Äî es la de tidyverse. Incluye ejemplos concretos de buenas y malas pr√°cticas para nombrar variables, manejar l√≠neas largas, usar sangr√≠as, entre otros aspectos. Puede consultarse en: https://style.tidyverse.org/\n\n\n\n\n\n\nImportante\n\n\n\nEste apunte ofrece un resumen general para quienes deseen repasar los aspectos b√°sicos de R y RStudio.\nSi no cuentan con experiencia previa en R y necesitan una introducci√≥n m√°s detallada, pod√©s consultar los siguientes recursos:\n\nCurso de Epidemiolog√≠a Nivel Avanzado - Unidad 1: Introducci√≥n a R\nEpiR Handbook ‚Äì secciones Aspectos b√°sicos y Gesti√≥n de datos.\n\nAnte cualquier duda espec√≠fica, recuerden que pueden comunicarse con los/as docentes del curso.",
    "crumbs": [
      "Introducci√≥n a la Revisi√≥n Sistem√°tica con Meta-an√°lisis",
      "Material Introductorio",
      "Introducci√≥n a R y RStudio"
    ]
  },
  {
    "objectID": "extras/intro_inferencia.html",
    "href": "extras/intro_inferencia.html",
    "title": "Introducci√≥n a la inferencia estad√≠stica",
    "section": "",
    "text": "Artwork por @allison_horst",
    "crumbs": [
      "Introducci√≥n a la Revisi√≥n Sistem√°tica con Meta-an√°lisis",
      "Material Introductorio",
      "Introducci√≥n a la inferencia estad√≠stica"
    ]
  },
  {
    "objectID": "extras/intro_inferencia.html#fundamentos",
    "href": "extras/intro_inferencia.html#fundamentos",
    "title": "Introducci√≥n a la inferencia estad√≠stica",
    "section": "Fundamentos",
    "text": "Fundamentos\nLa estad√≠stica inferencial es la rama de la estad√≠stica que permite extraer conclusiones sobre una poblaci√≥n a partir de una muestra de datos. Este proceso se sustenta en dos procedimientos principales: la estimaci√≥n y la prueba de hip√≥tesis.\nLa poblaci√≥n se define como el conjunto completo de individuos u observaciones de inter√©s, mientras que la muestra es el subconjunto representativo de esa poblaci√≥n, dise√±ado para reflejar sus caracter√≠sticas fundamentales. Para describir la poblaci√≥n se utilizan par√°metros, valores num√©ricos como la media poblacional \\((\\mu)\\), mientras que los datos muestrales se resumen con estad√≠sticos, por ejemplo, la media muestral \\((\\bar{x})\\).",
    "crumbs": [
      "Introducci√≥n a la Revisi√≥n Sistem√°tica con Meta-an√°lisis",
      "Material Introductorio",
      "Introducci√≥n a la inferencia estad√≠stica"
    ]
  },
  {
    "objectID": "extras/intro_inferencia.html#estimaci√≥n-de-par√°metros",
    "href": "extras/intro_inferencia.html#estimaci√≥n-de-par√°metros",
    "title": "Introducci√≥n a la inferencia estad√≠stica",
    "section": "Estimaci√≥n de par√°metros",
    "text": "Estimaci√≥n de par√°metros\nLa estimaci√≥n consiste en utilizar informaci√≥n muestral para inferir el valor de un par√°metro poblacional. Existen dos tipos principales:\n\nEstimaci√≥n puntual: proporciona un √∫nico valor estimado. Por ejemplo, la media muestral (\\(\\bar{x}\\)) como estimador de la media poblacional (\\(\\mu\\)).\nEstimaci√≥n por intervalo de confianza: proporciona un rango de valores plausibles para el par√°metro, con un nivel de confianza determinado.\n\nIntervalos de confianza\nAunque los intervalos de confianza son procedimientos inferenciales, est√°n estrechamente ligados a la estad√≠stica descriptiva. Un intervalo de confianza indica un rango de valores dentro del cual se espera que se ubique el verdadero valor del par√°metro poblacional, con una cierta probabilidad conocida como nivel de confianza.\nLa forma general de un IC es:\n\\[ IC = estimador~puntual \\pm (coeficiente~de~confiabilidad) * (error~ estandar) \\]\nEstimador puntual\n\nPara la media poblacional (\\(\\mu\\)): se utiliza la media muestral \\(\\bar{x}\\).\nPara una proporci√≥n poblacional (\\(p\\)): se utiliza la proporci√≥n muestral \\(\\hat{p}\\).\nCoeficiente de confiabilidad\nCorresponde al valor asociado al nivel de confianza deseado (por ejemplo, 90%, 95%, 99%). Se denota como \\(1 - \\alpha\\), siendo \\(\\alpha\\) el nivel de significaci√≥n (probabilidad de error tipo I). Por ejemplo, para un 95% de confianza, \\(\\alpha = 0.05\\) y el coeficiente es \\(Z_{1 - \\alpha/2} \\approx 1.96\\).\nError est√°ndar (SE)\nRepresenta la variabilidad de la distribuci√≥n muestral y depende del par√°metro.\nPor ejemplo, para la media se calcula:\n\\[\nSE = \\frac{\\sigma}{\\sqrt{n}}\n\\]\nDonde \\(\\sigma\\) es la desviaci√≥n est√°ndar poblacional y \\(n\\) el tama√±o de la muestra.\nMientras que para una proporci√≥n se calcula como:\n\\[\nSE = \\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n}}\n\\]\nTeorema del l√≠mite central\nEl Teorema del L√≠mite Central (TLC) establece que, para muestras suficientemente grandes, la distribuci√≥n muestral de la media (\\(\\bar{x}\\)) es aproximadamente normal, con media \\(\\mu\\) y varianza \\(\\sigma^2/n\\). Esto permite utilizar la distribuci√≥n normal est√°ndar para calcular probabilidades e intervalos:\n\\[\nZ = \\frac{\\bar{x}-\\mu}{\\sigma}\n\\]\nDado esto, se sabe que en una distribuci√≥n normal:\n\nAproximadamente el 68% de los valores se encuentran entre \\(\\mu \\pm \\sigma\\).\nAproximadamente el 95% entre \\(\\mu \\pm 2\\sigma\\).\nAproximadamente el 99% entre \\(\\mu \\pm 3\\sigma\\).\n\nEl siguiente gr√°fico ilustra lo explicado anteriormente:\n\n\n\n\n\n\n\n\nUn IC al 95% no significa que haya un 95% de probabilidad de que el par√°metro est√© dentro de un √∫nico intervalo calculado. Lo correcto es decir que, si repiti√©ramos muchas veces el procedimiento muestral, el 95% de los intervalos construidos de esa forma contendr√≠an el verdadero valor del par√°metro.\n¬øC√≥mo se interpreta un IC?\nSi repiti√©ramos el muestreo muchas veces, tomando muestras del mismo tama√±o y construyendo un IC en cada caso, aproximadamente el \\(100 * (1 ‚àí \\alpha)\\%\\) de esos intervalos contendr√≠an el valor real del par√°metro. Por ejemplo, un IC al 95% implica que, en el largo plazo, el 95% de los intervalos construidos con este m√©todo contendr√°n el valor verdadero.\nLa amplitud del IC est√° determinada por la precisi√≥n de la estimaci√≥n, que se calcula como el producto entre el coeficiente de confiabilidad (vinculado al nivel de confianza) y el error est√°ndar. La f√≥rmula general para construir un intervalo de confianza es:\n\\[ IC = estimador~puntual \\pm (coeficiente~de~confiabilidad) * (error~ estandar) \\]\nEn el caso de la media:\n\nAumento del nivel de confianza: Si se incrementa el nivel de confianza (por ejemplo, del 95% al 99%), el coeficiente de confiabilidad aumenta (por ejemplo, de 1.96 a 2.58), lo que produce un intervalo m√°s amplio.\n\nReducci√≥n del error est√°ndar: Si se mantiene fijo el nivel de confianza, reducir la amplitud del IC requiere disminuir el error est√°ndar. Para la media, este se calcula como:\n\\[ SE = \\frac{\\sigma}{\\sqrt{n}} \\]\ny considerando que \\(\\sigma\\) es constante, la √∫nica forma de disminuir el error est√°ndar es aumentando el tama√±o muestral (\\(n\\)).\n\n\nEl c√°lculo de los intervalos de confianza se basa en las distribuciones muestrales de los estimadores y en el error est√°ndar correspondiente. Aunque las f√≥rmulas pueden parecer complejas, los paquetes estad√≠sticos (como R) permiten calcularlos de forma autom√°tica. Lo esencial es comprender de qu√© depende la amplitud del IC (nivel de confianza, error est√°ndar y tama√±o de la muestra) y c√≥mo cada uno de estos factores influye en la precisi√≥n de la estimaci√≥n.",
    "crumbs": [
      "Introducci√≥n a la Revisi√≥n Sistem√°tica con Meta-an√°lisis",
      "Material Introductorio",
      "Introducci√≥n a la inferencia estad√≠stica"
    ]
  },
  {
    "objectID": "extras/intro_inferencia.html#pruebas-de-hip√≥tesis",
    "href": "extras/intro_inferencia.html#pruebas-de-hip√≥tesis",
    "title": "Introducci√≥n a la inferencia estad√≠stica",
    "section": "Pruebas de Hip√≥tesis",
    "text": "Pruebas de Hip√≥tesis\nLas pruebas de hip√≥tesis (tambi√©n conocidas como tests o contrastes de hip√≥tesis) permiten tomar decisiones sobre una poblaci√≥n a partir de los datos obtenidos de una muestra.\nAntes de profundizar en los aspectos estad√≠sticos, es importante distinguir entre dos tipos de hip√≥tesis:\n\nHip√≥tesis de investigaci√≥n: representan la pregunta o problema que motiva el estudio.\nHip√≥tesis estad√≠stica: es la formulaci√≥n que puede ser evaluada mediante t√©cnicas de estad√≠stica inferencial.\n\nEl contraste de hip√≥tesis se basa en la comparaci√≥n de dos hip√≥tesis estad√≠sticas:\n\nHip√≥tesis nula (\\(H_0\\)): sostiene que no existen diferencias entre los grupos comparados (por ejemplo, \\(\\mu = \\mu_0\\)‚Äã); por lo tanto, cualquier diferencia observada se debe √∫nicamente al azar.\nHip√≥tesis alternativa (\\(H_1\\)): plantea que existen diferencias entre grupos (por ejemplo, \\(\\mu \\neq \\mu_0,~ \\mu &gt; \\mu_0~ √≥~ \\mu &lt; \\mu_0\\)). Generalmente es la formulaci√≥n matem√°tica de nuestra hip√≥tesis de investigaci√≥n y es complementaria de \\(H_0\\). No se acepta ni se refuta de manera directa.\n\nEl m√©todo estad√≠stico nos permite cuantificar la diferencia entre grupos bajo el supuesto de que, si repiti√©semos el experimento infinitas veces y obtuvi√©semos todas las muestras posibles del mismo tama√±o, las diferencias entre grupos ‚Äúiguales‚Äù seguir√≠an una distribuci√≥n muestral te√≥rica. A partir de esta distribuci√≥n, se define un valor l√≠mite (por ejemplo, que abarca el 95% o el 99% de las diferencias esperadas).\n\nSi la diferencia observada excede ese l√≠mite, se considera demasiado grande para ser atribuida al azar y se rechaza la hip√≥tesis nula (\\(H_0\\)).\nSi la diferencia cae dentro del rango esperado, no se rechaza \\(H_0\\), ya que podr√≠a deberse al azar. En estos casos, se concluye que los grupos ‚Äúno son diferentes‚Äù, lo que no implica que ‚Äúsean iguales‚Äù, ya que la variabilidad muestral impide demostrar una igualdad exacta.\n\nLos contrastes de hip√≥tesis suelen realizarse suponiendo que se conoce a priori la distribuci√≥n de la poblaci√≥n y que se extrae una muestra aleatoria de la misma.\nEstad√≠stico de prueba\nEs el valor calculado a partir de los datos muestrales que se utiliza para tomar la decisi√≥n respecto de \\(H_0\\). Cada situaci√≥n tiene un estad√≠stico adecuado cuya magnitud, al compararse con su distribuci√≥n te√≥rica permite determinar si las diferencias observadas son atribuibles al azar. Por ejemplo:\n\nPara variables categ√≥ricas se utiliza el estad√≠stico chi-cuadrado (\\(\\chi^2\\)).\nPara variables num√©ricas, se emplean distribuciones como la normal (\\(Z\\)) o t de Student (\\(t\\)).\nErrores\nEn el razonamiento de los contrastes de hip√≥tesis existen dos posibles errores:\n\nError tipo I (\\(\\alpha\\)): ocurre cuando se rechaza la hip√≥tesis nula siendo esta verdadera. Es decir, se concluye err√≥neamente que existe una diferencia cuando en realidad no la hay. Para minimizar este riesgo, se elige un \\(\\alpha\\) peque√±o (por ejemplo, 0,01; 0,05 o 0,10).\nError tipo II (\\(\\beta\\)): ocurre cuando no se rechaza la hip√≥tesis nula siendo esta falsa, es decir, se falla en detectar una diferencia real. El valor de \\(\\beta\\) depende del valor real del par√°metro, y suele ser mayor que \\(\\alpha\\); sin embargo, no se conoce con certeza una vez realizada la prueba.\n\nUna vez finalizado el an√°lisis, no es posible saber si se ha cometido alguno de estos errores, ya que el verdadero estado de la poblaci√≥n es desconocido. Sin embargo, si se ha utilizado un \\(\\alpha\\) bajo, podemos tener mayor confianza en que, si se rechaz√≥ \\(H_0\\), el error tipo I es poco probable.\nNivel de significancia\nEl nivel de significaci√≥n (\\(\\alpha\\)) representa la probabilidad de cometer un error tipo I, es decir, rechazar \\(H_0\\) cuando en realidad es verdadera. Se define antes del an√°lisis (com√∫nmente 0,05 o 0,01) y determina el l√≠mite entre la regi√≥n de no rechazo y la regi√≥n cr√≠tica.\nRegi√≥n cr√≠tica\nSe denomina regi√≥n cr√≠tica (o regi√≥n de rechazo) al conjunto de valores del estad√≠stico de prueba que llevan al rechazo de \\(H_0\\). Esta regi√≥n se define seg√∫n el nivel de significaci√≥n (\\(\\alpha\\)), e incluye los valores extremos del estad√≠stico que ser√≠an poco probables si \\(H_0\\) fuera cierta. En una representaci√≥n gr√°fica, la regi√≥n cr√≠tica se ubica en una o ambas colas de la distribuci√≥n, dependiendo del tipo de prueba\n\n\n\n\n\n\n\n\nLa regla de decisi√≥n es la siguiente:\n\nSi el valor calculado del estad√≠stico cae dentro de la regi√≥n cr√≠tica, se rechaza \\(H_0\\) y se concluye que las diferencias observadas son estad√≠sticamente significativas.\nSi el valor no cae en la regi√≥n cr√≠tica, no se rechaza \\(H_0\\). En ese caso, las diferencias observadas pueden explicarse por el azar, y no se consideran estad√≠sticamente significativas.\nValor cr√≠tico\nEl valor cr√≠tico o p-valor es la probabilidad de obtener un resultado igual o m√°s extremo que el observado, bajo la suposici√≥n de que \\(H_0\\) es verdadera. Representa el menor nivel de \\(\\alpha\\) para el cual puede rechazarse \\(H_0\\).\nSi el valor p es muy peque√±o, indica que el resultado observado ser√≠a poco probable si \\(H_0\\) fuera cierta, por lo tanto, se rechaza la hip√≥tesis nula.\nLa regla pr√°ctica es:\n\nSi \\(p \\leq \\alpha\\), se rechaza \\(H_0\\).\nSi \\(p &gt; \\alpha\\), no se rechaza \\(H_0\\).\nTipos de contraste\nLos contrastes de hip√≥tesis se clasifican seg√∫n la forma de la hip√≥tesis alternativa (\\(H_1\\)). Esta clasificaci√≥n determina si la prueba es unilateral (de cola izquierda o derecha) o bilateral (de dos colas).\nTest de cola izquierda\nLa hip√≥tesis alternativa plantea que la media del primer grupo es significativamente menor que la del segundo:\n\\[\nH_1: \\mu_1 &lt; \\mu_2\n\\]\nLa regi√≥n cr√≠tica se encuentra en el extremo izquierdo de la distribuci√≥n. Todo el √°rea cr√≠tica tiene un tama√±o \\(\\alpha\\) con un valor cr√≠tico de \\(-1,645\\).\n\n\n\n\n\n\n\n\nTest de cola derecha\nLa hip√≥tesis alternativa establece que la media del primer grupo es significativamente mayor que la del segundo:\n\\[ H_1: \\mu_1 &gt; \\mu_2 \\]\nLa regi√≥n cr√≠tica se concentra en el extremo derecho de la distribuci√≥n y toda el √°rea cr√≠tica tiene un tama√±o \\(\\alpha\\) con un valor cr√≠tico de \\(1,645\\).\n\n\n\n\n\n\n\n\nPruebas bilaterales\nLa hip√≥tesis alternativa afirma que existen diferencias entre los grupos, sin especificar la direcci√≥n:\n\\[\nH_1: \\mu_1 \\neq \\mu_2\n\\]\nLa regi√≥n cr√≠tica se divide entre ambos extremos de la distribuci√≥n, con valores cr√≠ticos de \\(\\pm 1,96\\). El nivel de significaci√≥n total (\\(\\alpha\\)) se reparte en partes iguales entre las dos colas (\\(\\alpha/2\\) en cada una), lo que implica un 2,5% de probabilidad en cada cola si \\(H_0\\) es verdadera.\n\n\n\n\n\n\n\n\nPotencia estad√≠stica\nLa potencia estad√≠stica es la probabilidad de rechazar la hip√≥tesis nula (\\(H_0\\)) cuando esta es falsa, es decir, de detectar un efecto real. Se calcula como \\(1 - \\beta\\), donde \\(\\beta\\) es la probabilidad de cometer un error de tipo II. Aumenta con el tama√±o muestral, disminuye con la varianza, y depende de la magnitud del efecto que se desea detectar.\nMientras que \\(\\alpha\\) se fija antes del an√°lisis, \\(\\beta\\) var√≠a seg√∫n el valor real del par√°metro. La potencia se considera adecuada cuando alcanza al menos el 80%, lo que implica un 20% de riesgo de no detectar una diferencia real.\nNo es posible reducir simult√°neamente \\(\\alpha\\) y \\(\\beta\\), por lo que el dise√±o de una prueba debe buscar un equilibrio entre ambos errores. La potencia proporciona un control adicional en la toma de decisiones, ya que no basta con obtener un valor p peque√±o: tambi√©n se requiere una potencia suficiente para respaldar la conclusi√≥n.\nLa siguiente tabla resume las posibles situaciones en un contraste de hip√≥tesis:\n\n\n\n\n\nNo rechazar H0\nRechazar H0\n\n\n\nH0 es cierta\nCorrecto (1-Œ±)\nError tipo I (Œ±)\n\n\nH0 es falsa\nError tipo II (Œ≤)\nCorrecto (1-Œ≤)",
    "crumbs": [
      "Introducci√≥n a la Revisi√≥n Sistem√°tica con Meta-an√°lisis",
      "Material Introductorio",
      "Introducci√≥n a la inferencia estad√≠stica"
    ]
  },
  {
    "objectID": "extras/intro_inferencia.html#aplicaciones-e-interpretaci√≥n",
    "href": "extras/intro_inferencia.html#aplicaciones-e-interpretaci√≥n",
    "title": "Introducci√≥n a la inferencia estad√≠stica",
    "section": "Aplicaciones e Interpretaci√≥n",
    "text": "Aplicaciones e Interpretaci√≥n\nLa inferencia estad√≠stica permite responder preguntas de investigaci√≥n tales como:\n\n¬øEs significativa la diferencia entre dos medias?\n¬øExiste una relaci√≥n entre dos variables?\n¬øC√≥mo se distribuyen los datos respecto a un par√°metro de inter√©s?\n\nAl aplicar estos m√©todos, es crucial tener en cuenta la calidad y representatividad de la muestra, as√≠ como la validez de las asunciones subyacentes (normalidad, homogeneidad de varianzas, etc.).\n\n\n\n\n\n\nEste apunte sintetiza los conceptos esenciales y las herramientas b√°sicas para llevar a cabo un an√°lisis inferencial, que sirve de base para la interpretaci√≥n de modelos y resultados en an√°lisis cuantitativos. Quienes necesiten profundizar m√°s en los temas, les recomendamos consultar las siguientes fuentes:\n\nManual de Epidemiolog√≠a: Fundamentos, M√©todos y Aplicaciones (Instituto Nacional de Epidemiolog√≠a 2015): Cap√≠tulo 3.\nEstad√≠stica 12A Edici√≥n (Triola 2018): Cap√≠tulos 8 y 9.\n\n\n\n\n\nR√≠us D√≠az et¬†al. (2012)\nDaniel (2002)\nGlantz, S (2006)\nAgresti (2015)",
    "crumbs": [
      "Introducci√≥n a la Revisi√≥n Sistem√°tica con Meta-an√°lisis",
      "Material Introductorio",
      "Introducci√≥n a la inferencia estad√≠stica"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introducci√≥n a la Revisi√≥n Sistem√°tica con Meta-an√°lisis",
    "section": "",
    "text": "Les damos la bienvenida al curso de ‚ÄúIntroducci√≥n a la Revisi√≥n Sistem√°tica con Meta-an√°lisis‚Äù. Antes de profundizar en los temas espec√≠ficos, recomendamos a quienes lo requieran repasar el material introductorio sobre inferencia estad√≠stica y primeros pasos en R y RStudio. ya que les proporcionar√° una base s√≥lida para aprovechar al m√°ximo el curso. ¬°Esperamos que disfruten y enriquezcan sus conocimientos!\n\n\n\n Volver arribaReutilizaci√≥nCC BY-NC 4.0"
  },
  {
    "objectID": "unidad_2/02_fixed_random.html",
    "href": "unidad_2/02_fixed_random.html",
    "title": "Modelos de meta-an√°lisis",
    "section": "",
    "text": "Uno de los objetivos principales del modelado estad√≠stico es representar la realidad de la manera m√°s ‚Äúsencilla‚Äù posible, capturando su estructura esencial y descartando elementos cuya variabilidad podr√≠a generar ruido en la interpretaci√≥n de los fen√≥menos.\nPara ajustar un modelo estad√≠stico, partimos de los datos disponibles y buscamos construir una representaci√≥n basada en ellos. En el caso de los modelos de meta-an√°lisis, los datos de inter√©s son los estimadores de efecto obtenidos en cada estudio, y el objetivo principal es analizar la variabilidad entre ellos, la cual puede deberse a diferencias metodol√≥gicas, caracter√≠sticas de las poblaciones estudiadas u otras fuentes.\nExisten dos enfoques principales en meta-an√°lisis: los modelos de efectos fijos y los modelos de efectos aleatorios. Durante este curso, describiremos sus caracter√≠sticas fundamentales y su implementaci√≥n en R. Para quienes deseen profundizar en los fundamentos matem√°ticos de estos modelos, recomendamos consultar el Cap√≠tulo 4 de Schwarzer, Carpenter, y R√ºcker (2015) y el Cap√≠tulo 2 de Harrer et¬†al. (2021).",
    "crumbs": [
      "Introducci√≥n a la Revisi√≥n Sistem√°tica con Meta-an√°lisis",
      "Meta-an√°lisis",
      "Modelos de meta-an√°lisis"
    ]
  },
  {
    "objectID": "unidad_2/02_fixed_random.html#introducci√≥n",
    "href": "unidad_2/02_fixed_random.html#introducci√≥n",
    "title": "Modelos de meta-an√°lisis",
    "section": "",
    "text": "Uno de los objetivos principales del modelado estad√≠stico es representar la realidad de la manera m√°s ‚Äúsencilla‚Äù posible, capturando su estructura esencial y descartando elementos cuya variabilidad podr√≠a generar ruido en la interpretaci√≥n de los fen√≥menos.\nPara ajustar un modelo estad√≠stico, partimos de los datos disponibles y buscamos construir una representaci√≥n basada en ellos. En el caso de los modelos de meta-an√°lisis, los datos de inter√©s son los estimadores de efecto obtenidos en cada estudio, y el objetivo principal es analizar la variabilidad entre ellos, la cual puede deberse a diferencias metodol√≥gicas, caracter√≠sticas de las poblaciones estudiadas u otras fuentes.\nExisten dos enfoques principales en meta-an√°lisis: los modelos de efectos fijos y los modelos de efectos aleatorios. Durante este curso, describiremos sus caracter√≠sticas fundamentales y su implementaci√≥n en R. Para quienes deseen profundizar en los fundamentos matem√°ticos de estos modelos, recomendamos consultar el Cap√≠tulo 4 de Schwarzer, Carpenter, y R√ºcker (2015) y el Cap√≠tulo 2 de Harrer et¬†al. (2021).",
    "crumbs": [
      "Introducci√≥n a la Revisi√≥n Sistem√°tica con Meta-an√°lisis",
      "Meta-an√°lisis",
      "Modelos de meta-an√°lisis"
    ]
  },
  {
    "objectID": "unidad_2/02_fixed_random.html#modelos-de-efectos-fijos",
    "href": "unidad_2/02_fixed_random.html#modelos-de-efectos-fijos",
    "title": "Modelos de meta-an√°lisis",
    "section": "Modelos de efectos fijos",
    "text": "Modelos de efectos fijos\nEl modelo de efectos fijos parte de la premisa de que todos los estimadores de efecto incluidos en el meta-an√°lisis (\\(y_k\\)) provienen de una poblaci√≥n homog√©nea. Es decir, se asume un √∫nico efecto verdadero subyacente, denotado como \\(\\theta\\), y que las diferencias observadas entre estudios se explican √∫nicamente por el error muestral (\\(\\epsilon_k\\)).\n\\[\ny_k = \\theta + \\epsilon_k\n\\tag{1}\\]\nEste error muestral es dependiente del tama√±o de la muestra y equivalente al error est√°ndar del estimador. El objetivo es entonces calcular \\(\\theta\\) usando el promedio ponderado de los estimadores de efecto individuales.\n\\[\n\\theta = \\frac{\\sum{y_k w_k}}{\\sum{w_k}} \\qquad donde~w_k = \\frac{1}{S^2_{y_k}}\n\\tag{2}\\]\nEn el modelo de efectos fijos, los estudios con menor varianza poseen mayor influencia sobre la estimaci√≥n global. Esta estrategia de ponderaci√≥n se conoce como el m√©todo de la varianza inversa.\nComo se supone que los estudios son homog√©neos entre s√≠, no se considera la existencia de fuentes de variabilidad adicionales. Por esta raz√≥n, tambi√©n se les conoce como modelo de efecto com√∫n (common effect model) o modelo de efectos equivalentes (equal effect model).\nNo obstante, en la pr√°ctica, es frecuente encontrar heterogeneidad real entre los estudios, lo que hace inadecuado el enfoque de efectos fijos. En estos casos, conviene optar por un modelo de efectos aleatorios, que incorpora expl√≠citamente esa heterogeneidad en la estimaci√≥n del efecto global.",
    "crumbs": [
      "Introducci√≥n a la Revisi√≥n Sistem√°tica con Meta-an√°lisis",
      "Meta-an√°lisis",
      "Modelos de meta-an√°lisis"
    ]
  },
  {
    "objectID": "unidad_2/02_fixed_random.html#modelos-de-efectos-aleatorios",
    "href": "unidad_2/02_fixed_random.html#modelos-de-efectos-aleatorios",
    "title": "Modelos de meta-an√°lisis",
    "section": "Modelos de efectos aleatorios",
    "text": "Modelos de efectos aleatorios\nLos modelos de efectos aleatorios asumen que, adem√°s del error muestral, existen fuentes adicionales de variabilidad entre los estudios. A diferencia del modelo de efectos fijos, no se postula un √∫nico efecto verdadero com√∫n, sino que se considera que cada estudio estima un efecto espec√≠fico, que var√≠a alrededor de una media global.\nLa relaci√≥n entre el estimador de efecto para cada estudio (\\(y_k\\)) y su efecto verdadero se expresa como:\n\\[\ny_k = \\theta_k + \\epsilon_k\n\\tag{3}\\]\nEn este enfoque, los verdaderos efectos de los estudios (\\(\\theta_k\\)) no son id√©nticos, sino que se distribuyen seg√∫n una distribuci√≥n de probabilidad con media \\(\\mu\\) y desv√≠o est√°ndar \\(\\tau\\),\nReemplazando \\(\\theta_k\\) en la ecuaci√≥n anterior:\n\\[\ny_k = \\mu + \\tau_k + \\epsilon_k\n\\tag{4}\\]\ndonde:\n\n\\(\\tau_k\\) representa el desv√≠o del efecto verdadero del estudio \\(k\\) con respecto a la media global.\n\\(\\epsilon_k\\) es el error muestral.\n\nEl objetivo del modelo es estimar la media de la distribuci√≥n de efectos verdaderos (\\(\\mu\\)), teniendo en cuenta tanto la variabilidad dentro de los estudios (error muestral) como la variabilidad entre estudios (heterogeneidad). Para ello, cada estudio se pondera mediante una versi√≥n ajustada del m√©todo de la varianza inversa:\n\\[w^*_i = \\frac{1}{S^2_{y_k} + \\tau^2} \\qquad donde~\\tau^2 es~ la~ varianza~entre~estudios \\tag{5}\\]\nEl valor de tau-cuadrado no se conoce de antemano y debe estimarse a partir de los datos. Entre los m√©todos m√°s utilizados se encuentran el estimador de DerSimonian y Laird y la m√°xima verosimilitud restringida (REML). Aunque su desarrollo t√©cnico excede los objetivos de este curso, es importante destacar que la elecci√≥n del m√©todo puede influir tanto en la estimaci√≥n del efecto global como en la amplitud de los intervalos de confianza.\n\nIndicadores de heterogeneidad\nEn un meta-an√°lisis, la variabilidad observada en los resultados puede deberse a diversas fuentes:\n\nVariabilidad intraestudio: refleja las diferencias entre los participantes dentro de cada estudio.\nHeterogeneidad entre estudios: representa la variaci√≥n en los efectos estimados que no puede atribuirse √∫nicamente al azar.\nError de muestreo y otras fuentes de incertidumbre, que tambi√©n pueden influir en las diferencias observadas.\n\nLa heterogeneidad entre estudios es particularmente importante, ya que permite evaluar si los efectos estimados var√≠an m√°s de lo esperado por error aleatorio. Identificar y cuantificar esta heterogeneidad es esencial para decidir si corresponde utilizar un modelo de efectos aleatorios en lugar de uno de efectos fijos.\nLa siguiente tabla, adaptada de Schwarzer, Carpenter, y R√ºcker (2015), presenta los principales indicadores utilizados para cuantificar la heterogeneidad:\n\n\n\n\n\nMedida\nInterpretaci√≥n\nEscala\nRango\nN√∫mero de estudios\nPrecisi√≥n\n\n\n\n\nQ de Cochran\nEval√∫a si la variabilidad observada es mayor a la esperada por azar.\nAbsoluta\n[0, ‚àû)\nDependiente\nDependiente\n\n\nI¬≤\nPorcentaje de la variaci√≥n total atribuible a la heterogeneidad entre estudios.\nPorcentaje\n[0, 100]\nIndependiente\nDependiente\n\n\nH¬≤\nRaz√≥n entre la varianza observada y la varianza esperada bajo homogeneidad.\nAbsoluta\n[1, ‚àû)\nIndependiente\nDependiente\n\n\nœÑ¬≤\nVarianza entre los efectos verdaderos de los estudios incluidos.\nVarianza\n[0, ‚àû)\nIndependiente\nIndependiente\n\n\n\n\n\n\n\nEstos indicadores permiten evaluar si las diferencias observadas entre los estudios justifican el uso de un modelo de efectos aleatorios. A modo de s√≠ntesis:\n\nEl estad√≠stico \\(Q\\) de Cochran aumenta con el n√∫mero de estudios (\\(k\\)) y su precisi√≥n (tama√±o muestral).\nTanto \\(I^2\\) como \\(H^2\\) se derivan de \\(Q\\) y son independientes del n√∫mero de estudios, pero no de su precisi√≥n.\nLa varianza entre estudios, \\(\\tau^2\\), y su desv√≠o est√°ndar (\\(\\tau\\)), son independientes tanto de \\(k\\) como de la precisi√≥n, pero su interpretaci√≥n es menos intuitiva.\n\nEntre estos indicadores, \\(I^2\\) y su intervalo de confianza del 95‚ÄØ% son los m√°s com√∫nmente reportados. Su interpretaci√≥n usual es:\n\nHasta 25‚ÄØ%: heterogeneidad baja.\nEntre 25‚ÄØ% y 50‚ÄØ%: heterogeneidad moderada.\nM√°s del 75‚ÄØ%: heterogeneidad alta.\n\nPara complementar la informaci√≥n proporcionada por \\(I^2\\), se recomienda reportar un intervalo de predicci√≥n, que indica el rango en el que podr√≠an encontrarse los efectos verdaderos de estudios futuros, considerando la heterogeneidad estimada a partir de la evidencia actual.",
    "crumbs": [
      "Introducci√≥n a la Revisi√≥n Sistem√°tica con Meta-an√°lisis",
      "Meta-an√°lisis",
      "Modelos de meta-an√°lisis"
    ]
  },
  {
    "objectID": "unidad_2/02_fixed_random.html#implementaci√≥n-en-r",
    "href": "unidad_2/02_fixed_random.html#implementaci√≥n-en-r",
    "title": "Modelos de meta-an√°lisis",
    "section": "Implementaci√≥n en R",
    "text": "Implementaci√≥n en R\nExisten diversos paquetes para ajustar modelos de meta-an√°lisis en R, siendo los m√°s utilizados metafor (Viechtbauer 2010) y meta (Balduzzi, R√ºcker, y Schwarzer 2019). Ambos ajustan modelos robustos, pero difieren en su enfoque, facilidad de uso y otras caracter√≠sticas.\n\n\n\n\n\n\nmetafor\nmeta\n\n\n\n\nCaracter√≠stica principal\nFlexibilidad y potencia\nFacilidad de uso\n\n\nCurva de aprendizaje\nModerada a alta\nApto para principiantes en R\n\n\nTipo de datos\nPuede manejar diversos tipos de datos y transformaciones\nFunciones espec√≠ficas para cada tipo de datos\n\n\nMeta-regresiones\nPermite m√∫ltiples covariables e interacciones\nPermiten una o pocas covariables\n\n\nAn√°lisis de subgrupos\nMeta-regresi√≥n con predictores categ√≥ricos\nArgumentos espec√≠ficos para an√°lisis de subgrupos\n\n\nSalida\nDetallada, muestra estad√≠sticos avanzados\nConcisa, orientada a interpretar los resultados\n\n\n\n\n\n\n\nDado que este curso se enfoca en la aplicaci√≥n pr√°ctica del meta-an√°lisis, utilizaremos principalmente el paquete meta, que ajusta por defecto modelos de efectos fijos y aleatorios, e incluye distintos estimadores de heterogeneidad estad√≠stica.\n\nEstructura b√°sica\nEl paquete meta ofrece una serie de funciones para ajustar modelos de meta-an√°lisis con una estructura uniforme. La funci√≥n principal es metagen(), que permite trabajar con datos precalculados. Sus argumentos principales son:\n\nmetagen(\n1  TE,\n2  seTE,\n3  studlab,\n4  data,\n5  subset,\n6  common,\n7  random,\n8  subgroup,\n9  cluster,\n10  prediction,\n11  backtransf,\n  ...\n)\n\n\n1\n\nEstimador de efecto individual.\n\n2\n\nError est√°ndar el estimador de efecto individual.\n\n3\n\nIdentificador √∫nico del estudio (opcional).\n\n4\n\nConjunto de datos a utilizar (opcional).\n\n5\n\nFiltrar estudios por una condici√≥n (opcional).\n\n6\n\nAjustar modelo de efectos fijos (TRUE/FALSE).\n\n7\n\nAjustar modelo de efectos aleatorios (TRUE/FALSE).\n\n8\n\nDefinir variable para an√°lisis de subgrupos (opcional).\n\n9\n\nDefinir variable para ajuste de modelo multinivel (opcional).\n\n10\n\nCalcular intervalo de predicci√≥n (TRUE/FALSE, opcional).\n\n11\n\nMostrar resultados en la escala original de los datos (TRUE/FALSE, opcional).\n\n\n\n\n\n\nEjemplo pr√°ctico\nUsaremos el conjunto de datos dat.konstantopoulos2011, incluido en la dependencia metadat (Viechtbauer et¬†al. 2025). El mismo presenta los resultados de 56 estudios que comparan el rendimiento escolar de estudiantes que asisten a escuelas con un calendario escolar modificado ‚Äîcaracterizado por varios per√≠odos cortos de vacaciones distribuidos a lo largo del a√±o‚Äî con aquellos que asisten a escuelas con un calendario tradicional, que incluye un receso de verano largo y vacaciones m√°s breves en invierno y primavera. Los resultados se expresan como diferencias de medias estandarizadas.\nComenzaremos por cargar el paquete necesario:\n\n# Cargar el paquete meta\nlibrary(meta)\n\nCargamos los datos y exploramos su estructura:\n\n# Cargar datos\ndatos &lt;- dat.konstantopoulos2011\n\n# Explorar estructura del dataset\nnames(datos)\n\n[1] \"district\" \"school\"   \"study\"    \"year\"     \"yi\"       \"vi\"      \n\n\nLas variables de entrada para metagen() ser√°n yi (diferencia de medias estandarizada), vi (variabilidad de la estimaci√≥n) y study¬†(identificador √∫nico del estudio):\n\n# Ajustar el modelo\nmod &lt;- metagen(TE = yi,\n               seTE = vi,\n               studlab = study,\n               common = TRUE,    \n               random = TRUE,    \n               backtransf = TRUE, \n               data = datos)\n\nPodemos acceder a la salida completa del modelo, con los estimadores de efecto y su \\(95\\%~CI\\) para cada estudio usando summary(), o a una versi√≥n m√°s resumida imprimiendo el objeto donde almacenamos el modelo:\n\n# Resumen del modelo\nmod\n\nNumber of studies: k = 56\n\n                                         95%-CI      z p-value\nCommon effect model  -0.0133 [-0.0140; -0.0126] -38.82       0\nRandom effects model  0.1219 [ 0.0365;  0.2074]   2.80  0.0052\n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.1048 [0.0739; 0.1588]; tau = 0.3238 [0.2719; 0.3985]\n I^2 = 99.9%; H = 41.32\n\nTest of heterogeneity:\n        Q d.f. p-value\n 93892.81   55       0\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n\n\nAntes de analizar en detalle cada elemento de la salida debemos fijarnos en el valor de \\(I^2\\), ya que si el porcentaje de heterogeneidad estad√≠stica es alto, debemos omitir los resultados del modelo de efectos fijos. En nuestro ejemplo \\(I^2 = 99,9\\%\\) nos indica que el modelo de efectos aleatorios es el m√°s apropiado (podemos reajustar el modelo cambiando el argumento common a FALSE o simplemente ignorar estos coeficientes).\nUna vez que decidimos con cual modelo quedarnos, procedemos a interpretar la salida:\n\nk: n√∫mero de estudios incluidos en el an√°lisis.\nCommon effect model: estimador de efecto, \\(95\\%~IC\\), estad√≠stico z y significancia estad√≠stica para el modelo de efectos fijos.\nRandom effects model: estimador de efecto, \\(95\\%~IC\\), estad√≠stico z y significancia estad√≠stica para el modelo de efectos aleatorios.\nQuantifying heterogeneity (with 95%-CIs): muestra las distintas medidas de heterogeneidad y los test de significancia asociados:\n\ntau^2: variabilidad entre estudios (tau-cuadrado) y su \\(95\\%~IC\\).\ntau: ra√≠z cuadrada de la variabilidad entre estudios y su \\(95\\%~IC\\).\nI^2: porcentaje de variabilidad atribuida a diferencias reales entre estudios (\\(I^2\\)).\nH: ra√≠z cuadrada del estad√≠stico \\(H^2\\), que mide la raz√≥n entre la varianza observada y la esperada.\nQ: estad√≠stico Q de Cochran con sus grados de libertad y significancia.\n\nDetails of meta-analysis methods: indica los m√©todos estad√≠sticos utilizados en el ajuste del modelo, incluyendo:\n\nInverse variance method: m√©todo de varianza inversa para ponderar los estudios.\nRestricted maximum-likelihood estimator for tau^2: estimador de m√°xima verosimilitud restringida para tau-cuadrado.\nQ-Profile method for confidence interval of tau^2 and tau: m√©todo para estimar el intervalo de confianza de tau y tau-cuadrado.\nCalculation of I^2 based on Q: metodolog√≠a aplicada para calcular \\(I^2\\).\n\n\nEl paquete meta no calcula el intervalo de predicci√≥n por defecto, si nos interesa obtenerlo podemos actualizar el modelo de la siguiente forma:\n\n# Calcular el intervalo de predicci√≥n\nmod &lt;- update(mod, prediction = TRUE)\n\n# Salida del modelo\nmod\n\nNumber of studies: k = 56\n\n                                         95%-CI      z p-value\nCommon effect model  -0.0133 [-0.0140; -0.0126] -38.82       0\nRandom effects model  0.1219 [ 0.0365;  0.2074]   2.80  0.0052\nPrediction interval          [-0.5328;  0.7767]               \n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.1048 [0.0739; 0.1588]; tau = 0.3238 [0.2719; 0.3985]\n I^2 = 99.9%; H = 41.32\n\nTest of heterogeneity:\n        Q d.f. p-value\n 93892.81   55       0\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n- Prediction interval based on t-distribution (df = 55)\n\n# L√≠mite inferior intervalo de predicci√≥n\nmod$lower.predict\n\n[1] -0.5328297\n\n# L√≠mite superior intervalo de predicci√≥n\nmod$upper.predict\n\n[1] 0.7767285\n\n\n\n\nInterpretaci√≥n de resultados\nEn base a la salida anterior, podemos concluir que el meta-an√°lisis realizado sobre 56 estudios individuales muestra que el rendimiento acad√©mico aumenta significativamente con la modificaci√≥n del calendario escolar (\\(p &lt; 0.005\\)). La alta heterogeneidad estad√≠stica (\\(I^2 = 99,9\\%\\)) sugiere que la variabilidad observada se debe a diferencias reales entre estudios y el intervalo de predicci√≥n incluye la posibilidad de obtener asociaciones negativas en futuros estudios.\n\n\nRepresentaci√≥n gr√°fica\nLos resultados del meta-an√°lisis pueden visualizarse mediante forest plots, gr√°ficos que representan la distribuci√≥n de los estimadores de efecto de los estudios individuales y sus intervalos de confianza en relaci√≥n con el estimador global. Adem√°s, proporcionan informaci√≥n sobre la heterogeneidad entre estudios, facilitando la interpretaci√≥n de los resultados.\nEl paquete meta incluye la funci√≥n forest(), que permite generar forest plots de forma r√°pida y con m√∫ltiples opciones de personalizaci√≥n. Para conocer todos los argumentos disponibles, se puede ejecutar ?forest en la consola de R.\nAlgunos de sus argumentos principales incluyen:\n\nforest(\n1  mod,\n2  sortvar,\n3  smlab,\n4  col.diamond,\n5  col.square,\n6  print.tau2 = TRUE,\n7  print.I2 = TRUE,\n8  print.Q = TRUE,\n9  digits = 2,\n  ...)\n\n\n1\n\nNombre del modelo de meta-an√°lisis.\n\n2\n\nOrdenar los estudios seg√∫n una variable num√©rica\n\n3\n\nEtiqueta a mostrar para el estimador de efecto.\n\n4\n\nColor para mostrar el s√≠mbolo del estimador de efecto global.\n\n5\n\nColor para mostrar el s√≠mbolo de los estimadores de efecto individuales.\n\n6\n\nMostrar tau-cuadrado (TRUE/FALSE).\n\n7\n\nMostrar I-cuadrado (TRUE/FALSE).\n\n8\n\nMostrar Q de Cochran (TRUE/FALSE).\n\n9\n\nEspecificar el n√∫mero de decimales a mostrar en los resultados.\n\n\n\n\nA continuaci√≥n, generaremos un forest plot para representar gr√°ficamente el modelo que ajustamos. Para mejorar su visualizaci√≥n, vamos a usar colores personalizados para los argumentos col.diamond y col.square:\n\nforest(mod,\n       smlab = \"Diferencia de medias estandarizada\",\n       col.diamond = \"#8C0172\",   # Color estimador global\n       col.square = \"#6BD48C\",    # Color estimadores individuales\n       common = FALSE,            # Omitir modelo de efectos fijos\n       prediction = TRUE          # Mostrar intervalo de predicci√≥n\n       )\n\n\n\n\n\n\n\n\nEl gr√°fico consta de tres paneles principales:\n\nPanel izquierdo\n\nMuestra el identificador √∫nico de cada estudio (generalmente el apellido del primer autor y el a√±o de publicaci√≥n).\nPuede incluir columnas adicionales seg√∫n el tipo de estimador de efecto utilizado (por ejemplo, tama√±o muestral, n√∫mero de eventos, medias y desv√≠os est√°ndar, etc.).\n\n\n\nPanel central\n\nL√≠nea vertical de referencia: indica el valor de no efecto (0 para diferencias de medias o coeficientes de correlaci√≥n; 1 para datos en escala logar√≠tmica).\nEstimador global: representado por una l√≠nea punteada vertical que finaliza en un rombo. La posici√≥n del mismo indica el valor puntual estimado y su ancho el intervalo de confianza (\\(95\\%~IC\\)).\nEstimadores individuales: representados por cuadrados, cuyo tama√±o est√° dado por el peso estad√≠stico del estudio, con bigotes horizontales que indican su \\(95\\%~IC\\).\nOpcionalmente, se puede incluir una l√≠nea horizontal roja que representa el intervalo de predicci√≥n.\nEn la parte inferior del gr√°fico se reportan los valores de \\(I^2\\), \\(\\tau^2\\) y la significancia del test Q de Cochran.\n\n\n\nPanel derecho\n\nMuestra el valor del estimador de efecto para cada estudio y su \\(95\\%~IC\\).\nIndica el peso estad√≠stico asignado a cada estudio en el modelo.\n\nSe puede controlar la informaci√≥n que aparece en los lados del forest plot mediante los argumentos leftcols, rightcols, leftlabs y rightlabs. Tambi√©n es posible aplicar formatos predefinidos con layout = \"RevMan5\" o layout = \"JAMA\", que ajustan el dise√±o seg√∫n estilos ampliamente utilizados en la literatura cient√≠fica.\nLos gr√°ficos generados con forest() no son compatibles con ggplot2 ni se autoescalan, lo que puede ser problem√°tico si el n√∫mero de estudios es grande, ya que el gr√°fico podr√≠a quedar ilegible en la vista predeterminada.\nPara evitar este problema, se recomienda exportar el gr√°fico a un archivo de imagen (por ejemplo, PDF o PNG) usando las funciones pdf() o png(), especificando un tama√±o adecuado antes de ejecutarlo con forest(). En la √∫ltima clase adem√°s veremos opciones de visualizaci√≥n avanzada para generar gr√°ficos listos para su publicaci√≥n.\nEn la siguiente secci√≥n, exploraremos las funciones de meta que permiten ajustar modelos de meta-an√°lisis para distintos estimadores de efecto en epidemiolog√≠a. Luego, abordaremos m√©todos para controlar la heterogeneidad, tales como el an√°lisis de moderadores y la meta-regresi√≥n y aprenderemos qu√© es y como se mide el sesgo de publicaci√≥n.",
    "crumbs": [
      "Introducci√≥n a la Revisi√≥n Sistem√°tica con Meta-an√°lisis",
      "Meta-an√°lisis",
      "Modelos de meta-an√°lisis"
    ]
  },
  {
    "objectID": "unidad_2/04_mod_bias.html",
    "href": "unidad_2/04_mod_bias.html",
    "title": "Exploraci√≥n de la heterogeneidad",
    "section": "",
    "text": "En la clase anterior abordamos el ajuste de modelos de efectos fijos y aleatorios, la representaci√≥n gr√°fica de los resultados mediante forest plots y la estimaci√≥n de la heterogeneidad estad√≠stica. En esta clase, nos enfocaremos en distintas estrategias para controlar la heterogeneidad observada y evaluar la robustez de los modelos ajustados.",
    "crumbs": [
      "Introducci√≥n a la Revisi√≥n Sistem√°tica con Meta-an√°lisis",
      "Meta-an√°lisis",
      "Exploraci√≥n de la heterogeneidad"
    ]
  },
  {
    "objectID": "unidad_2/04_mod_bias.html#introducci√≥n",
    "href": "unidad_2/04_mod_bias.html#introducci√≥n",
    "title": "Exploraci√≥n de la heterogeneidad",
    "section": "",
    "text": "En la clase anterior abordamos el ajuste de modelos de efectos fijos y aleatorios, la representaci√≥n gr√°fica de los resultados mediante forest plots y la estimaci√≥n de la heterogeneidad estad√≠stica. En esta clase, nos enfocaremos en distintas estrategias para controlar la heterogeneidad observada y evaluar la robustez de los modelos ajustados.",
    "crumbs": [
      "Introducci√≥n a la Revisi√≥n Sistem√°tica con Meta-an√°lisis",
      "Meta-an√°lisis",
      "Exploraci√≥n de la heterogeneidad"
    ]
  },
  {
    "objectID": "unidad_2/04_mod_bias.html#an√°lisis-de-moderadores",
    "href": "unidad_2/04_mod_bias.html#an√°lisis-de-moderadores",
    "title": "Exploraci√≥n de la heterogeneidad",
    "section": "An√°lisis de moderadores",
    "text": "An√°lisis de moderadores\nEl an√°lisis de moderadores permite explorar fuentes de heterogeneidad entre los estudios incluidos en un meta-an√°lisis. Se asume que los estudios no provienen de una misma poblaci√≥n base sino de distintas subpoblaciones o subgrupos, cada una con su propio efecto verdadero.\nPuede realizarse incorporando como moderador una variable categ√≥rica (an√°lisis de subgrupos) o una variable num√©rica (metarregresi√≥n).\nEste enfoque contribuye a:\n\nEvaluar hip√≥tesis sobre variaciones en la magnitud del estimador de efecto entre estudios.\nInterpretar diferencias observadas en los resultados.\n\nPara evitar sesgos de selecci√≥n, es fundamental definir las variables moderadoras durante la extracci√≥n de datos en la revisi√≥n sistem√°tica.\n\nAn√°lisis de sugbgrupos\nEn el an√°lisis de subgrupos se asume que los estudios no provienen de una poblaci√≥n √∫nica, sino de distintos subgrupos poblacionales, cada uno con su propio efecto verdadero.\nEl an√°lisis consta de dos etapas:\n\nEstimaci√≥n del efecto dentro de cada subgrupo.\nPrueba estad√≠stica para evaluar diferencias entre subgrupos.\n\nPara evaluar el efecto de una variable categ√≥rica con meta, ajustamos el modelo de meta-an√°lisis incluyendo el argumento subgroup = var, donde var es el nombre de una variable del dataset.\nEn el siguiente ejemplo, realizaremos un an√°lisis de subgrupos con el dataset ‚Äúdat.crisafulli2020‚Äù considerando el pa√≠s de realizaci√≥n del estudio (country) como posible fuente de heterogeneidad.\nCargamos los paquetes necesarios:\n\n# Cargar paquetes\npacman::p_load(\n  janitor,\n  meta,\n  tidyverse\n)\n\nCargamos los datos y exploramos su estructura:\n\n# Cargar datos\ndatos &lt;- dat.crisafulli2020\n\n# Inspeccionar estructura de los datos\nglimpse(datos)\n\nRows: 26\nColumns: 7\n$ study   &lt;chr&gt; \"Brooks (1977)\", \"Danieli (1977)\", \"Takeshita (1977)\", \"Drummo‚Ä¶\n$ pubyear &lt;int&gt; 1977, 1977, 1977, 1979, 1980, 1980, 1981, 1982, 1983, 1983, 19‚Ä¶\n$ country &lt;fct&gt; UK, IT, JP, NZ, AU, IT, IT, CA, FR, IT, DE, IT, JP, CA, NO, IT‚Ä¶\n$ from    &lt;int&gt; 1953, 1952, 1956, NA, 1960, 1952, 1955, 1950, 1978, 1969, 1977‚Ä¶\n$ to      &lt;int&gt; 1968, 1972, 1970, NA, 1971, 1972, 1974, 1979, 1978, 1980, 1984‚Ä¶\n$ cases   &lt;int&gt; 47, 66, 19, 2, 99, 105, 73, 110, 12, 156, 48, 76, 50, 5, 16, 2‚Ä¶\n$ total   &lt;int&gt; 177413, 234396, 91157, 10000, 532302, 371698, 301283, 420374, ‚Ä¶\n\n\nUsaremos la funci√≥n tabyl() del paquete janitor (Firke 2024) para generar una tabla de frecuencias de los niveles de la variable country:\n\ntabyl(datos, country) |&gt;   # Generar tabla de frecuencia\n  arrange(-n) |&gt;           # Ordenar por frecuencia\n  adorn_pct_formatting()   # Proporciones a porcentajes\n\n country n percent\n      IT 6   23.1%\n      CA 3   11.5%\n      UK 3   11.5%\n      JP 2    7.7%\n      AU 1    3.8%\n      BE 1    3.8%\n      CY 1    3.8%\n      DE 1    3.8%\n      DK 1    3.8%\n      EE 1    3.8%\n      FR 1    3.8%\n      NL 1    3.8%\n      NO 1    3.8%\n      NZ 1    3.8%\n      SI 1    3.8%\n      US 1    3.8%\n\n\nComo la mayor√≠a de los estudios provienen de Italia y la frecuencia en otros pa√≠ses es baja, creamos una variable dicot√≥mica pais_cat:\n\ndatos &lt;- datos |&gt; \n  mutate(pais_cat = if_else(\n    country  == \"IT\", # Condici√≥n a testear\n    \"Italia\",         # Valor si la condici√≥n se cumple\n    \"Otro/s\" ))       # Valor si la condici√≥n no se cumple\n\nAjustamos el modelo de meta-an√°lisis para proporciones, incorporando pais_cat como moderador:\n\nmod_sub &lt;- metaprop(\n  event = cases,          # Casos observados\n  n = total,              # Tama√±o de la muestra\n  studlab = study,        # Identificador del estudio\n  data = datos,           # Conjunto de datos\n  sm = \"PLOGIT\",          # Transformaci√≥n logit\n  common = FALSE,         # Omitir modelo de efectos fijos\n  random = TRUE,          # Modelo de efectos aleatorios\n  pscale = 100000,        # Escala a casos/100 000 habitantes\n  subgroup = pais_cat     # Moderador categ√≥rico\n)\n\nVeamos la salida del modelo:\n\nmod_sub\n\nNumber of studies: k = 26\nNumber of observations: o = 6831388\nNumber of events: e = 1545\n\n                      events             95%-CI\nRandom effects model 22.2342 [20.6056; 23.9915]\n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.0126; tau = 0.1121; I^2 = 33.2% [0.0%; 58.6%]; H = 1.22 [1.00; 1.55]\n\nTest of heterogeneity:\n          Q d.f. p-value\n Wald 37.41   25  0.0527\n LRT  39.01   25  0.0368\n\nResults for subgroups (random effects model):\n                    k  events             95%-CI  tau^2    tau     Q   I^2\npais_cat = Otro/s  20 20.9400 [19.0685; 22.9951] 0.0122 0.1104 26.02 27.0%\npais_cat = Italia   6 25.0380 [22.5505; 27.7999] 0.0033 0.0577  5.97 16.2%\n\nTest for subgroup differences (random effects model):\n                  Q d.f. p-value\nBetween groups 6.22    1  0.0126\n\nDetails of meta-analysis methods:\n- Random intercept logistic regression model\n- Maximum-likelihood estimator for tau^2\n- Calculation of I^2 based on Q\n- Logit transformation\n- Events per 100000 observations\n\n\nEl an√°lisis de subgrupos ajusta un modelo de meta-an√°lisis para cada nivel de la variable categ√≥rica, con sus estimadores de efecto (\\(95\\%~IC\\)) e indicadores de heterogeneidad, adem√°s del estimador global (\\(95\\%~IC\\)) y sus indicadores de heterogeneidad. En base a esto, la salida del modelo muestra dos nuevos paneles:\n\nResults for subgroups (random effects model): muestra los resultados para cada categor√≠a del moderador, incluyendo:\n\nIdentificador de las categor√≠as del moderador.\nk: n√∫mero de estudios en la categor√≠a/subgrupo.\nevents: prevalencia en la categor√≠a/subgrupo.\n95%-CI: intervalo de confianza al 95% para la prevalencia en la categor√≠a/subgrupo.\ntau^2: varianza dentro de la categor√≠a/subgrupo.\ntau: desv√≠o est√°ndar en la categor√≠a/subgrupo.\nQ: estad√≠stico Q de Cochran para la categor√≠a/subgrupo.\nI^2: porcentaje de heterogeneidad observado en la categor√≠a/subgrupo.\n\nTest for subgroup differences (random effects model): prueba de hip√≥tesis para detectar diferencias significativas entre subgrupos.\n\nEn este ejemplo, observamos una prevalencia significativamente mayor en Italia en comparaci√≥n con otros pa√≠ses \\((p = 0,013)\\). Podemos acceder al p-valor de la prueba de moderadores con el siguiente c√≥digo:\n\nmod_sub$pval.Q.b.random\n\n[1] 0.0125965\n\n\nPodemos visualizar los resultados del an√°lisis de moderadores incorporando el argumento layout = \"subgroup\" a la funci√≥n forest():\n\nforest(\n  mod_sub,\n1  layout = \"subgroup\",\n2  sort.subgroup = TRUE,\n3  calcwidth.subgroup = TRUE,\n4  calcwidth.tests = TRUE,\n5  print.subgroup.name = FALSE,\n)\n\n\n1\n\nlayout = \"subgroup\": muestra los estimadores de efecto para cada subgrupo y el estimador global, omitiendo los resultados de los estudios individuales.\n\n2\n\nsort.subgroup: ordena alfab√©ticamente las categor√≠as de la variable moderadora.\n\n3\n\ncalcwidth.subgroup: ajusta el ancho del forest plot para que se muestren correctamente las etiquetas de las categor√≠as/subgrupos.\n\n4\n\ncalcwidth.tests: ajusta el ancho del forest plot para que se muestren correctamente las etiquetas del test de hip√≥tesis de diferencias en las categor√≠as/subgrupos.\n\n5\n\nprint.subgroup.name: muestra la etiqueta de la variable moderadora delante de cada categor√≠a (TRUE, por defecto) o lo oculta (FALSE).\n\n\n\n\n\n\n\n\n\n\n\nCuando graficamos un an√°lisis de subgrupos, el argumento col.diamond modifica el color del estimador global y de los estimadores por subgrupo. El argumento col.square no tiene efecto en este caso.\nEl an√°lisis de subgrupos puede interpretarse como un enfoque intermedio entre el modelo de efectos fijos y el de efectos aleatorios. Se asume que existe heterogeneidad entre los subgrupos, y que cada nivel de la variable moderadora posee su propio efecto verdadero. Sin embargo, los subgrupos analizados (por ejemplo, sexo biol√≥gico, grupo etario, pa√≠s de origen, tipo de prueba diagn√≥stica) se consideran categor√≠as fijas, definidas a priori.\nEntre sus principales limitaciones se encuentran:\n\nSi la heterogeneidad es elevada, los intervalos de confianza pueden ser amplios y superponerse, incluso cuando existen diferencias estad√≠sticamente significativas entre subgrupos.\nEl tama√±o muestral por subgrupo es menor que para el estimador global, lo que reduce la potencia estad√≠stica.\nLa ausencia de significaci√≥n estad√≠stica no implica equivalencia entre los grupos, ya que el an√°lisis no permite evaluar relaciones causales.\n\n\n\nMetarregresi√≥n\nLa metarregresi√≥n intenta predecir el estimador de efecto global en base a una o m√°s variables independientes. Por lo general, se usa para evaluar el efecto de una variable continua (por ejemplo, el a√±o de publicaci√≥n) sobre la magnitud del efecto global. Sin embargo, tambi√©n pueden incluirse moderadores categ√≥ricos, obteniendo resultados id√©nticos a los del an√°lisis de subgrupos.\nPara ilustrar el uso de la metarregresi√≥n, vamos a reajustar el modelo anterior (mod_sub) eliminando el moderador categ√≥rico:\n\nmod &lt;- metaprop(\n  event = cases,          \n  n = total,              \n  studlab = study,        \n  data = datos,           \n  sm = \"PLOGIT\",         \n  common = FALSE,       \n  random = TRUE,\n  pscale = 100000,\n )\n\nO bien usando la funci√≥n update():\n\nmod &lt;- update(mod_sub, subgroup = NULL)\n\nAjustaremos la metarregresi√≥n con la funci√≥n metareg(), incluyendo el a√±o de publicaci√≥n (pubyear) como moderador en el argumento formula:\n\nmod_year &lt;- metareg(mod, \n                    formula = ~ pubyear,\n                    intercept = TRUE)\n\nLa salida del modelo muestra lo siguiente:\n\nsummary(mod_year)\n\n\nMixed-Effects Model (k = 26; tau^2 estimator: ML)\n\n  logLik  deviance       AIC       BIC      AICc   \n-75.9315   14.5514  157.8629  161.6372  158.9538   \n\ntau^2 (estimated amount of residual heterogeneity):     0.0067\ntau (square root of estimated tau^2 value):             0.0816\nI^2 (residual heterogeneity / unaccounted variability): 26.61%\nH^2 (unaccounted variability / sampling variability):   1.36\n\nTests for Residual Heterogeneity:\nWld(df = 24) = 28.8391, p-val = 0.2262\nLRT(df = 24) = 30.5162, p-val = 0.1682\n\nTest of Moderators (coefficient 2):\nQM(df = 1) = 7.1208, p-val = 0.0076\n\nModel Results:\n\n         estimate      se     zval    pval    ci.lb    ci.ub     \nintrcpt    8.5560  6.3550   1.3463  0.1782  -3.8996  21.0116     \npubyear   -0.0085  0.0032  -2.6685  0.0076  -0.0148  -0.0023  ** \n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nMixed-Effects Model:¬†reporta los cambios en heterogeneidad al a√±adir el moderador continuo y (seg√∫n el estimador) la bondad de ajuste (\\(R^2\\)) del modelo.\nModel results presenta los coeficientes del modelo para el intercepto y el moderador, con su significancia estad√≠stica y \\(95\\%~IC\\).\n\nEn nuestro ejemplo, los resultados muestran un efecto estad√≠sticamente significativo del a√±o de publicaci√≥n sobre la prevalencia del evento \\((p = 0,008)\\).\n\n\n\n\n\n\nImportante\n\n\n\nCuando se trabaja con moderadores continuos, estamos ajustando una recta de regresi√≥n que busca minimizar la diferencia entre el estimador observado y el predicho.\n\nEl intercepto corresponde al valor del efecto cuando el moderador es cero (lo cual no tiene interpretaci√≥n biol√≥gica).\nLa pendiente representa el efecto del moderador sobre el estimador de efecto.\n\nSi se utilizan moderadores categ√≥ricos, cada nivel de la variable representa un subgrupo con su propio estimador de efecto:\n\nSe debe omitir el intercepto para obtener directamente el estimador de efecto de cada categor√≠a.\nEste enfoque es equivalente a un ANOVA, donde se comparan medias entre grupos sin necesidad de definir una categor√≠a de referencia.\nLos resultados se presentan en escala transformada (por ejemplo log-OR), por lo que se debe aplicar la transformaci√≥n inversa para interpretarlos.\n\n\n\n\nBubble plots\nLos resultados de la metarregresi√≥n con predictores num√©ricos se visualizan usando bubble plots. Estos gr√°ficos representan en el eje \\(X\\) el valor del moderador continuo y en el eje \\(Y\\) el efecto estimado para cada estudio. Cada burbuja representa un estudio individual, y su tama√±o es proporcional al peso del estudio (generalmente inversamente proporcional a la varianza). Adem√°s, el gr√°fico incluye una l√≠nea de regresi√≥n con su intervalo de confianza del 95%, permitiendo visualizar la tendencia general.\nLa funci√≥n bubble() genera este gr√°fico de forma r√°pida:\n\nbubble(\n1  mod_year,\n2  cex = \"common\",\n3  col.line = \"magenta\"\n)\n\n\n1\n\nModelo de meta-an√°lisis.\n\n2\n\nTama√±o de las burbujas.\n\n3\n\nColor para la l√≠nea de regresi√≥n.\n\n\n\n\n\n\n\n\n\n\n\nPara ajustar el tama√±o de las burbujas seg√∫n el peso de cada estudio debemos definir una funci√≥n. Por ejemplo rescale() del paquete plotrix:\n\n# Peso de cada estudio\nwt &lt;- plotrix::rescale(\n    x = 1 / mod_year$vi,\n    newrange = c(0.5, 3))\n\nPara ajustar el tama√±o de las burbujas seg√∫n el peso de cada estudio, se puede modificar el argumento cex utilizando la funci√≥n anterior:\n\nbubble(\n  mod_year,\n  cex = wt,  # Ajusta la escala de los s√≠mbolos\n  col.line = \"magenta\"\n)\n\n\n\n\n\n\n\n\nO de forma m√°s artesanal, calculamos el tama√±o de las burbujas con el inverso de la varianza del modelo:\n\nbubble(\n  mod_year,\n  cex = (1/mod_year$vi) * 0.01,\n  col.line = \"magenta\", \n  studlab = TRUE         # A√±adir etiqueta autor principal\n)\n\n\n\n\n\n\n\n\n\n\nMetarregresi√≥n m√∫ltiple\nLos modelos de metarregresi√≥n permiten evaluar el efecto de dos o m√°s variables independientes, que pueden ser continuas, categ√≥ricas o una combinaci√≥n de ambas.\nAl igual que en los modelos de regresi√≥n convencional, se pueden especificar efectos aditivos (independientes) o multiplicativos (interacci√≥n).\n\n## Modelo aditivo\nreg1 &lt;- metareg(mod, formula = ~ pubyear + pais_cat)\n\nsummary(reg1)\n\n\nMixed-Effects Model (k = 26; tau^2 estimator: ML)\n\n  logLik  deviance       AIC       BIC      AICc   \n-75.1662   13.0208  158.3323  163.3647  160.2371   \n\ntau^2 (estimated amount of residual heterogeneity):     0.0063\ntau (square root of estimated tau^2 value):             0.0796\nI^2 (residual heterogeneity / unaccounted variability): 24.66%\nH^2 (unaccounted variability / sampling variability):   1.33\n\nTests for Residual Heterogeneity:\nWld(df = 23) = 27.5875, p-val = 0.2318\nLRT(df = 23) = 28.9347, p-val = 0.1825\n\nTest of Moderators (coefficients 2:3):\nQM(df = 2) = 8.9563, p-val = 0.0114\n\nModel Results:\n\n                estimate      se     zval    pval    ci.lb    ci.ub    \nintrcpt           4.3656  6.9407   0.6290  0.5294  -9.2380  17.9692    \npubyear          -0.0064  0.0035  -1.8233  0.0683  -0.0132   0.0005  . \npais_catOtro/s   -0.1110  0.0794  -1.3988  0.1619  -0.2666   0.0446    \n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n## Modelo multiplicativo\nreg2 &lt;- metareg(mod, formula = ~ pubyear * pais_cat)\n\nsummary(reg2)\n\n\nMixed-Effects Model (k = 26; tau^2 estimator: ML)\n\n  logLik  deviance       AIC       BIC      AICc   \n-75.2219   13.1323  160.4439  166.7344  163.4439   \n\ntau^2 (estimated amount of residual heterogeneity):     0.0062\ntau (square root of estimated tau^2 value):             0.0790\nI^2 (residual heterogeneity / unaccounted variability): 24.27%\nH^2 (unaccounted variability / sampling variability):   1.32\n\nTests for Residual Heterogeneity:\nWld(df = 22) = 27.4711, p-val = 0.1939\nLRT(df = 22) = 28.7926, p-val = 0.1509\n\nTest of Moderators (coefficients 2:4):\nQM(df = 3) = 9.8262, p-val = 0.0201\n\nModel Results:\n\n                        estimate      se     zval    pval     ci.lb    ci.ub    \nintrcpt                   8.8395  8.5541   1.0334  0.3014   -7.9261  25.6052    \npubyear                  -0.0086  0.0043  -2.0023  0.0453   -0.0171  -0.0002  * \npais_catOtro/s           -4.8434  5.2717  -0.9188  0.3582  -15.1757   5.4889    \npubyear:pais_catOtro/s    0.0024  0.0027   0.8976  0.3694   -0.0028   0.0076    \n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nA menos que exista una hip√≥tesis espec√≠fica de interacci√≥n, se recomienda utilizar un modelo aditivo. Los modelos con interacci√≥n aumentan la complejidad, el riesgo de sobreajuste, la posibilidad de colinealidad entre variables moderadoras y los problemas de convergencia, especialmente cuando el n√∫mero de estudios es reducido o hay muchos niveles en las variables categ√≥ricas.",
    "crumbs": [
      "Introducci√≥n a la Revisi√≥n Sistem√°tica con Meta-an√°lisis",
      "Meta-an√°lisis",
      "Exploraci√≥n de la heterogeneidad"
    ]
  },
  {
    "objectID": "unidad_2/04_mod_bias.html#sesgo-de-publicaci√≥n",
    "href": "unidad_2/04_mod_bias.html#sesgo-de-publicaci√≥n",
    "title": "Exploraci√≥n de la heterogeneidad",
    "section": "Sesgo de publicaci√≥n",
    "text": "Sesgo de publicaci√≥n\nEl sesgo de publicaci√≥n (publication bias) se refiere a la tendencia de publicar con mayor frecuencia estudios con resultados positivos, estad√≠sticamente significativos o con grandes tama√±os del efecto. Esto puede distorsionar la s√≠ntesis de la evidencia en un meta-an√°lisis, produciendo una sobreestimaci√≥n del efecto global. Por ello, es esencial evaluar y ajustar el sesgo de publicaci√≥n para garantizar que los resultados sean lo m√°s precisos y representativos posible.\n\nFunnel plots\nEl funnel plot o gr√°fico de embudo representa en el eje \\(Y\\) el tama√±o muestral o la precisi√≥n de los estudios, y en el eje \\(X\\) el estimador de efecto para cada estudio. En ausencia de sesgo de publicaci√≥n, se espera una distribuci√≥n sim√©trica que forme un patr√≥n similar a un embudo; de lo contrario, se observa asimetr√≠a.\nPara generar un funnel plot, se utiliza la funci√≥n funnel():\n\nfunnel(mod)\n\n\n\n\n\n\n\n\n\n\nTest de Egger\nEl test de Egger eval√∫a la simetr√≠a del funnel plot mediante una regresi√≥n lineal entre el estimador de efecto y su error est√°ndar. Un p-valor menor a 0,05 sugiere la presencia de sesgo de publicaci√≥n.\nEste test se implementa con la funci√≥n metabias():\n\nmetabias(\n  mod,                  # modelo de meta-an√°lisis\n  method.bias = \"Egger\" # aplica test de Egger (opci√≥n por defecto)\n  )\n\nLinear regression test of funnel plot asymmetry\n\nTest result: t = -1.45, df = 24, p-value = 0.1603\nBias estimate: -0.6649 (SE = 0.4589)\n\nDetails:\n- multiplicative residual heterogeneity variance (tau^2 = 1.4335)\n- predictor: standard error\n- weight:    inverse variance\n- reference: Egger et al. (1997), BMJ\n\n\n\n\nTest de Begg\nEl test de Begg utiliza la correlaci√≥n de rangos para evaluar la relaci√≥n entre el tama√±o del efecto y el error est√°ndar. Un p-valor menor que 0,05 indica la presencia de sesgo de publicaci√≥n.\nSe implementa a√±adiendo el argumento method.bias = \"Begg\" a la funci√≥n metabias():\n\nmetabias(\n  mod,                  # modelo de meta-an√°lisis\n  method.bias = \"Begg\"  # aplica test de Begg\n  )\n\nRank correlation test of funnel plot asymmetry\n\nTest result: z = -0.90, p-value = 0.3662\nBias estimate: -41.0000 (SE = 45.3689)\n\nReference: Begg & Mazumdar (1993), Biometrics\n\n\n\n\nTrim-and-fill\nEl m√©todo trim-and-fill estima el n√∫mero de estudios faltantes debido al sesgo de publicaci√≥n y ajusta la media global en consecuencia, incorporando estudios hipot√©ticos. Esto ayuda a corregir la estimaci√≥n del efecto global.\nSe utiliza la funci√≥n trimfill():\n\ntrimfill(mod)\n\nNumber of studies: k = 32 (with 6 added studies)\n\n                      events             95%-CI\nRandom effects model 23.4496 [21.7062; 25.3329]\n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.0181; tau = 0.1344; I^2 = 42.4% [12.2%; 62.2%]; H = 1.32 [1.07; 1.63]\n\nTest of heterogeneity:\n     Q d.f. p-value\n 53.82   31  0.0067\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Maximum-likelihood estimator for tau^2\n- Calculation of I^2 based on Q\n- Trim-and-fill method to adjust for funnel plot asymmetry (L-estimator)\n- Logit transformation\n- Events per 100000 observations\n\n\nGeneralmente, se recomienda utilizar dos o m√°s m√©todos para evaluar el sesgo de publicaci√≥n y obtener una visi√≥n m√°s completa de su impacto en el meta-an√°lisis. En el ejemplo anterior, no hubiera sido necesario realizar el trim-and-fill ya que el funnel plot tiene una forma bastante sim√©trica y el p-valor de los test de Egger y Begg fue menor a 0,05.",
    "crumbs": [
      "Introducci√≥n a la Revisi√≥n Sistem√°tica con Meta-an√°lisis",
      "Meta-an√°lisis",
      "Exploraci√≥n de la heterogeneidad"
    ]
  },
  {
    "objectID": "unidad_2/04_mod_bias.html#modelos-multinivel",
    "href": "unidad_2/04_mod_bias.html#modelos-multinivel",
    "title": "Exploraci√≥n de la heterogeneidad",
    "section": "Modelos multinivel",
    "text": "Modelos multinivel\nDesde una perspectiva estad√≠stica, todos los modelos de meta-an√°lisis pueden considerarse multinivel, ya que contemplan m√∫ltiples fuentes de variaci√≥n. Por ejemplo, los modelos de efectos aleatorios incluyen al menos dos niveles: la variabilidad dentro de los estudios (error aleatorio) y la variaci√≥n sistem√°tica no explicada por los moderadores (heterogeneidad).\nEsta estructura asume que los individuos est√°n anidados dentro de cada estudio, lo que configura una jerarqu√≠a de los datos an√°loga a un modelo lineal con intercepto aleatorio, tambi√©n conocido como modelo de efectos mixtos.\n\n\n\n\n\n\nImportante\nEn estad√≠stica convencional, los modelos lineales generalizados con efectos mixtos ‚Äîo modelos multinivel‚Äî incorporan efectos fijos (coeficientes comunes a todos los grupos) y efectos aleatorios (espec√≠ficos por grupo o cl√∫ster). Los efectos aleatorios modelan la dependencia estructural entre observaciones, pero no afectan directamente la inferencia sobre los efectos fijos.\n\n\n\nAunque ambos enfoques son t√©cnicamente modelos mixtos, en meta-an√°lisis el t√©rmino suele referirse a modelos en los que se incluyen categor√≠as fijas para los moderadores y un componente aleatorio para modelar la heterogeneidad entre estudios. Por esta raz√≥n, a la metarregresi√≥n se la denomina tambi√©n modelo de efectos fijos plurales (fixed effects ‚Äìplural‚Äì model) o modelo de efectos mixtos.\nAhora bien, en ciertas situaciones, esta representaci√≥n puede no ser suficiente para capturar la estructura real de los datos. Por ejemplo, un mismo estudio puede reportar m√∫ltiples estimadores de efecto correspondientes a diferentes subgrupos, momentos de seguimiento, sitios de estudio, tratamientos o desenlaces. En estos casos, asumir que las estimaciones de un mismo estudio son independientes puede conducir a inferencias sesgadas y p√©rdida de precisi√≥n.\nLos modelos de tres niveles abordan esta limitaci√≥n incorporando una capa adicional de variabilidad para modelar la heterogeneidad intraestudio, es decir, la variaci√≥n entre estimadores reportados por un mismo estudio. Esto permite incorporar todas las estimaciones disponibles sin necesidad de promediarlas ni seleccionar una por estudio, mejorando el ajuste del modelo.\n\nImplementaci√≥n en R\nSi bien el paquete metafor es el m√°s apropiado para trabajar con modelos multinivel y/o metarregresiones m√∫ltiples, su uso requiere un manejo m√°s avanzado de R.\nEn sus actualizaciones m√°s recientes, el paquete meta permite ajustar modelos multinivel sencillos incorporando el argumento cluster.\nEn este ejemplo, trabajaremos con el conjunto de datos dat.bornmann2007, que contiene los resultados de 21 estudios sobre diferencias de g√©nero en la adjudicaci√≥n de becas y subsidios para investigaci√≥n:\n\n# Cargar datos\ndatos &lt;- dat.bornmann2007\n\n# Explorar datos\nglimpse(datos)\n\nRows: 66\nColumns: 13\n$ study      &lt;chr&gt; \"Ackers (2000)\", \"Ackers (2000)\", \"Ackers (2000)\", \"Ackers ‚Ä¶\n$ obs        &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 1, 1, 2, 3, 4,‚Ä¶\n$ doctype    &lt;chr&gt; \"Grey\", \"Grey\", \"Grey\", \"Grey\", \"Grey\", \"Grey\", \"Grey\", \"Ar‚Ä¶\n$ gender     &lt;chr&gt; \"M&F\", \"M&F\", \"M&F\", \"M&F\", \"M&F\", \"M&F\", \"M&F\", \"M&F\", \"M&‚Ä¶\n$ year       &lt;dbl&gt; 1996.0, 1996.0, 1996.0, 1996.0, 1996.0, 1996.0, 1996.0, 199‚Ä¶\n$ org        &lt;chr&gt; \"MSCA\", \"MSCA\", \"MSCA\", \"MSCA\", \"MSCA\", \"MSCA\", \"MSCA\", \"DF‚Ä¶\n$ country    &lt;chr&gt; \"Europe\", \"Europe\", \"Europe\", \"Europe\", \"Europe\", \"Europe\",‚Ä¶\n$ type       &lt;chr&gt; \"Fellowship\", \"Fellowship\", \"Fellowship\", \"Fellowship\", \"Fe‚Ä¶\n$ discipline &lt;chr&gt; \"Physical Sciences\", \"Physical Sciences\", \"Physical Science‚Ä¶\n$ waward     &lt;int&gt; 139, 45, 44, 63, 157, 114, 381, 8, 5, 6, 8, 4, 20, 5, 11, 2‚Ä¶\n$ wtotal     &lt;int&gt; 711, 258, 236, 251, 910, 589, 2027, 13, 8, 8, 16, 11, 44, 1‚Ä¶\n$ maward     &lt;int&gt; 274, 166, 219, 96, 252, 460, 489, 53, 53, 63, 53, 43, 55, 7‚Ä¶\n$ mtotal     &lt;int&gt; 1029, 908, 928, 507, 1118, 2244, 2275, 72, 82, 97, 94, 92, ‚Ä¶\n\n\nLas variables de inter√©s son:\n\nwaward: n√∫mero de mujeres que fueron seleccionadas.\nwtotal: n√∫mero de mujeres que se postularon.\nmaward: n√∫mero de varones que fueron seleccionados.\nmtotal: n√∫mero de varones que se postularon.\ntype: tipo de subsidio otorgado (\"Fellowship\"- beca de posgrado- o \"Grant\" - fondos para investigaci√≥n-)-\n\nEl conjunto de datos contiene 66 observaciones, lo que sugiere que varios estudios reportan m√°s de un estimador de efecto. Para confirmarlo, generamos una tabla de frecuencias por estudio:\n\ntabyl(datos, study) |&gt; \n  arrange(-n)\n\n                 study n    percent\n           Wood (1997) 9 0.13636364\n            NSF (2005) 8 0.12121212\n         Ackers (2000) 7 0.10606061\n   Allmendinger (2002) 7 0.10606061\n         Brouns (2000) 5 0.07575758\n          Grant (1997) 4 0.06060606\n        Willems (2001) 4 0.06060606\n         Dexter (2002) 3 0.04545455\n        Friesen (1998) 3 0.04545455\n        Taplick (2005) 3 0.04545455\n      Goldsmith (2002) 2 0.03030303\n          Viner (2004) 2 0.03030303\n        Bazeley (1998) 1 0.01515152\n       Bornmann (2005) 1 0.01515152\n          Emery (1992) 1 0.01515152\n     Jayasinghe (2001) 1 0.01515152\n           Over (1996) 1 0.01515152\n       Sigelman (1987) 1 0.01515152\n           Ward (1998) 1 0.01515152\n Wellcome Trust (1997) 1 0.01515152\n       Wenneras (1997) 1 0.01515152\n\n\nComo se observa, cada estudio aporta entre 1 y 9 estimaciones. Ajustaremos un modelo de efectos aleatorios para el odds-ratio de ser seleccionada siendo mujer:\n\n# Ajustar modelo\nmod &lt;- metabin(event.e = waward,  \n               n.e = wtotal,\n               event.c = maward,\n               n.c = mtotal,\n               data = datos,\n               sm = \"OR\",\n               common = FALSE,    \n               subgroup = type,\n               studlab = study)   \n\nVeamos los resultados en un forest plot:\n\nforest(mod, layout = \"subgroup\")\n\n\n\n\n\n\n\n\nEl efecto global nos muestra que las mujeres tienen probabilidades significativamente menores de ser seleccionadas respecto de los varones (OR: 0,93, \\(95\\%~IC\\): 0,88-0,99) y que esta tendencia global se mantiene cuando se trata de becas de posgrado, pero se vuelve no significativa para el pedido de subsidios de investigaci√≥n. Sin embargo, este modelo asume que las 66 observaciones son independientes entre s√≠, por lo que podr√≠a estar sobreestimando o subestimando los coeficientes y su significancia.\nAntes de continuar con el ajuste del modelo de tres niveles, generaremos una nueva variable que asigne un identificador √∫nico a cada observaci√≥n en base a su n√∫mero de fila:\n\ndatos &lt;- datos |&gt; \n  # Crear identificador √∫nico\n  rowid_to_column(var = \"id\")\n\nReajustamos el modelo incorporando study como variable de agrupamiento (cluster) y el n√∫mero de fila (id) como identificador de estudio:\n\nmod_multi &lt;- metabin(\n  event.e = waward,\n  n.e = wtotal,\n  event.c = maward,\n  n.c = mtotal,\n  data = datos, \n  sm = \"OR\",         \n  common = FALSE,\n  subgroup = type,\n  studlab = id,\n  cluster = study\n) \n\nForest plot:\n\nforest(mod_multi, layout = \"subgroup\")\n\n\n\n\n\n\n\n\nVeamos la salida del modelo:\n\nmod_multi\n\nNumber of studies: n = 21\nNumber of estimates: k = 66\nNumber of observations: o = 353725 (o.e = 74060, o.c = 279665)\nNumber of events: e = 109357\n\n                         OR           95%-CI     z p-value\nRandom effects model 0.9039 [0.8329; 0.9810] -2.42  0.0155\n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2.1 = 0.0161 [0.0040; 0.0555]; tau.1 = 0.1268 [0.0630; 0.2357] (between cluster)\n tau^2.2 = 0.0038 [0.0008; 0.0146]; tau.2 = 0.0613 [0.0285; 0.1208] (within cluster)\n I^2 = 70.6% [62.4%; 77.1%]; H = 1.85 [1.63; 2.09]\n\nTest of heterogeneity:\n      Q d.f.  p-value\n 221.28   65 &lt; 0.0001\n\nResults for subgroups (random effects model):\n                    k     OR           95%-CI  tau^2    tau     Q   I^2\ntype = Fellowship  26 0.8320 [0.7602; 0.9105] 0.0213 0.1460 59.56 58.0%\ntype = Grant       40 0.9850 [0.9094; 1.0669] 0.0157 0.1255 73.93 47.2%\n\nDetails of meta-analysis methods:\n- Inverse variance method (three-level model)\n- Restricted maximum-likelihood estimator for tau^2\n- Profile-Likelihood method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n\n\nPodemos observar que tanto los coeficientes para el estimador global como dentro de los subgrupos cambian ligeramente respecto al modelo de efectos aleatorios. Adicionamente, la heterogeneidad (tau-cuadrado) ahora aparece dividida en dos componentes:\n\ntau^2.1: heterogeneidad entre estudios o cl√∫steres.\ntau^2.2: heterogeneidad intra estudio/cl√∫ster.\n\nEsta descomposici√≥n permite una estimaci√≥n m√°s precisa de la variabilidad real y evita subestimar o sobreestimar la incertidumbre asociada al efecto global. Actualmente el paquete meta no nos permite obtener estimaciones de \\(I^2\\) intracl√∫ster (\\(I^2_{nivel2}\\)) e intercl√∫ster (\\(I^2_{nivel3}\\)) o calcular sesgo de publicaci√≥n. En la pr√≥xima secci√≥n, veremos herramientas adicionales para obtener estas estimaciones a partir de modelos ajustados con metafor.\n\n\nAn√°lisis de sensibilidad\nEl an√°lisis de sensibilidad permite evaluar la robustez de los resultados de un meta-an√°lisis. Una estrategia com√∫n consiste en reajustar el modelo excluyendo estudios con menor tama√±o muestral o de menor calidad, y luego comparar el estimador de efecto y su intervalo de confianza del 95% con los del modelo original. Otra alternativa es el an√°lisis leave-one-out, que implica eliminar un estudio a la vez para observar c√≥mo var√≠a el estimador global, en meta se implementa usando la funci√≥n metainf() y solo admite modelos de efectos fijos o de efectos aleatorios.\n\n\n\n\n\n\nHasta aqu√≠ hemos cubierto los aspectos b√°sicos para evaluar fuentes de heterogeneidad en modelos de meta-an√°lisis. Quienes tengan inter√©s en profundizar en las medidas de heterogeneidad y su aplicaci√≥n, recomendamos consultar el art√≠culo de (Bown y Sutton 2010) y los cap√≠tulos 7, 8 y 9 de Harrer et¬†al. (2021).\nLa pr√≥xima secci√≥n es optativa y orientada a quienes tengan mayor manejo de R, se orientar√° al uso de herramientas adicionales para la visualizaci√≥n avanzada de resultados y an√°lisis de metarregresiones m√∫ltiples y modelos multinivel.",
    "crumbs": [
      "Introducci√≥n a la Revisi√≥n Sistem√°tica con Meta-an√°lisis",
      "Meta-an√°lisis",
      "Exploraci√≥n de la heterogeneidad"
    ]
  }
]